{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "501_A4_P2.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JBenedictM/501-A4-TF/blob/master/501_A4_P2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z1o4PRH6KJuJ",
        "colab_type": "code",
        "outputId": "81af74ed-1a7b-49c9-c8af-8b795ec5b882",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w4ughi_1E4dp",
        "colab_type": "text"
      },
      "source": [
        "# Upload to google drive: notMNIST.npz"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S4eVDT0IKKbh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        },
        "outputId": "5c360b78-9a80-4971-8b87-9bc83e2f5ecd"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "path = \"/content/drive/My Drive/notMNIST.npz\""
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UmlX83--KT6M",
        "colab_type": "code",
        "outputId": "4bf957af-b396-403c-ee4e-0bf3a72d6fff",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "print(\"--Get data--\")\n",
        "# path is defined by the cell above\n",
        "with np.load(path, allow_pickle=True) as f:\n",
        "    x_train, y_train = f['x_train'], f['y_train']\n",
        "    x_test, y_test = f['x_test'], f['y_test']\n",
        "\n",
        "print(\"--Process data--\")\n",
        "print(len(y_train))\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "#shape = (batch_size, height, width, depth)\n",
        "x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
        "x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
        " \n",
        " # new model employes more convolution layers \n",
        " # each layer also contains more kernels\n",
        "print(\"--Make model--\")\n",
        "model = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Conv2D(256, input_shape=(28, 28, 1), kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
        "  tf.keras.layers.MaxPool2D(pool_size=(2,2)),\n",
        "  tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
        "  tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "  tf.keras.layers.Conv2D(256, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
        "  tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "  #tf.keras.layers.Conv2D(128, kernel_size=(3, 3), activation=\"relu\", padding=\"same\"),\n",
        "  #tf.keras.layers.MaxPool2D(pool_size=(2, 2)),\n",
        "  tf.keras.layers.Flatten(),\n",
        "  tf.keras.layers.Dense(512, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.50),\n",
        "  tf.keras.layers.Dense(512, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.50),\n",
        "  tf.keras.layers.Dense(512, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.50),\n",
        "  tf.keras.layers.Dense(512, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.50),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "print(\"--Fit model--\")\n",
        "val_loss_callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=20)\n",
        "checkpoint_val = tf.keras.callbacks.ModelCheckpoint(\"best_notmnist_model.h5\", monitor=\"val_loss\", mode=\"min\", save_best_only=True, verbose=1)\n",
        "checkpoint_train = tf.keras.callbacks.ModelCheckpoint(\"best_notmnist_model.h5\", monitor=\"loss\", mode=\"min\", save_best_only=True, verbose=1)\n",
        "\n",
        "cb = [val_loss_callback, checkpoint_val, checkpoint_train]\n",
        "\n",
        "model.fit(x_train, y_train, epochs=99999999,  verbose=1, validation_data=(x_test, y_test), callbacks=cb)\n",
        "\n",
        "print(\"--Evaluate model--\")\n",
        "model_loss, model_acc = model.evaluate(x_test,  y_test, verbose=2)\n",
        "model.summary()\n",
        "print(f\"Model Loss:    {model_loss:.2f}\")\n",
        "print(f\"Model Accuray: {model_acc*100:.1f}%\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--Get data--\n",
            "--Process data--\n",
            "60000\n",
            "--Make model--\n",
            "--Fit model--\n",
            "Train on 60000 samples, validate on 10000 samples\n",
            "Epoch 1/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 2.0345 - accuracy: 0.2442\n",
            "Epoch 00001: val_loss improved from inf to 0.72238, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.03355, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 45s 758us/sample - loss: 2.0336 - accuracy: 0.2445 - val_loss: 0.7224 - val_accuracy: 0.7735\n",
            "Epoch 2/99999999\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.8021 - accuracy: 0.7560\n",
            "Epoch 00002: val_loss improved from 0.72238 to 0.30524, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00002: loss improved from 2.03355 to 0.80194, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 678us/sample - loss: 0.8019 - accuracy: 0.7560 - val_loss: 0.3052 - val_accuracy: 0.9090\n",
            "Epoch 3/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.5688 - accuracy: 0.8319\n",
            "Epoch 00003: val_loss improved from 0.30524 to 0.25386, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00003: loss improved from 0.80194 to 0.56871, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 676us/sample - loss: 0.5687 - accuracy: 0.8320 - val_loss: 0.2539 - val_accuracy: 0.9222\n",
            "Epoch 4/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.5028 - accuracy: 0.8514\n",
            "Epoch 00004: val_loss improved from 0.25386 to 0.22781, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00004: loss improved from 0.56871 to 0.50277, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 677us/sample - loss: 0.5028 - accuracy: 0.8514 - val_loss: 0.2278 - val_accuracy: 0.9318\n",
            "Epoch 5/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.4591 - accuracy: 0.8650\n",
            "Epoch 00005: val_loss improved from 0.22781 to 0.21190, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00005: loss improved from 0.50277 to 0.45911, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 682us/sample - loss: 0.4591 - accuracy: 0.8649 - val_loss: 0.2119 - val_accuracy: 0.9378\n",
            "Epoch 6/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.4312 - accuracy: 0.8730\n",
            "Epoch 00006: val_loss improved from 0.21190 to 0.19529, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00006: loss improved from 0.45911 to 0.43113, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 675us/sample - loss: 0.4311 - accuracy: 0.8730 - val_loss: 0.1953 - val_accuracy: 0.9430\n",
            "Epoch 7/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.4074 - accuracy: 0.8788\n",
            "Epoch 00007: val_loss improved from 0.19529 to 0.18480, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00007: loss improved from 0.43113 to 0.40730, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 677us/sample - loss: 0.4073 - accuracy: 0.8788 - val_loss: 0.1848 - val_accuracy: 0.9462\n",
            "Epoch 8/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.3896 - accuracy: 0.8839\n",
            "Epoch 00008: val_loss improved from 0.18480 to 0.17615, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00008: loss improved from 0.40730 to 0.38952, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 677us/sample - loss: 0.3895 - accuracy: 0.8839 - val_loss: 0.1762 - val_accuracy: 0.9483\n",
            "Epoch 9/99999999\n",
            "59968/60000 [============================>.] - ETA: 0s - loss: 0.3753 - accuracy: 0.8887\n",
            "Epoch 00009: val_loss improved from 0.17615 to 0.17130, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00009: loss improved from 0.38952 to 0.37537, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 678us/sample - loss: 0.3754 - accuracy: 0.8887 - val_loss: 0.1713 - val_accuracy: 0.9497\n",
            "Epoch 10/99999999\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.3603 - accuracy: 0.8924\n",
            "Epoch 00010: val_loss improved from 0.17130 to 0.16900, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00010: loss improved from 0.37537 to 0.36035, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 677us/sample - loss: 0.3604 - accuracy: 0.8924 - val_loss: 0.1690 - val_accuracy: 0.9487\n",
            "Epoch 11/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.3500 - accuracy: 0.8951\n",
            "Epoch 00011: val_loss improved from 0.16900 to 0.16595, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00011: loss improved from 0.36035 to 0.35011, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 677us/sample - loss: 0.3501 - accuracy: 0.8951 - val_loss: 0.1659 - val_accuracy: 0.9510\n",
            "Epoch 12/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.3392 - accuracy: 0.8975\n",
            "Epoch 00012: val_loss improved from 0.16595 to 0.15947, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00012: loss improved from 0.35011 to 0.33924, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 680us/sample - loss: 0.3392 - accuracy: 0.8974 - val_loss: 0.1595 - val_accuracy: 0.9515\n",
            "Epoch 13/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.3309 - accuracy: 0.9004\n",
            "Epoch 00013: val_loss improved from 0.15947 to 0.15583, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00013: loss improved from 0.33924 to 0.33108, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 677us/sample - loss: 0.3311 - accuracy: 0.9005 - val_loss: 0.1558 - val_accuracy: 0.9527\n",
            "Epoch 14/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.3207 - accuracy: 0.9035\n",
            "Epoch 00014: val_loss improved from 0.15583 to 0.15239, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00014: loss improved from 0.33108 to 0.32058, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 40s 675us/sample - loss: 0.3206 - accuracy: 0.9035 - val_loss: 0.1524 - val_accuracy: 0.9553\n",
            "Epoch 15/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.3141 - accuracy: 0.9042\n",
            "Epoch 00015: val_loss improved from 0.15239 to 0.14880, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00015: loss improved from 0.32058 to 0.31428, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 677us/sample - loss: 0.3143 - accuracy: 0.9042 - val_loss: 0.1488 - val_accuracy: 0.9549\n",
            "Epoch 16/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.3028 - accuracy: 0.9084\n",
            "Epoch 00016: val_loss improved from 0.14880 to 0.14867, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00016: loss improved from 0.31428 to 0.30266, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 676us/sample - loss: 0.3027 - accuracy: 0.9084 - val_loss: 0.1487 - val_accuracy: 0.9552\n",
            "Epoch 17/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.2968 - accuracy: 0.9098\n",
            "Epoch 00017: val_loss improved from 0.14867 to 0.14680, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00017: loss improved from 0.30266 to 0.29685, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 677us/sample - loss: 0.2969 - accuracy: 0.9097 - val_loss: 0.1468 - val_accuracy: 0.9553\n",
            "Epoch 18/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.2904 - accuracy: 0.9129\n",
            "Epoch 00018: val_loss did not improve from 0.14680\n",
            "\n",
            "Epoch 00018: loss improved from 0.29685 to 0.29023, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 678us/sample - loss: 0.2902 - accuracy: 0.9129 - val_loss: 0.1468 - val_accuracy: 0.9563\n",
            "Epoch 19/99999999\n",
            "59968/60000 [============================>.] - ETA: 0s - loss: 0.2812 - accuracy: 0.9148\n",
            "Epoch 00019: val_loss improved from 0.14680 to 0.14265, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00019: loss improved from 0.29023 to 0.28119, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 679us/sample - loss: 0.2812 - accuracy: 0.9149 - val_loss: 0.1426 - val_accuracy: 0.9567\n",
            "Epoch 20/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.2762 - accuracy: 0.9157\n",
            "Epoch 00020: val_loss improved from 0.14265 to 0.14239, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00020: loss improved from 0.28119 to 0.27616, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 681us/sample - loss: 0.2762 - accuracy: 0.9158 - val_loss: 0.1424 - val_accuracy: 0.9577\n",
            "Epoch 21/99999999\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.2678 - accuracy: 0.9186\n",
            "Epoch 00021: val_loss improved from 0.14239 to 0.13868, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00021: loss improved from 0.27616 to 0.26779, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 676us/sample - loss: 0.2678 - accuracy: 0.9186 - val_loss: 0.1387 - val_accuracy: 0.9595\n",
            "Epoch 22/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.2605 - accuracy: 0.9192\n",
            "Epoch 00022: val_loss improved from 0.13868 to 0.13418, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00022: loss improved from 0.26779 to 0.26048, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 681us/sample - loss: 0.2605 - accuracy: 0.9192 - val_loss: 0.1342 - val_accuracy: 0.9604\n",
            "Epoch 23/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.2572 - accuracy: 0.9209\n",
            "Epoch 00023: val_loss did not improve from 0.13418\n",
            "\n",
            "Epoch 00023: loss improved from 0.26048 to 0.25719, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 679us/sample - loss: 0.2572 - accuracy: 0.9209 - val_loss: 0.1344 - val_accuracy: 0.9606\n",
            "Epoch 24/99999999\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.2513 - accuracy: 0.9235\n",
            "Epoch 00024: val_loss did not improve from 0.13418\n",
            "\n",
            "Epoch 00024: loss improved from 0.25719 to 0.25106, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 681us/sample - loss: 0.2511 - accuracy: 0.9236 - val_loss: 0.1380 - val_accuracy: 0.9597\n",
            "Epoch 25/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.2433 - accuracy: 0.9250\n",
            "Epoch 00025: val_loss did not improve from 0.13418\n",
            "\n",
            "Epoch 00025: loss improved from 0.25106 to 0.24322, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 679us/sample - loss: 0.2432 - accuracy: 0.9250 - val_loss: 0.1375 - val_accuracy: 0.9598\n",
            "Epoch 26/99999999\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.2399 - accuracy: 0.9261\n",
            "Epoch 00026: val_loss did not improve from 0.13418\n",
            "\n",
            "Epoch 00026: loss improved from 0.24322 to 0.23986, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 678us/sample - loss: 0.2399 - accuracy: 0.9261 - val_loss: 0.1348 - val_accuracy: 0.9616\n",
            "Epoch 27/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.2344 - accuracy: 0.9278\n",
            "Epoch 00027: val_loss improved from 0.13418 to 0.13399, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00027: loss improved from 0.23986 to 0.23442, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 680us/sample - loss: 0.2344 - accuracy: 0.9278 - val_loss: 0.1340 - val_accuracy: 0.9615\n",
            "Epoch 28/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.2279 - accuracy: 0.9296\n",
            "Epoch 00028: val_loss improved from 0.13399 to 0.13298, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00028: loss improved from 0.23442 to 0.22798, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 681us/sample - loss: 0.2280 - accuracy: 0.9296 - val_loss: 0.1330 - val_accuracy: 0.9604\n",
            "Epoch 29/99999999\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.2216 - accuracy: 0.9305\n",
            "Epoch 00029: val_loss did not improve from 0.13298\n",
            "\n",
            "Epoch 00029: loss improved from 0.22798 to 0.22147, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 681us/sample - loss: 0.2215 - accuracy: 0.9305 - val_loss: 0.1341 - val_accuracy: 0.9620\n",
            "Epoch 30/99999999\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.2181 - accuracy: 0.9322\n",
            "Epoch 00030: val_loss did not improve from 0.13298\n",
            "\n",
            "Epoch 00030: loss improved from 0.22147 to 0.21794, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 680us/sample - loss: 0.2179 - accuracy: 0.9323 - val_loss: 0.1390 - val_accuracy: 0.9620\n",
            "Epoch 31/99999999\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.2113 - accuracy: 0.9342\n",
            "Epoch 00031: val_loss improved from 0.13298 to 0.13262, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00031: loss improved from 0.21794 to 0.21130, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 680us/sample - loss: 0.2113 - accuracy: 0.9342 - val_loss: 0.1326 - val_accuracy: 0.9613\n",
            "Epoch 32/99999999\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.2052 - accuracy: 0.9361\n",
            "Epoch 00032: val_loss did not improve from 0.13262\n",
            "\n",
            "Epoch 00032: loss improved from 0.21130 to 0.20518, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 680us/sample - loss: 0.2052 - accuracy: 0.9362 - val_loss: 0.1329 - val_accuracy: 0.9616\n",
            "Epoch 33/99999999\n",
            "59968/60000 [============================>.] - ETA: 0s - loss: 0.2000 - accuracy: 0.9378\n",
            "Epoch 00033: val_loss did not improve from 0.13262\n",
            "\n",
            "Epoch 00033: loss improved from 0.20518 to 0.19997, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 679us/sample - loss: 0.2000 - accuracy: 0.9378 - val_loss: 0.1349 - val_accuracy: 0.9625\n",
            "Epoch 34/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.1970 - accuracy: 0.9374\n",
            "Epoch 00034: val_loss improved from 0.13262 to 0.13128, saving model to best_notmnist_model.h5\n",
            "\n",
            "Epoch 00034: loss improved from 0.19997 to 0.19711, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 677us/sample - loss: 0.1971 - accuracy: 0.9374 - val_loss: 0.1313 - val_accuracy: 0.9632\n",
            "Epoch 35/99999999\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1930 - accuracy: 0.9391\n",
            "Epoch 00035: val_loss did not improve from 0.13128\n",
            "\n",
            "Epoch 00035: loss improved from 0.19711 to 0.19299, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 682us/sample - loss: 0.1930 - accuracy: 0.9391 - val_loss: 0.1429 - val_accuracy: 0.9602\n",
            "Epoch 36/99999999\n",
            "59968/60000 [============================>.] - ETA: 0s - loss: 0.1858 - accuracy: 0.9416\n",
            "Epoch 00036: val_loss did not improve from 0.13128\n",
            "\n",
            "Epoch 00036: loss improved from 0.19299 to 0.18600, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 680us/sample - loss: 0.1860 - accuracy: 0.9416 - val_loss: 0.1386 - val_accuracy: 0.9609\n",
            "Epoch 37/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.1826 - accuracy: 0.9437\n",
            "Epoch 00037: val_loss did not improve from 0.13128\n",
            "\n",
            "Epoch 00037: loss improved from 0.18600 to 0.18254, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 679us/sample - loss: 0.1825 - accuracy: 0.9437 - val_loss: 0.1426 - val_accuracy: 0.9622\n",
            "Epoch 38/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.1748 - accuracy: 0.9452\n",
            "Epoch 00038: val_loss did not improve from 0.13128\n",
            "\n",
            "Epoch 00038: loss improved from 0.18254 to 0.17508, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 678us/sample - loss: 0.1751 - accuracy: 0.9451 - val_loss: 0.1472 - val_accuracy: 0.9615\n",
            "Epoch 39/99999999\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1754 - accuracy: 0.9446\n",
            "Epoch 00039: val_loss did not improve from 0.13128\n",
            "\n",
            "Epoch 00039: loss did not improve from 0.17508\n",
            "60000/60000 [==============================] - 41s 677us/sample - loss: 0.1754 - accuracy: 0.9446 - val_loss: 0.1405 - val_accuracy: 0.9630\n",
            "Epoch 40/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.1702 - accuracy: 0.9461\n",
            "Epoch 00040: val_loss did not improve from 0.13128\n",
            "\n",
            "Epoch 00040: loss improved from 0.17508 to 0.17039, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 678us/sample - loss: 0.1704 - accuracy: 0.9460 - val_loss: 0.1426 - val_accuracy: 0.9630\n",
            "Epoch 41/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.1676 - accuracy: 0.9470\n",
            "Epoch 00041: val_loss did not improve from 0.13128\n",
            "\n",
            "Epoch 00041: loss improved from 0.17039 to 0.16760, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 678us/sample - loss: 0.1676 - accuracy: 0.9470 - val_loss: 0.1388 - val_accuracy: 0.9626\n",
            "Epoch 42/99999999\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1614 - accuracy: 0.9499\n",
            "Epoch 00042: val_loss did not improve from 0.13128\n",
            "\n",
            "Epoch 00042: loss improved from 0.16760 to 0.16144, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 676us/sample - loss: 0.1614 - accuracy: 0.9499 - val_loss: 0.1461 - val_accuracy: 0.9605\n",
            "Epoch 43/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.1589 - accuracy: 0.9498\n",
            "Epoch 00043: val_loss did not improve from 0.13128\n",
            "\n",
            "Epoch 00043: loss improved from 0.16144 to 0.15889, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 682us/sample - loss: 0.1589 - accuracy: 0.9499 - val_loss: 0.1423 - val_accuracy: 0.9632\n",
            "Epoch 44/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.1542 - accuracy: 0.9519\n",
            "Epoch 00044: val_loss did not improve from 0.13128\n",
            "\n",
            "Epoch 00044: loss improved from 0.15889 to 0.15414, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 676us/sample - loss: 0.1541 - accuracy: 0.9519 - val_loss: 0.1516 - val_accuracy: 0.9626\n",
            "Epoch 45/99999999\n",
            "59968/60000 [============================>.] - ETA: 0s - loss: 0.1481 - accuracy: 0.9526\n",
            "Epoch 00045: val_loss did not improve from 0.13128\n",
            "\n",
            "Epoch 00045: loss improved from 0.15414 to 0.14801, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 679us/sample - loss: 0.1480 - accuracy: 0.9526 - val_loss: 0.1495 - val_accuracy: 0.9635\n",
            "Epoch 46/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.1452 - accuracy: 0.9532\n",
            "Epoch 00046: val_loss did not improve from 0.13128\n",
            "\n",
            "Epoch 00046: loss improved from 0.14801 to 0.14520, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 677us/sample - loss: 0.1452 - accuracy: 0.9532 - val_loss: 0.1498 - val_accuracy: 0.9634\n",
            "Epoch 47/99999999\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1420 - accuracy: 0.9547\n",
            "Epoch 00047: val_loss did not improve from 0.13128\n",
            "\n",
            "Epoch 00047: loss improved from 0.14520 to 0.14207, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 677us/sample - loss: 0.1421 - accuracy: 0.9547 - val_loss: 0.1486 - val_accuracy: 0.9642\n",
            "Epoch 48/99999999\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1372 - accuracy: 0.9558\n",
            "Epoch 00048: val_loss did not improve from 0.13128\n",
            "\n",
            "Epoch 00048: loss improved from 0.14207 to 0.13711, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 678us/sample - loss: 0.1371 - accuracy: 0.9559 - val_loss: 0.1413 - val_accuracy: 0.9647\n",
            "Epoch 49/99999999\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1367 - accuracy: 0.9570\n",
            "Epoch 00049: val_loss did not improve from 0.13128\n",
            "\n",
            "Epoch 00049: loss improved from 0.13711 to 0.13672, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 679us/sample - loss: 0.1367 - accuracy: 0.9569 - val_loss: 0.1507 - val_accuracy: 0.9634\n",
            "Epoch 50/99999999\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1388 - accuracy: 0.9558\n",
            "Epoch 00050: val_loss did not improve from 0.13128\n",
            "\n",
            "Epoch 00050: loss did not improve from 0.13672\n",
            "60000/60000 [==============================] - 41s 681us/sample - loss: 0.1387 - accuracy: 0.9558 - val_loss: 0.1591 - val_accuracy: 0.9627\n",
            "Epoch 51/99999999\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1310 - accuracy: 0.9578\n",
            "Epoch 00051: val_loss did not improve from 0.13128\n",
            "\n",
            "Epoch 00051: loss improved from 0.13672 to 0.13090, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 681us/sample - loss: 0.1309 - accuracy: 0.9579 - val_loss: 0.1685 - val_accuracy: 0.9636\n",
            "Epoch 52/99999999\n",
            "59936/60000 [============================>.] - ETA: 0s - loss: 0.1289 - accuracy: 0.9589\n",
            "Epoch 00052: val_loss did not improve from 0.13128\n",
            "\n",
            "Epoch 00052: loss improved from 0.13090 to 0.12896, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 679us/sample - loss: 0.1290 - accuracy: 0.9589 - val_loss: 0.1668 - val_accuracy: 0.9638\n",
            "Epoch 53/99999999\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1225 - accuracy: 0.9615\n",
            "Epoch 00053: val_loss did not improve from 0.13128\n",
            "\n",
            "Epoch 00053: loss improved from 0.12896 to 0.12255, saving model to best_notmnist_model.h5\n",
            "60000/60000 [==============================] - 41s 678us/sample - loss: 0.1225 - accuracy: 0.9615 - val_loss: 0.1581 - val_accuracy: 0.9632\n",
            "Epoch 54/99999999\n",
            "59904/60000 [============================>.] - ETA: 0s - loss: 0.1239 - accuracy: 0.9605\n",
            "Epoch 00054: val_loss did not improve from 0.13128\n",
            "\n",
            "Epoch 00054: loss did not improve from 0.12255\n",
            "60000/60000 [==============================] - 41s 675us/sample - loss: 0.1239 - accuracy: 0.9605 - val_loss: 0.1615 - val_accuracy: 0.9641\n",
            "Epoch 00054: early stopping\n",
            "--Evaluate model--\n",
            "10000/1 - 2s - loss: 0.0916 - accuracy: 0.9641\n",
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 28, 28, 256)       2560      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 14, 14, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 14, 14, 256)       590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 7, 7, 256)         0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 7, 7, 256)         590080    \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 3, 3, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 2304)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1180160   \n",
            "_________________________________________________________________\n",
            "dropout (Dropout)            (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 512)               262656    \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 512)               0         \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 10)                5130      \n",
            "=================================================================\n",
            "Total params: 3,155,978\n",
            "Trainable params: 3,155,978\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Model Loss:    0.16\n",
            "Model Accuray: 96.4%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FqOYMbbzEwUt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Save Model to notMNIST.h5"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "03ZLaLRVEweP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from google.colab import files\n",
        "files.download('best_notmnist_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}