{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "501_A4_p3.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/JBenedictM/501-A4-TF/blob/master/501_A4_p3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4t6-j9Iz4P8n",
        "colab_type": "code",
        "outputId": "ca09c37a-7c00-4a30-ceb3-0c6508190ccf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "try:\n",
        "  # %tensorflow_version only exists in Colab.\n",
        "  %tensorflow_version 2.x\n",
        "except Exception:\n",
        "  pass"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TensorFlow 2.x selected.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWSrYbtK_8f-",
        "colab_type": "code",
        "outputId": "291c087b-896f-4028-ebab-2c64ecaf15b9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xbi_YY3VxwlR",
        "colab_type": "text"
      },
      "source": [
        "# Path for test and train files in google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZkJqrCo95K7W",
        "colab_type": "code",
        "outputId": "a1c802ee-a31e-417c-ff15-d5ed04b91584",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 124
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "data_path = \"/content/drive/My Drive/heart.csv\"\n",
        "train_path = \"/content/drive/My Drive/heart_train.csv\"\n",
        "test_path = \"/content/drive/My Drive/heart_test.csv\""
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mRjtrGjxn3SD",
        "colab_type": "text"
      },
      "source": [
        "# Used to create Train and Test csv files\n",
        "Splits Heart.csv into 80% training data and 20% testing data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iCBKlQbomK0D",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "import sys\n",
        "\n",
        "data = pd.read_csv(data_path)\n",
        "y_chd = data.chd\n",
        "X = data.drop(\"chd\", axis=1)\n",
        "X = X.drop(\"row.names\", axis=1)\n",
        "#data = data.drop(\"\", axis=1)\n",
        "#print(X)\n",
        "\n",
        "x_train, x_test, y_train, y_test = train_test_split(data, y_chd, test_size=0.2)\n",
        "\n",
        "#print(x_train.shape)\n",
        "#print(x_train)\n",
        "\n",
        "#print(x_test.shape)\n",
        "#print(x_test)\n",
        "\n",
        "x_train.to_csv(\"/content/drive/My Drive/heart_train.csv\", encoding=\"utf-8\", sep='\\t', index=False)\n",
        "x_test.to_csv(\"/content/drive/My Drive/heart_test.csv\", encoding=\"utf-8\", sep='\\t', index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fJEY5TfLMNAb",
        "colab_type": "text"
      },
      "source": [
        "# Load and Process Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cS6egxKiML57",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import absolute_import, division, print_function, unicode_literals\n",
        "import functools\n",
        "\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import pandas as pd\n",
        "import sys\n",
        "\n",
        "PREDICT_COLUMN = \"chd\"\n",
        "PREDICT_LABELs = [0, 1]\n",
        "\n",
        "# load csv data\n",
        "def get_dataset(file_path, **kwargs):\n",
        "    dataset = tf.data.experimental.make_csv_dataset(  \n",
        "        file_path, \n",
        "        label_name=PREDICT_COLUMN,\n",
        "        batch_size=1,\n",
        "        na_value=\"?\",\n",
        "        num_epochs=1,\n",
        "        ignore_errors=True,\n",
        "        field_delim='\\t',\n",
        "        **kwargs)\n",
        "    \n",
        "    return dataset\n",
        "\n",
        "def show_batch(dataset):\n",
        "    for batch, label in dataset.take(1):\n",
        "        for key, value in batch.items():\n",
        "            print(\"{:20s}: {}\".format(key, value.numpy()))\n",
        "\n",
        "def pack(features, label):\n",
        "    return tf.stack(list(features.values()), axis=-1), label\n",
        "\n",
        "\n",
        "def normalize_numeric_data(data, mean, std):\n",
        "    return (data-mean)/std\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fuMly7cyx1A5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class PackNumericFeatures(object):\n",
        "    def __init__(self, names):\n",
        "        self.names = names\n",
        "\n",
        "      \n",
        "    def __call__(self, features, labels):\n",
        "        numeric_features = [features.pop(name) for name in self.names]\n",
        "        numeric_features = [tf.cast(feat, tf.float32) for feat in numeric_features]\n",
        "        numeric_features = tf.stack(numeric_features, axis=-1)\n",
        "        features[\"numeric\"] = numeric_features\n",
        "\n",
        "        return features, labels\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6L1KiMyFxvny",
        "colab_type": "code",
        "outputId": "032666be-9c99-4544-9efe-ef9303424318",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "# instaniate training and testing data\n",
        "\n",
        "import pathlib\n",
        "import shutil\n",
        "import tempfile\n",
        "\n",
        "import tensorflow_docs as tfdocs\n",
        "import tensorflow_docs.modeling\n",
        "import tensorflow_docs.plots\n",
        "\n",
        "from  IPython import display\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "logdir = pathlib.Path(tempfile.mkdtemp())/\"tensorboard_logs\"\n",
        "shutil.rmtree(logdir, ignore_errors=True)\n",
        "\n",
        "NAME_COLUMN = \"row.names\"\n",
        "SELECT_COLUMNS =  [\"sbp\", \"tobacco\", \"ldl\", \"adiposity\", \"famhist\", \"typea\", \"obesity\", \"alcohol\", \"age\"] + [PREDICT_COLUMN]\n",
        "NUMERIC_COLUMNS = [\"sbp\", \"tobacco\", \"ldl\", \"adiposity\", \"typea\", \"obesity\", \"alcohol\", \"age\"]\n",
        "SELECT_COLUMNS_NUM = NUMERIC_COLUMNS + [PREDICT_COLUMN]\n",
        "DEFAULT_NUM = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n",
        "\n",
        "data_sample_size = 462\n",
        "train_sample_size = int(data_sample_size*0.8)\n",
        "test_sample_size = data_sample_size - train_sample_size\n",
        "BATCH_SIZE = 10\n",
        "STEPS_PER_EPOCH = train_sample_size//BATCH_SIZE\n",
        "\n",
        "print(train_sample_size)\n",
        "print(test_sample_size)\n",
        "\n",
        "raw_train_data = get_dataset(train_path, select_columns=SELECT_COLUMNS).repeat().batch(BATCH_SIZE)\n",
        "raw_test_data = get_dataset(test_path, select_columns=SELECT_COLUMNS).batch(BATCH_SIZE)\n",
        "\n",
        "#show_batch(raw_train_data)\n",
        "#print()\n",
        "#show_batch(raw_test_data)\n",
        "\n",
        "# pack numeric data types\n",
        "#temp_train_numeric = get_dataset(train_path, select_columns=SELECT_COLUMNS_NUM, column_defaults=DEFAULT_NUM)\n",
        "#show_batch(temp_train_numeric)\n",
        "#print(len(list(raw_test_data)))\n",
        "\n",
        "#example_batch, labels_batch = next(iter(temp_train_numeric))\n",
        "\n",
        "#packed_dataset = temp_train_numeric.map(pack)\n",
        "\n",
        "#for features, label in packed_dataset.take(1):\n",
        " #   print(features.numpy())\n",
        "  #  print()\n",
        "   # print(label.numpy())\n",
        "\n",
        "packed_train_data = raw_train_data.map(PackNumericFeatures(NUMERIC_COLUMNS))\n",
        "packed_test_data = raw_test_data.map(PackNumericFeatures(NUMERIC_COLUMNS))\n",
        "show_batch(packed_train_data)\n",
        "\n",
        "example_batch, labels_batch = next(iter(packed_train_data))\n",
        "print(example_batch)\n",
        "\n",
        "# normalize data\n",
        "# load data and calculate mean and standard deviation of training data\n",
        "#desc = pd.read_csv(train_path, names=SELECT_COLUMNS, index_col=SELECT_COLUMNS, usecols=NUMERIC_COLUMNS, sep='\\t')\n",
        "desc = pd.read_csv(train_path, sep='\\t')[NUMERIC_COLUMNS].describe()\n",
        "print(desc)\n",
        "MEAN = np.array(desc.T[\"mean\"])\n",
        "STD = np.array(desc.T[\"std\"])\n",
        "\n",
        "#sys.exit(1)\n",
        "\n",
        "normalizer = functools.partial(normalize_numeric_data, mean=MEAN, std=STD)\n",
        "\n",
        "numeric_column = tf.feature_column.numeric_column(\"numeric\", normalizer_fn=normalizer, shape=[len(NUMERIC_COLUMNS)])\n",
        "numeric_columns = [numeric_column]\n",
        "#print(\"Before\")\n",
        "#print(example_batch[\"numeric\"])\n",
        "\n",
        "numeric_layer = tf.keras.layers.DenseFeatures(numeric_columns)\n",
        "#print(\"After\")\n",
        "#print(numeric_layer(example_batch).numpy())\n",
        "\n",
        "# enumerate categorical columns\n",
        "CATEGORIES = {\n",
        "    \"famhist\" : [\"Absent\", \"Present\"]\n",
        "}\n",
        "\n",
        "categorical_columns = []\n",
        "for feature, vocab in CATEGORIES.items():\n",
        "    cat_col = tf.feature_column.categorical_column_with_vocabulary_list(  \n",
        "              key=feature, vocabulary_list=vocab)\n",
        "    categorical_columns.append(tf.feature_column.indicator_column(cat_col))\n",
        "\n",
        "#categorical_layer = tf.keras.layers.DenseFeatures(categorical_columns)\n",
        "#print(categorical_layer(example_batch).numpy())\n",
        "#sys.exit(0)\n",
        "\n",
        "preprocessing_layer = tf.keras.layers.DenseFeatures(categorical_columns + numeric_columns)\n",
        "print(preprocessing_layer(example_batch).numpy())\n",
        "#print(labels_batch)\n",
        "\n",
        "train_data = packed_train_data.shuffle(500)\n",
        "#train_data = preprocessing_layer(.numpy())\n",
        "test_data = packed_test_data\n",
        "\n",
        "\n",
        "\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "369\n",
            "93\n",
            "WARNING:tensorflow:From /tensorflow-2.0.0/python3.6/tensorflow_core/python/data/experimental/ops/readers.py:521: parallel_interleave (from tensorflow.python.data.experimental.ops.interleave_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use `tf.data.Dataset.interleave(map_func, cycle_length, block_length, num_parallel_calls=tf.data.experimental.AUTOTUNE)` instead. If sloppy execution is desired, use `tf.data.Options.experimental_determinstic`.\n",
            "famhist             : [[b'Absent']\n",
            " [b'Present']\n",
            " [b'Absent']\n",
            " [b'Absent']\n",
            " [b'Absent']\n",
            " [b'Present']\n",
            " [b'Present']\n",
            " [b'Absent']\n",
            " [b'Present']\n",
            " [b'Present']]\n",
            "numeric             : [[[1.5200e+02 5.9900e+00 7.9900e+00 3.2480e+01 4.5000e+01 2.6570e+01\n",
            "   1.0032e+02 4.8000e+01]]\n",
            "\n",
            " [[1.4600e+02 5.0800e+00 7.0300e+00 2.7410e+01 6.3000e+01 3.6460e+01\n",
            "   2.4480e+01 3.7000e+01]]\n",
            "\n",
            " [[1.5400e+02 7.0000e-01 5.9100e+00 2.5000e+01 1.3000e+01 2.0600e+01\n",
            "   0.0000e+00 4.2000e+01]]\n",
            "\n",
            " [[1.5200e+02 1.9450e+01 4.2200e+00 2.9810e+01 2.8000e+01 2.3950e+01\n",
            "   0.0000e+00 5.9000e+01]]\n",
            "\n",
            " [[1.2700e+02 0.0000e+00 2.8100e+00 1.5700e+01 4.2000e+01 2.2030e+01\n",
            "   1.0300e+00 1.7000e+01]]\n",
            "\n",
            " [[1.2600e+02 9.0000e-02 5.0300e+00 1.3270e+01 5.0000e+01 1.7750e+01\n",
            "   4.6300e+00 2.0000e+01]]\n",
            "\n",
            " [[1.3000e+02 5.0000e-02 2.4400e+00 2.8250e+01 6.7000e+01 3.0860e+01\n",
            "   4.0320e+01 3.4000e+01]]\n",
            "\n",
            " [[1.3400e+02 0.0000e+00 5.9000e+00 3.0840e+01 4.9000e+01 2.9160e+01\n",
            "   0.0000e+00 5.5000e+01]]\n",
            "\n",
            " [[1.1800e+02 8.0000e-02 3.4800e+00 3.2280e+01 5.2000e+01 2.9140e+01\n",
            "   3.8100e+00 4.6000e+01]]\n",
            "\n",
            " [[1.3200e+02 0.0000e+00 6.6300e+00 2.9580e+01 3.7000e+01 2.9410e+01\n",
            "   2.5700e+00 6.2000e+01]]]\n",
            "OrderedDict([('famhist', <tf.Tensor: id=226, shape=(10, 1), dtype=string, numpy=\n",
            "array([[b'Absent'],\n",
            "       [b'Present'],\n",
            "       [b'Absent'],\n",
            "       [b'Absent'],\n",
            "       [b'Present'],\n",
            "       [b'Absent'],\n",
            "       [b'Present'],\n",
            "       [b'Absent'],\n",
            "       [b'Present'],\n",
            "       [b'Absent']], dtype=object)>), ('numeric', <tf.Tensor: id=227, shape=(10, 1, 8), dtype=float32, numpy=\n",
            "array([[[206.  ,   0.  ,   4.17,  33.23,  69.  ,  27.36,   6.17,  50.  ]],\n",
            "\n",
            "       [[188.  ,   0.  ,   5.47,  32.44,  71.  ,  28.99,   7.41,  50.  ]],\n",
            "\n",
            "       [[146.  ,   1.35,   6.39,  34.21,  51.  ,  26.43,   0.  ,  59.  ]],\n",
            "\n",
            "       [[138.  ,   0.87,   1.87,  15.89,  44.  ,  26.76,  42.99,  31.  ]],\n",
            "\n",
            "       [[118.  ,   1.05,   3.16,  12.98,  46.  ,  22.09,  16.35,  31.  ]],\n",
            "\n",
            "       [[148.  ,   4.5 ,  10.49,  33.27,  50.  ,  25.92,   2.06,  53.  ]],\n",
            "\n",
            "       [[124.  ,   0.61,   2.69,  17.15,  61.  ,  22.76,  11.55,  20.  ]],\n",
            "\n",
            "       [[120.  ,   0.  ,   3.68,  12.24,  51.  ,  20.52,   0.51,  20.  ]],\n",
            "\n",
            "       [[118.  ,   1.25,   4.69,  31.58,  52.  ,  27.16,   4.11,  53.  ]],\n",
            "\n",
            "       [[126.  ,  10.5 ,   4.49,  17.33,  67.  ,  19.37,   0.  ,  49.  ]]],\n",
            "      dtype=float32)>)])\n",
            "              sbp     tobacco         ldl  ...     obesity     alcohol         age\n",
            "count  369.000000  369.000000  369.000000  ...  369.000000  369.000000  369.000000\n",
            "mean   138.818428    3.796504    4.785474  ...   26.041274   17.706423   43.555556\n",
            "std     21.265713    4.758530    2.099181  ...    4.096126   25.539654   14.591085\n",
            "min    101.000000    0.000000    0.980000  ...   14.700000    0.000000   15.000000\n",
            "25%    124.000000    0.100000    3.280000  ...   23.110000    0.510000   32.000000\n",
            "50%    134.000000    2.200000    4.370000  ...   25.870000    7.710000   45.000000\n",
            "75%    150.000000    5.600000    5.810000  ...   28.110000   23.970000   57.000000\n",
            "max    218.000000   31.200000   15.330000  ...   46.580000  147.190000   64.000000\n",
            "\n",
            "[8 rows x 8 columns]\n",
            "WARNING:tensorflow:From /tensorflow-2.0.0/python3.6/tensorflow_core/python/feature_column/feature_column_v2.py:4276: IndicatorColumn._variable_shape (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "WARNING:tensorflow:From /tensorflow-2.0.0/python3.6/tensorflow_core/python/feature_column/feature_column_v2.py:4331: VocabularyListCategoricalColumn._num_buckets (from tensorflow.python.feature_column.feature_column_v2) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "The old _FeatureColumn APIs are being deprecated. Please use the new FeatureColumn APIs instead.\n",
            "[[ 1.          0.          3.1591494  -0.7978312  -0.29319733  1.0221474\n",
            "   1.574784    0.32194504 -0.45170632  0.44166988]\n",
            " [ 0.          1.          2.3127165  -0.7978312   0.3260917   0.917693\n",
            "   1.770472    0.71988183 -0.40315437  0.44166988]\n",
            " [ 1.          0.          0.33770627 -0.5141302   0.7643579   1.1517235\n",
            "  -0.18640718  0.09490117 -0.6932914   1.0584849 ]\n",
            " [ 1.          0.         -0.03848616 -0.6150016  -1.3888628  -1.2705572\n",
            "  -0.8713149   0.17546509  0.9899734  -0.86049515]\n",
            " [ 0.          1.         -0.9789672  -0.57717484 -0.77433735 -1.6553191\n",
            "  -0.675627   -0.96463656 -0.05311045 -0.86049515]\n",
            " [ 1.          0.          0.43175438  0.1478389   2.7175007   1.0274364\n",
            "  -0.28425112 -0.02960677 -0.6126326   0.6472749 ]\n",
            " [ 0.          1.         -0.6968229  -0.6696403  -0.9982342  -1.1039593\n",
            "   0.7920324  -0.80106735 -0.24105349 -1.6143801 ]\n",
            " [ 1.          0.         -0.8849191  -0.7978312  -0.5266217  -1.7531623\n",
            "  -0.18640718 -1.3479254  -0.67332244 -1.6143801 ]\n",
            " [ 0.          1.         -0.9789672  -0.53514504 -0.04548166  0.8039835\n",
            "  -0.08856322  0.27311823 -0.53236514  0.6472749 ]\n",
            " [ 1.          0.         -0.6027748   1.4087323  -0.14075705 -1.0801595\n",
            "   1.3790962  -1.6286784  -0.6932914   0.37313488]]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c7lytA6da1OW",
        "colab_type": "text"
      },
      "source": [
        "# Create and Train Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBo9wotqnEmJ",
        "colab_type": "text"
      },
      "source": [
        "# Base Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D--O6Y2tawIU",
        "colab_type": "code",
        "outputId": "380ff4c0-9269-4692-edeb-564a8c5798bc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "def create_base_model():\n",
        "    model = tf.keras.Sequential([\n",
        "      preprocessing_layer,\n",
        "      tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(128, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ])\n",
        "\n",
        "    lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay( \n",
        "                  0.001,\n",
        "                  decay_steps=STEPS_PER_EPOCH*1000,\n",
        "                  decay_rate=1,\n",
        "                  staircase=False)\n",
        "    \n",
        "\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=tf.keras.optimizers.Adam(lr_schedule),\n",
        "        metrics=[\"accuracy\", \"binary_crossentropy\"]\n",
        "    )\n",
        "\n",
        "    \n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "train_model = create_base_model()\n",
        "base_model_path = \"/content/drive/My Drive/base_model_heart/base_heart_model.ckpt\"\n",
        "\n",
        "\n",
        "# train model\n",
        "print(\"--Fit model--\")\n",
        "val_loss_callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", verbose=1, patience=100, min_delta=0.001)\n",
        "checkpoint_val = tf.keras.callbacks.ModelCheckpoint(base_model_path, monitor=\"val_accuracy\", mode=\"max\", save_best_only=True, save_weights_only=True, verbose=1)\n",
        "log_name = \"sizes/Base\"\n",
        "tb_log = tf.keras.callbacks.TensorBoard(logdir/log_name)\n",
        "#checkpoint_train = tf.keras.callbacks.ModelCheckpoint(\"base_heart_model.h5\", monitor=\"loss\", mode=\"min\", save_best_only=True, save_weights_only=True, verbose=1)\n",
        "cb = [val_loss_callback, checkpoint_val, tb_log]\n",
        "\n",
        "train_history = train_model.fit(\n",
        "    train_data,\n",
        "    epochs=99999999999, \n",
        "    verbose=1, \n",
        "    validation_data=test_data, \n",
        "    callbacks=cb,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH)\n",
        "\n",
        "model_histories = {}\n",
        "model_histories[\"Base\"] = train_history\n",
        "\n",
        "plotter = tfdocs.plots.HistoryPlotter(metric='accuracy')\n",
        "plotter.plot(model_histories)\n",
        "plt.ylim([0.4, 1.0])\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--Fit model--\n",
            "Train for 36 steps\n",
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', functools.partial(<function normalize_numeric_data at 0x7f9f81de2488>, mean=array([138.81842818,   3.79650407,   4.78547425,  25.49937669,\n",
            "        52.90514905,  26.04127371,  17.70642276,  43.55555556]), std=array([21.26571252,  4.75853044,  2.09918096,  7.56312   , 10.22035483,\n",
            "        4.09612605, 25.53965407, 14.5910849 ])))\n",
            "Epoch 1/99999999999\n",
            "29/36 [=======================>......] - ETA: 0s - loss: 0.6027 - accuracy: 0.6862 - binary_crossentropy: 0.6027\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.72043, saving model to /content/drive/My Drive/base_model_heart/base_heart_model.ckpt\n",
            "36/36 [==============================] - 3s 81ms/step - loss: 0.5794 - accuracy: 0.7056 - binary_crossentropy: 0.5794 - val_loss: 0.5367 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5323\n",
            "Epoch 2/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.4938 - accuracy: 0.7000 - binary_crossentropy: 0.4938\n",
            "Epoch 00002: val_accuracy improved from 0.72043 to 0.73118, saving model to /content/drive/My Drive/base_model_heart/base_heart_model.ckpt\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.5257 - accuracy: 0.7528 - binary_crossentropy: 0.5322 - val_loss: 0.5229 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.5276\n",
            "Epoch 3/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4704 - accuracy: 0.8111 - binary_crossentropy: 0.4704\n",
            "Epoch 00003: val_accuracy did not improve from 0.73118\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.5068 - accuracy: 0.7667 - binary_crossentropy: 0.5154 - val_loss: 0.5434 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5522\n",
            "Epoch 4/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.7815 - accuracy: 0.4000 - binary_crossentropy: 0.7815\n",
            "Epoch 00004: val_accuracy did not improve from 0.73118\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.5245 - accuracy: 0.7556 - binary_crossentropy: 0.4812 - val_loss: 0.5433 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5616\n",
            "Epoch 5/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.4098 - accuracy: 0.8000 - binary_crossentropy: 0.4098\n",
            "Epoch 00005: val_accuracy improved from 0.73118 to 0.75269, saving model to /content/drive/My Drive/base_model_heart/base_heart_model.ckpt\n",
            "36/10 [============================================================================================================] - 0s 11ms/step - loss: 0.4943 - accuracy: 0.7750 - binary_crossentropy: 0.4353 - val_loss: 0.5873 - val_accuracy: 0.7527 - val_binary_crossentropy: 0.5484\n",
            "Epoch 6/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.3121 - accuracy: 0.8000 - binary_crossentropy: 0.3121\n",
            "Epoch 00006: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.3884 - accuracy: 0.7694 - binary_crossentropy: 0.4392 - val_loss: 0.5212 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.5307\n",
            "Epoch 7/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5425 - accuracy: 0.7333 - binary_crossentropy: 0.5425\n",
            "Epoch 00007: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.4136 - accuracy: 0.7500 - binary_crossentropy: 0.5071 - val_loss: 0.5448 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.5422\n",
            "Epoch 8/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.5510 - accuracy: 0.7000 - binary_crossentropy: 0.5510\n",
            "Epoch 00008: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.4698 - accuracy: 0.8222 - binary_crossentropy: 0.4136 - val_loss: 0.5358 - val_accuracy: 0.7419 - val_binary_crossentropy: 0.5525\n",
            "Epoch 9/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4222 - accuracy: 0.7750 - binary_crossentropy: 0.4222\n",
            "Epoch 00009: val_accuracy improved from 0.75269 to 0.76344, saving model to /content/drive/My Drive/base_model_heart/base_heart_model.ckpt\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.4131 - accuracy: 0.7667 - binary_crossentropy: 0.4331 - val_loss: 0.5405 - val_accuracy: 0.7634 - val_binary_crossentropy: 0.5563\n",
            "Epoch 10/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.2725 - accuracy: 0.8000 - binary_crossentropy: 0.2725\n",
            "Epoch 00010: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.3901 - accuracy: 0.8167 - binary_crossentropy: 0.4073 - val_loss: 0.5603 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.5954\n",
            "Epoch 11/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.3442 - accuracy: 0.9000 - binary_crossentropy: 0.3442\n",
            "Epoch 00011: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.3530 - accuracy: 0.7972 - binary_crossentropy: 0.4215 - val_loss: 0.6372 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.5690\n",
            "Epoch 12/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.5678 - accuracy: 0.6000 - binary_crossentropy: 0.5678\n",
            "Epoch 00012: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.3471 - accuracy: 0.7833 - binary_crossentropy: 0.4217 - val_loss: 0.5794 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.5809\n",
            "Epoch 13/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.4990 - accuracy: 0.8000 - binary_crossentropy: 0.4990\n",
            "Epoch 00013: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.4786 - accuracy: 0.8139 - binary_crossentropy: 0.4336 - val_loss: 0.6231 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.5730\n",
            "Epoch 14/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.6865 - accuracy: 0.6000 - binary_crossentropy: 0.6865\n",
            "Epoch 00014: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.3715 - accuracy: 0.8417 - binary_crossentropy: 0.4012 - val_loss: 0.5666 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.5980\n",
            "Epoch 15/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.3110 - accuracy: 1.0000 - binary_crossentropy: 0.3110\n",
            "Epoch 00015: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.3361 - accuracy: 0.8083 - binary_crossentropy: 0.4217 - val_loss: 0.6285 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.5828\n",
            "Epoch 16/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1758 - accuracy: 1.0000 - binary_crossentropy: 0.1758\n",
            "Epoch 00016: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2876 - accuracy: 0.8306 - binary_crossentropy: 0.3638 - val_loss: 0.5493 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.5816\n",
            "Epoch 17/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3243 - accuracy: 0.8444 - binary_crossentropy: 0.3243\n",
            "Epoch 00017: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.5043 - accuracy: 0.8389 - binary_crossentropy: 0.3724 - val_loss: 0.5744 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.5968\n",
            "Epoch 18/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.3145 - accuracy: 1.0000 - binary_crossentropy: 0.3145\n",
            "Epoch 00018: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.3818 - accuracy: 0.8222 - binary_crossentropy: 0.4132 - val_loss: 0.5648 - val_accuracy: 0.7634 - val_binary_crossentropy: 0.5878\n",
            "Epoch 19/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.2961 - accuracy: 0.9000 - binary_crossentropy: 0.2961\n",
            "Epoch 00019: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.3762 - accuracy: 0.8417 - binary_crossentropy: 0.3642 - val_loss: 0.5976 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.5685\n",
            "Epoch 20/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1335 - accuracy: 1.0000 - binary_crossentropy: 0.1335\n",
            "Epoch 00020: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.3310 - accuracy: 0.7944 - binary_crossentropy: 0.3891 - val_loss: 0.5860 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.6122\n",
            "Epoch 21/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3282 - accuracy: 0.9333 - binary_crossentropy: 0.3282\n",
            "Epoch 00021: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.3792 - accuracy: 0.8694 - binary_crossentropy: 0.3449 - val_loss: 0.5839 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5931\n",
            "Epoch 22/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3214 - accuracy: 0.8778 - binary_crossentropy: 0.3214\n",
            "Epoch 00022: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.4359 - accuracy: 0.8611 - binary_crossentropy: 0.3454 - val_loss: 0.6614 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.5974\n",
            "Epoch 23/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.2634 - accuracy: 0.9000 - binary_crossentropy: 0.2634\n",
            "Epoch 00023: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2869 - accuracy: 0.8528 - binary_crossentropy: 0.3327 - val_loss: 0.5756 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.6037\n",
            "Epoch 24/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.2277 - accuracy: 0.9000 - binary_crossentropy: 0.2277\n",
            "Epoch 00024: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2914 - accuracy: 0.8833 - binary_crossentropy: 0.3081 - val_loss: 0.6514 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.6332\n",
            "Epoch 25/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3661 - accuracy: 0.8222 - binary_crossentropy: 0.3661\n",
            "Epoch 00025: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.3363 - accuracy: 0.8500 - binary_crossentropy: 0.3559 - val_loss: 0.6080 - val_accuracy: 0.7419 - val_binary_crossentropy: 0.6034\n",
            "Epoch 26/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3138 - accuracy: 0.8444 - binary_crossentropy: 0.3138\n",
            "Epoch 00026: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3106 - accuracy: 0.8667 - binary_crossentropy: 0.3099 - val_loss: 0.5780 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.6159\n",
            "Epoch 27/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.2838 - accuracy: 0.9000 - binary_crossentropy: 0.2838\n",
            "Epoch 00027: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.3459 - accuracy: 0.8694 - binary_crossentropy: 0.3040 - val_loss: 0.6011 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.6219\n",
            "Epoch 28/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.2934 - accuracy: 0.8778 - binary_crossentropy: 0.2934\n",
            "Epoch 00028: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2530 - accuracy: 0.8833 - binary_crossentropy: 0.2681 - val_loss: 0.5989 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.6309\n",
            "Epoch 29/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.2676 - accuracy: 0.9111 - binary_crossentropy: 0.2676\n",
            "Epoch 00029: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2515 - accuracy: 0.9139 - binary_crossentropy: 0.2658 - val_loss: 0.6575 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.6265\n",
            "Epoch 30/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1776 - accuracy: 0.9667 - binary_crossentropy: 0.1776\n",
            "Epoch 00030: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1799 - accuracy: 0.9333 - binary_crossentropy: 0.2155 - val_loss: 0.7350 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.6626\n",
            "Epoch 31/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.7768 - accuracy: 0.6000 - binary_crossentropy: 0.7768\n",
            "Epoch 00031: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2473 - accuracy: 0.9028 - binary_crossentropy: 0.2765 - val_loss: 0.6308 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.6482\n",
            "Epoch 32/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.2860 - accuracy: 0.9111 - binary_crossentropy: 0.2860\n",
            "Epoch 00032: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2867 - accuracy: 0.8861 - binary_crossentropy: 0.2691 - val_loss: 0.6347 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.6594\n",
            "Epoch 33/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1475 - accuracy: 1.0000 - binary_crossentropy: 0.1475\n",
            "Epoch 00033: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2518 - accuracy: 0.9056 - binary_crossentropy: 0.2662 - val_loss: 0.6667 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.6425\n",
            "Epoch 34/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.2767 - accuracy: 0.9000 - binary_crossentropy: 0.2767\n",
            "Epoch 00034: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.2258 - accuracy: 0.8972 - binary_crossentropy: 0.2730 - val_loss: 0.6047 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.6418\n",
            "Epoch 35/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.4593 - accuracy: 0.9000 - binary_crossentropy: 0.4593\n",
            "Epoch 00035: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2100 - accuracy: 0.9222 - binary_crossentropy: 0.2341 - val_loss: 0.7057 - val_accuracy: 0.6667 - val_binary_crossentropy: 0.6454\n",
            "Epoch 36/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1763 - accuracy: 1.0000 - binary_crossentropy: 0.1763\n",
            "Epoch 00036: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2035 - accuracy: 0.9278 - binary_crossentropy: 0.2108 - val_loss: 0.7425 - val_accuracy: 0.6452 - val_binary_crossentropy: 0.7427\n",
            "Epoch 37/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.2125 - accuracy: 0.9444 - binary_crossentropy: 0.2125\n",
            "Epoch 00037: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2014 - accuracy: 0.9278 - binary_crossentropy: 0.2090 - val_loss: 0.6793 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.6853\n",
            "Epoch 38/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.2006 - accuracy: 0.9000 - binary_crossentropy: 0.2006\n",
            "Epoch 00038: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2322 - accuracy: 0.9111 - binary_crossentropy: 0.2248 - val_loss: 0.6693 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.6855\n",
            "Epoch 39/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0776 - accuracy: 1.0000 - binary_crossentropy: 0.0776\n",
            "Epoch 00039: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.4827 - accuracy: 0.9222 - binary_crossentropy: 0.2151 - val_loss: 0.6456 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.6736\n",
            "Epoch 40/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.2157 - accuracy: 0.9000 - binary_crossentropy: 0.2157\n",
            "Epoch 00040: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.2082 - accuracy: 0.9361 - binary_crossentropy: 0.1902 - val_loss: 0.6556 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.6754\n",
            "Epoch 41/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0935 - accuracy: 1.0000 - binary_crossentropy: 0.0935\n",
            "Epoch 00041: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1699 - accuracy: 0.9444 - binary_crossentropy: 0.1701 - val_loss: 0.6336 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.6804\n",
            "Epoch 42/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.2164 - accuracy: 0.9111 - binary_crossentropy: 0.2164\n",
            "Epoch 00042: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.1720 - accuracy: 0.9389 - binary_crossentropy: 0.2032 - val_loss: 0.6621 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.7027\n",
            "Epoch 43/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.3217 - accuracy: 0.9000 - binary_crossentropy: 0.3217\n",
            "Epoch 00043: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2462 - accuracy: 0.9306 - binary_crossentropy: 0.1964 - val_loss: 0.7184 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.6828\n",
            "Epoch 44/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.2813 - accuracy: 0.9000 - binary_crossentropy: 0.2813\n",
            "Epoch 00044: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2543 - accuracy: 0.9389 - binary_crossentropy: 0.1931 - val_loss: 0.6327 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.6681\n",
            "Epoch 45/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1782 - accuracy: 0.9000 - binary_crossentropy: 0.1782\n",
            "Epoch 00045: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1840 - accuracy: 0.9444 - binary_crossentropy: 0.1837 - val_loss: 0.6701 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.7158\n",
            "Epoch 46/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.2936 - accuracy: 0.9000 - binary_crossentropy: 0.2936\n",
            "Epoch 00046: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2859 - accuracy: 0.9444 - binary_crossentropy: 0.1576 - val_loss: 0.7925 - val_accuracy: 0.6667 - val_binary_crossentropy: 0.7601\n",
            "Epoch 47/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.1472 - accuracy: 0.9625 - binary_crossentropy: 0.1472\n",
            "Epoch 00047: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1441 - accuracy: 0.9444 - binary_crossentropy: 0.1766 - val_loss: 0.7833 - val_accuracy: 0.6667 - val_binary_crossentropy: 0.7821\n",
            "Epoch 48/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.2425 - accuracy: 0.9000 - binary_crossentropy: 0.2425\n",
            "Epoch 00048: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2133 - accuracy: 0.9333 - binary_crossentropy: 0.1943 - val_loss: 0.8164 - val_accuracy: 0.6667 - val_binary_crossentropy: 0.8478\n",
            "Epoch 49/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.2837 - accuracy: 0.9000 - binary_crossentropy: 0.2837\n",
            "Epoch 00049: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1722 - accuracy: 0.9389 - binary_crossentropy: 0.1700 - val_loss: 0.7279 - val_accuracy: 0.6559 - val_binary_crossentropy: 0.7433\n",
            "Epoch 50/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1371 - accuracy: 1.0000 - binary_crossentropy: 0.1371\n",
            "Epoch 00050: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1500 - accuracy: 0.9389 - binary_crossentropy: 0.1580 - val_loss: 0.7670 - val_accuracy: 0.6667 - val_binary_crossentropy: 0.7814\n",
            "Epoch 51/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0393 - accuracy: 1.0000 - binary_crossentropy: 0.0393\n",
            "Epoch 00051: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1424 - accuracy: 0.9472 - binary_crossentropy: 0.1433 - val_loss: 0.7830 - val_accuracy: 0.6667 - val_binary_crossentropy: 0.7713\n",
            "Epoch 52/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1633 - accuracy: 1.0000 - binary_crossentropy: 0.1633\n",
            "Epoch 00052: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1754 - accuracy: 0.9667 - binary_crossentropy: 0.1341 - val_loss: 0.7799 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.7645\n",
            "Epoch 53/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0828 - accuracy: 1.0000 - binary_crossentropy: 0.0828\n",
            "Epoch 00053: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1638 - accuracy: 0.9472 - binary_crossentropy: 0.1493 - val_loss: 0.8299 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.8061\n",
            "Epoch 54/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0906 - accuracy: 0.9778 - binary_crossentropy: 0.0906\n",
            "Epoch 00054: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0892 - accuracy: 0.9833 - binary_crossentropy: 0.0959 - val_loss: 0.8408 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.8722\n",
            "Epoch 55/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0913 - accuracy: 0.9667 - binary_crossentropy: 0.0913\n",
            "Epoch 00055: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1183 - accuracy: 0.9694 - binary_crossentropy: 0.1172 - val_loss: 0.7147 - val_accuracy: 0.6559 - val_binary_crossentropy: 0.7678\n",
            "Epoch 56/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0850 - accuracy: 1.0000 - binary_crossentropy: 0.0850\n",
            "Epoch 00056: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0942 - accuracy: 0.9861 - binary_crossentropy: 0.0997 - val_loss: 0.7897 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.8004\n",
            "Epoch 57/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1322 - accuracy: 0.9000 - binary_crossentropy: 0.1322\n",
            "Epoch 00057: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1043 - accuracy: 0.9833 - binary_crossentropy: 0.0996 - val_loss: 0.8309 - val_accuracy: 0.6667 - val_binary_crossentropy: 0.8642\n",
            "Epoch 58/99999999999\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.0861 - accuracy: 0.9857 - binary_crossentropy: 0.0861\n",
            "Epoch 00058: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.0843 - accuracy: 0.9861 - binary_crossentropy: 0.0890 - val_loss: 0.8563 - val_accuracy: 0.6667 - val_binary_crossentropy: 0.8288\n",
            "Epoch 59/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0473 - accuracy: 1.0000 - binary_crossentropy: 0.0473\n",
            "Epoch 00059: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0991 - accuracy: 0.9806 - binary_crossentropy: 0.0918 - val_loss: 0.8640 - val_accuracy: 0.6559 - val_binary_crossentropy: 0.8921\n",
            "Epoch 60/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0745 - accuracy: 1.0000 - binary_crossentropy: 0.0745\n",
            "Epoch 00060: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0778 - accuracy: 0.9861 - binary_crossentropy: 0.0813 - val_loss: 0.7923 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.8506\n",
            "Epoch 61/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0842 - accuracy: 0.9889 - binary_crossentropy: 0.0842\n",
            "Epoch 00061: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0655 - accuracy: 0.9889 - binary_crossentropy: 0.0789 - val_loss: 0.8431 - val_accuracy: 0.6667 - val_binary_crossentropy: 0.8734\n",
            "Epoch 62/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0674 - accuracy: 1.0000 - binary_crossentropy: 0.0674\n",
            "Epoch 00062: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0557 - accuracy: 0.9944 - binary_crossentropy: 0.0815 - val_loss: 0.8588 - val_accuracy: 0.6452 - val_binary_crossentropy: 0.8659\n",
            "Epoch 63/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0742 - accuracy: 1.0000 - binary_crossentropy: 0.0742\n",
            "Epoch 00063: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0787 - accuracy: 0.9861 - binary_crossentropy: 0.0706 - val_loss: 0.9234 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.9236\n",
            "Epoch 64/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0666 - accuracy: 1.0000 - binary_crossentropy: 0.0666\n",
            "Epoch 00064: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0848 - accuracy: 0.9861 - binary_crossentropy: 0.0699 - val_loss: 0.8966 - val_accuracy: 0.6667 - val_binary_crossentropy: 0.8947\n",
            "Epoch 65/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0759 - accuracy: 1.0000 - binary_crossentropy: 0.0759\n",
            "Epoch 00065: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0631 - accuracy: 0.9917 - binary_crossentropy: 0.0662 - val_loss: 0.9986 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.9492\n",
            "Epoch 66/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0834 - accuracy: 0.9889 - binary_crossentropy: 0.0834\n",
            "Epoch 00066: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0716 - accuracy: 0.9917 - binary_crossentropy: 0.0721 - val_loss: 0.9263 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.9178\n",
            "Epoch 67/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.0685 - accuracy: 0.9875 - binary_crossentropy: 0.0685\n",
            "Epoch 00067: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0518 - accuracy: 0.9889 - binary_crossentropy: 0.0588 - val_loss: 1.1477 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.0239\n",
            "Epoch 68/99999999999\n",
            " 6/10 [=================>............] - ETA: 0s - loss: 0.0818 - accuracy: 0.9667 - binary_crossentropy: 0.0818\n",
            "Epoch 00068: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0640 - accuracy: 0.9917 - binary_crossentropy: 0.0687 - val_loss: 0.8854 - val_accuracy: 0.6667 - val_binary_crossentropy: 0.9294\n",
            "Epoch 69/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0508 - accuracy: 1.0000 - binary_crossentropy: 0.0508\n",
            "Epoch 00069: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.0566 - accuracy: 1.0000 - binary_crossentropy: 0.0488 - val_loss: 0.9031 - val_accuracy: 0.6559 - val_binary_crossentropy: 0.9414\n",
            "Epoch 70/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0405 - accuracy: 1.0000 - binary_crossentropy: 0.0405\n",
            "Epoch 00070: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0519 - accuracy: 0.9972 - binary_crossentropy: 0.0528 - val_loss: 1.0436 - val_accuracy: 0.6559 - val_binary_crossentropy: 1.0689\n",
            "Epoch 71/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.0857 - accuracy: 0.9875 - binary_crossentropy: 0.0857\n",
            "Epoch 00071: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0559 - accuracy: 0.9889 - binary_crossentropy: 0.0614 - val_loss: 0.9493 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.9816\n",
            "Epoch 72/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0479 - accuracy: 1.0000 - binary_crossentropy: 0.0479\n",
            "Epoch 00072: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0601 - accuracy: 0.9972 - binary_crossentropy: 0.0457 - val_loss: 0.9711 - val_accuracy: 0.6559 - val_binary_crossentropy: 0.9719\n",
            "Epoch 73/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0487 - accuracy: 1.0000 - binary_crossentropy: 0.0487\n",
            "Epoch 00073: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0286 - accuracy: 0.9944 - binary_crossentropy: 0.0481 - val_loss: 0.9373 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.9364\n",
            "Epoch 74/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0238 - accuracy: 1.0000 - binary_crossentropy: 0.0238\n",
            "Epoch 00074: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0318 - accuracy: 1.0000 - binary_crossentropy: 0.0407 - val_loss: 0.9812 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.9670\n",
            "Epoch 75/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0160 - accuracy: 1.0000 - binary_crossentropy: 0.0160\n",
            "Epoch 00075: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0382 - accuracy: 0.9972 - binary_crossentropy: 0.0489 - val_loss: 1.0647 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.9846\n",
            "Epoch 76/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0177 - accuracy: 1.0000 - binary_crossentropy: 0.0177\n",
            "Epoch 00076: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0407 - accuracy: 1.0000 - binary_crossentropy: 0.0361 - val_loss: 1.1701 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.0596\n",
            "Epoch 77/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0352 - accuracy: 1.0000 - binary_crossentropy: 0.0352\n",
            "Epoch 00077: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0562 - accuracy: 0.9972 - binary_crossentropy: 0.0317 - val_loss: 1.1415 - val_accuracy: 0.6989 - val_binary_crossentropy: 1.0215\n",
            "Epoch 78/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.0430 - accuracy: 1.0000 - binary_crossentropy: 0.0430\n",
            "Epoch 00078: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.0368 - accuracy: 1.0000 - binary_crossentropy: 0.0371 - val_loss: 1.0588 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.0768\n",
            "Epoch 79/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0327 - accuracy: 1.0000 - binary_crossentropy: 0.0327\n",
            "Epoch 00079: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0319 - accuracy: 1.0000 - binary_crossentropy: 0.0299 - val_loss: 1.0957 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.0922\n",
            "Epoch 80/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0319 - accuracy: 1.0000 - binary_crossentropy: 0.0319\n",
            "Epoch 00080: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0342 - accuracy: 1.0000 - binary_crossentropy: 0.0348 - val_loss: 1.0337 - val_accuracy: 0.6667 - val_binary_crossentropy: 1.1114\n",
            "Epoch 81/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0582 - accuracy: 1.0000 - binary_crossentropy: 0.0582\n",
            "Epoch 00081: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0265 - accuracy: 1.0000 - binary_crossentropy: 0.0278 - val_loss: 1.0770 - val_accuracy: 0.6989 - val_binary_crossentropy: 1.0854\n",
            "Epoch 82/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.0383 - accuracy: 1.0000 - binary_crossentropy: 0.0383\n",
            "Epoch 00082: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0251 - accuracy: 0.9972 - binary_crossentropy: 0.0300 - val_loss: 1.2934 - val_accuracy: 0.6452 - val_binary_crossentropy: 1.2401\n",
            "Epoch 83/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0497 - accuracy: 0.9889 - binary_crossentropy: 0.0497\n",
            "Epoch 00083: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0447 - accuracy: 0.9944 - binary_crossentropy: 0.0396 - val_loss: 1.2677 - val_accuracy: 0.6022 - val_binary_crossentropy: 1.3112\n",
            "Epoch 84/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0744 - accuracy: 1.0000 - binary_crossentropy: 0.0744\n",
            "Epoch 00084: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 7ms/step - loss: 0.0586 - accuracy: 1.0000 - binary_crossentropy: 0.0367 - val_loss: 1.1135 - val_accuracy: 0.6882 - val_binary_crossentropy: 1.1455\n",
            "Epoch 85/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0198 - accuracy: 1.0000 - binary_crossentropy: 0.0198\n",
            "Epoch 00085: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0225 - accuracy: 1.0000 - binary_crossentropy: 0.0235 - val_loss: 1.0951 - val_accuracy: 0.6989 - val_binary_crossentropy: 1.1730\n",
            "Epoch 86/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0565 - accuracy: 1.0000 - binary_crossentropy: 0.0565\n",
            "Epoch 00086: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0255 - accuracy: 0.9917 - binary_crossentropy: 0.0330 - val_loss: 1.0708 - val_accuracy: 0.6559 - val_binary_crossentropy: 1.1459\n",
            "Epoch 87/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0211 - accuracy: 1.0000 - binary_crossentropy: 0.0211\n",
            "Epoch 00087: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0303 - accuracy: 1.0000 - binary_crossentropy: 0.0229 - val_loss: 1.2399 - val_accuracy: 0.6559 - val_binary_crossentropy: 1.2436\n",
            "Epoch 88/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0274 - accuracy: 1.0000 - binary_crossentropy: 0.0274\n",
            "Epoch 00088: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0340 - accuracy: 1.0000 - binary_crossentropy: 0.0242 - val_loss: 1.1654 - val_accuracy: 0.6989 - val_binary_crossentropy: 1.1696\n",
            "Epoch 89/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.0161 - accuracy: 1.0000 - binary_crossentropy: 0.0161\n",
            "Epoch 00089: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.0159 - accuracy: 1.0000 - binary_crossentropy: 0.0211 - val_loss: 1.1568 - val_accuracy: 0.6667 - val_binary_crossentropy: 1.1928\n",
            "Epoch 90/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0173 - accuracy: 1.0000 - binary_crossentropy: 0.0173\n",
            "Epoch 00090: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0171 - accuracy: 1.0000 - binary_crossentropy: 0.0191 - val_loss: 1.2506 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.1864\n",
            "Epoch 91/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0412 - accuracy: 1.0000 - binary_crossentropy: 0.0412\n",
            "Epoch 00091: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0233 - accuracy: 1.0000 - binary_crossentropy: 0.0212 - val_loss: 1.1249 - val_accuracy: 0.6452 - val_binary_crossentropy: 1.1988\n",
            "Epoch 92/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0062 - accuracy: 1.0000 - binary_crossentropy: 0.0062\n",
            "Epoch 00092: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0154 - accuracy: 1.0000 - binary_crossentropy: 0.0174 - val_loss: 1.3804 - val_accuracy: 0.6989 - val_binary_crossentropy: 1.2537\n",
            "Epoch 93/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0090 - accuracy: 1.0000 - binary_crossentropy: 0.0090\n",
            "Epoch 00093: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0145 - accuracy: 1.0000 - binary_crossentropy: 0.0165 - val_loss: 1.3685 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.2204\n",
            "Epoch 94/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0198 - accuracy: 1.0000 - binary_crossentropy: 0.0198\n",
            "Epoch 00094: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0189 - accuracy: 1.0000 - binary_crossentropy: 0.0192 - val_loss: 1.2150 - val_accuracy: 0.6344 - val_binary_crossentropy: 1.2656\n",
            "Epoch 95/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0177 - accuracy: 1.0000 - binary_crossentropy: 0.0177\n",
            "Epoch 00095: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0131 - accuracy: 1.0000 - binary_crossentropy: 0.0177 - val_loss: 1.1363 - val_accuracy: 0.6667 - val_binary_crossentropy: 1.2214\n",
            "Epoch 96/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.0235 - accuracy: 1.0000 - binary_crossentropy: 0.0235\n",
            "Epoch 00096: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.0245 - accuracy: 1.0000 - binary_crossentropy: 0.0175 - val_loss: 1.3164 - val_accuracy: 0.6882 - val_binary_crossentropy: 1.2657\n",
            "Epoch 97/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0186 - accuracy: 1.0000 - binary_crossentropy: 0.0186\n",
            "Epoch 00097: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0108 - accuracy: 1.0000 - binary_crossentropy: 0.0149 - val_loss: 1.1894 - val_accuracy: 0.6989 - val_binary_crossentropy: 1.2656\n",
            "Epoch 98/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0046 - accuracy: 1.0000 - binary_crossentropy: 0.0046\n",
            "Epoch 00098: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0268 - accuracy: 0.9972 - binary_crossentropy: 0.0196 - val_loss: 1.3008 - val_accuracy: 0.6989 - val_binary_crossentropy: 1.3039\n",
            "Epoch 99/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0136 - accuracy: 1.0000 - binary_crossentropy: 0.0136\n",
            "Epoch 00099: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.0138 - accuracy: 1.0000 - binary_crossentropy: 0.0135 - val_loss: 1.2577 - val_accuracy: 0.6667 - val_binary_crossentropy: 1.3491\n",
            "Epoch 100/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0155 - accuracy: 1.0000 - binary_crossentropy: 0.0155\n",
            "Epoch 00100: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0089 - accuracy: 1.0000 - binary_crossentropy: 0.0127 - val_loss: 1.2137 - val_accuracy: 0.6882 - val_binary_crossentropy: 1.3044\n",
            "Epoch 101/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0098 - accuracy: 1.0000 - binary_crossentropy: 0.0098\n",
            "Epoch 00101: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0080 - accuracy: 1.0000 - binary_crossentropy: 0.0115 - val_loss: 1.3586 - val_accuracy: 0.6882 - val_binary_crossentropy: 1.3575\n",
            "Epoch 102/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0083 - accuracy: 1.0000 - binary_crossentropy: 0.0083\n",
            "Epoch 00102: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0107 - accuracy: 1.0000 - binary_crossentropy: 0.0098 - val_loss: 1.2391 - val_accuracy: 0.6989 - val_binary_crossentropy: 1.2641\n",
            "Epoch 103/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.0085 - accuracy: 1.0000 - binary_crossentropy: 0.0085\n",
            "Epoch 00103: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0088 - accuracy: 1.0000 - binary_crossentropy: 0.0094 - val_loss: 1.2316 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.3160\n",
            "Epoch 104/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0203 - accuracy: 1.0000 - binary_crossentropy: 0.0203\n",
            "Epoch 00104: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.0125 - accuracy: 1.0000 - binary_crossentropy: 0.0104 - val_loss: 1.4588 - val_accuracy: 0.6667 - val_binary_crossentropy: 1.3821\n",
            "Epoch 105/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0099 - accuracy: 1.0000 - binary_crossentropy: 0.0099\n",
            "Epoch 00105: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0131 - accuracy: 1.0000 - binary_crossentropy: 0.0110 - val_loss: 1.3806 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.3377\n",
            "Epoch 106/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0113 - accuracy: 1.0000 - binary_crossentropy: 0.0113\n",
            "Epoch 00106: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0063 - accuracy: 1.0000 - binary_crossentropy: 0.0091 - val_loss: 1.2842 - val_accuracy: 0.6989 - val_binary_crossentropy: 1.3586\n",
            "Epoch 107/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.0119 - accuracy: 1.0000 - binary_crossentropy: 0.0119\n",
            "Epoch 00107: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.0090 - accuracy: 1.0000 - binary_crossentropy: 0.0094 - val_loss: 1.2597 - val_accuracy: 0.6989 - val_binary_crossentropy: 1.3320\n",
            "Epoch 108/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0100 - accuracy: 1.0000 - binary_crossentropy: 0.0100\n",
            "Epoch 00108: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0227 - accuracy: 1.0000 - binary_crossentropy: 0.0088 - val_loss: 1.2671 - val_accuracy: 0.6989 - val_binary_crossentropy: 1.3321\n",
            "Epoch 109/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0068 - accuracy: 1.0000 - binary_crossentropy: 0.0068\n",
            "Epoch 00109: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0085 - accuracy: 1.0000 - binary_crossentropy: 0.0096 - val_loss: 1.2832 - val_accuracy: 0.6667 - val_binary_crossentropy: 1.3791\n",
            "Epoch 00109: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/UaaI4Vs0iYAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "um2-2KiIUcIO",
        "colab_type": "text"
      },
      "source": [
        "# Model with l2 regularizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uQmBZ_KCRzqF",
        "colab_type": "code",
        "outputId": "11484ccf-4359-4602-ef44-ea5244a17a95",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras import regularizers\n",
        "\n",
        "def create_l2_model():\n",
        "    model = tf.keras.Sequential([\n",
        "      preprocessing_layer,\n",
        "      tf.keras.layers.Dense(128, activation=\"relu\",\n",
        "                            kernel_regularizer=regularizers.l2(0.001)),\n",
        "      tf.keras.layers.Dense(128, activation=\"relu\",\n",
        "                            kernel_regularizer=regularizers.l2(0.001)),   \n",
        "      tf.keras.layers.Dense(128, activation=\"relu\",\n",
        "                            kernel_regularizer=regularizers.l2(0.001)),                                   \n",
        "      tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ])\n",
        "\n",
        "    lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "                  0.001,\n",
        "                  decay_steps=STEPS_PER_EPOCH*1000,\n",
        "                  decay_rate=1,\n",
        "                  staircase=False)\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=tf.keras.optimizers.Adam(lr_schedule),\n",
        "        metrics=[\"accuracy\", \"binary_crossentropy\"]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "train_model = create_l2_model()\n",
        "l2_model_path = \"/content/drive/My Drive/l2_model_heart/l2_heart_model.ckpt\"\n",
        "\n",
        "\n",
        "# train model\n",
        "print(\"--Fit model--\")\n",
        "val_loss_callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", verbose=1, patience=100, min_delta=0.001)\n",
        "checkpoint_val = tf.keras.callbacks.ModelCheckpoint(l2_model_path, monitor=\"val_accuracy\", mode=\"max\", save_best_only=True, save_weights_only=True, verbose=1)\n",
        "log_name = \"sizes/l2\"\n",
        "tb_log = tf.keras.callbacks.TensorBoard(logdir/log_name)\n",
        "#checkpoint_train = tf.keras.callbacks.ModelCheckpoint(\"base_heart_model.h5\", monitor=\"loss\", mode=\"min\", save_best_only=True, save_weights_only=True, verbose=1)\n",
        "cb = [val_loss_callback, checkpoint_val, tb_log]\n",
        "\n",
        "train_history = train_model.fit(\n",
        "    train_data,\n",
        "    epochs=99999999999, \n",
        "    verbose=1, \n",
        "    validation_data=test_data, \n",
        "    callbacks=cb,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH)\n",
        "\n",
        "#model_histories = {}\n",
        "model_histories[\"l2\"] = train_history\n",
        "\n",
        "plotter = tfdocs.plots.HistoryPlotter(metric='accuracy')\n",
        "plotter.plot(model_histories)\n",
        "plt.ylim([0.4, 1.0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--Fit model--\n",
            "Train for 36 steps\n",
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', functools.partial(<function normalize_numeric_data at 0x7f9f81de2488>, mean=array([138.81842818,   3.79650407,   4.78547425,  25.49937669,\n",
            "        52.90514905,  26.04127371,  17.70642276,  43.55555556]), std=array([21.26571252,  4.75853044,  2.09918096,  7.56312   , 10.22035483,\n",
            "        4.09612605, 25.53965407, 14.5910849 ])))\n",
            "Epoch 1/99999999999\n",
            "28/36 [======================>.......] - ETA: 0s - loss: 0.8632 - accuracy: 0.6714 - binary_crossentropy: 0.6041\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.76344, saving model to /content/drive/My Drive/l2_model_heart/l2_heart_model.ckpt\n",
            "36/36 [==============================] - 2s 55ms/step - loss: 0.8499 - accuracy: 0.6917 - binary_crossentropy: 0.5954 - val_loss: 0.7781 - val_accuracy: 0.7634 - val_binary_crossentropy: 0.5131\n",
            "Epoch 2/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.8813 - accuracy: 0.5000 - binary_crossentropy: 0.6471\n",
            "Epoch 00002: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.6763 - accuracy: 0.7694 - binary_crossentropy: 0.5003 - val_loss: 0.7239 - val_accuracy: 0.7419 - val_binary_crossentropy: 0.5527\n",
            "Epoch 3/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6966 - accuracy: 0.7750 - binary_crossentropy: 0.4932\n",
            "Epoch 00003: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.6329 - accuracy: 0.7444 - binary_crossentropy: 0.5411 - val_loss: 0.7259 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.5361\n",
            "Epoch 4/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.5901 - accuracy: 0.8000 - binary_crossentropy: 0.4050\n",
            "Epoch 00004: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.5823 - accuracy: 0.7778 - binary_crossentropy: 0.4547 - val_loss: 0.7734 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.5897\n",
            "Epoch 5/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.4720 - accuracy: 0.9000 - binary_crossentropy: 0.3009\n",
            "Epoch 00005: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.5667 - accuracy: 0.7778 - binary_crossentropy: 0.4361 - val_loss: 0.7004 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.5519\n",
            "Epoch 6/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5495 - accuracy: 0.8125 - binary_crossentropy: 0.3911\n",
            "Epoch 00006: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.6990 - accuracy: 0.7639 - binary_crossentropy: 0.4885 - val_loss: 0.7188 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.5613\n",
            "Epoch 7/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5837 - accuracy: 0.7750 - binary_crossentropy: 0.4350\n",
            "Epoch 00007: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.5328 - accuracy: 0.8139 - binary_crossentropy: 0.4005 - val_loss: 0.6915 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.5855\n",
            "Epoch 8/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.8409 - accuracy: 0.5000 - binary_crossentropy: 0.6973\n",
            "Epoch 00008: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.5569 - accuracy: 0.7667 - binary_crossentropy: 0.4582 - val_loss: 0.7065 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5747\n",
            "Epoch 9/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.3812 - accuracy: 1.0000 - binary_crossentropy: 0.2433\n",
            "Epoch 00009: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.5635 - accuracy: 0.7833 - binary_crossentropy: 0.4460 - val_loss: 0.6639 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.5669\n",
            "Epoch 10/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5501 - accuracy: 0.8111 - binary_crossentropy: 0.4176\n",
            "Epoch 00010: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.4618 - accuracy: 0.8250 - binary_crossentropy: 0.3812 - val_loss: 0.7904 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.5956\n",
            "Epoch 11/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 1.0201 - accuracy: 0.5000 - binary_crossentropy: 0.8906\n",
            "Epoch 00011: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.5490 - accuracy: 0.7611 - binary_crossentropy: 0.4551 - val_loss: 0.6561 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5636\n",
            "Epoch 12/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.5033 - accuracy: 0.8000 - binary_crossentropy: 0.3783\n",
            "Epoch 00012: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4510 - accuracy: 0.8306 - binary_crossentropy: 0.3726 - val_loss: 0.7265 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.6376\n",
            "Epoch 13/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.5352 - accuracy: 0.8000 - binary_crossentropy: 0.4125\n",
            "Epoch 00013: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.5883 - accuracy: 0.8306 - binary_crossentropy: 0.3765 - val_loss: 0.7571 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.6708\n",
            "Epoch 14/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.5278 - accuracy: 0.8000 - binary_crossentropy: 0.4073\n",
            "Epoch 00014: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.5581 - accuracy: 0.8444 - binary_crossentropy: 0.3697 - val_loss: 0.7470 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.6744\n",
            "Epoch 15/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.5008 - accuracy: 0.7000 - binary_crossentropy: 0.3825\n",
            "Epoch 00015: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.5923 - accuracy: 0.8111 - binary_crossentropy: 0.3955 - val_loss: 0.7065 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.6156\n",
            "Epoch 16/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4521 - accuracy: 0.8889 - binary_crossentropy: 0.3367\n",
            "Epoch 00016: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.4403 - accuracy: 0.8333 - binary_crossentropy: 0.3815 - val_loss: 0.7840 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.6314\n",
            "Epoch 17/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4727 - accuracy: 0.8125 - binary_crossentropy: 0.3584\n",
            "Epoch 00017: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.4699 - accuracy: 0.8500 - binary_crossentropy: 0.3288 - val_loss: 0.8183 - val_accuracy: 0.6559 - val_binary_crossentropy: 0.7023\n",
            "Epoch 18/99999999999\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5345 - accuracy: 0.8143 - binary_crossentropy: 0.4208\n",
            "Epoch 00018: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3936 - accuracy: 0.8500 - binary_crossentropy: 0.3494 - val_loss: 0.7669 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.6383\n",
            "Epoch 19/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.3919 - accuracy: 0.9000 - binary_crossentropy: 0.2794\n",
            "Epoch 00019: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4271 - accuracy: 0.8583 - binary_crossentropy: 0.3328 - val_loss: 0.7531 - val_accuracy: 0.6667 - val_binary_crossentropy: 0.6825\n",
            "Epoch 20/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4723 - accuracy: 0.8111 - binary_crossentropy: 0.3609\n",
            "Epoch 00020: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4296 - accuracy: 0.8556 - binary_crossentropy: 0.3305 - val_loss: 0.8079 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.6697\n",
            "Epoch 21/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.6380 - accuracy: 0.8000 - binary_crossentropy: 0.5271\n",
            "Epoch 00021: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3956 - accuracy: 0.8556 - binary_crossentropy: 0.3258 - val_loss: 0.7930 - val_accuracy: 0.6452 - val_binary_crossentropy: 0.7133\n",
            "Epoch 22/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3763 - accuracy: 0.9000 - binary_crossentropy: 0.2658\n",
            "Epoch 00022: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3480 - accuracy: 0.8972 - binary_crossentropy: 0.2850 - val_loss: 0.7740 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.7002\n",
            "Epoch 23/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.3110 - accuracy: 1.0000 - binary_crossentropy: 0.2002\n",
            "Epoch 00023: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.4257 - accuracy: 0.8750 - binary_crossentropy: 0.2883 - val_loss: 0.8686 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.7093\n",
            "Epoch 24/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.3670 - accuracy: 0.9000 - binary_crossentropy: 0.2556\n",
            "Epoch 00024: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3801 - accuracy: 0.9028 - binary_crossentropy: 0.2590 - val_loss: 0.9029 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.7402\n",
            "Epoch 25/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4026 - accuracy: 0.9000 - binary_crossentropy: 0.2903\n",
            "Epoch 00025: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3066 - accuracy: 0.9000 - binary_crossentropy: 0.2606 - val_loss: 0.8141 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.7476\n",
            "Epoch 26/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.3268 - accuracy: 0.9500 - binary_crossentropy: 0.2140\n",
            "Epoch 00026: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.2839 - accuracy: 0.9250 - binary_crossentropy: 0.2109 - val_loss: 0.7954 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.7108\n",
            "Epoch 27/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3004 - accuracy: 0.9333 - binary_crossentropy: 0.1865\n",
            "Epoch 00027: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2745 - accuracy: 0.9472 - binary_crossentropy: 0.1748 - val_loss: 0.8958 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.8017\n",
            "Epoch 28/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.2703 - accuracy: 0.9625 - binary_crossentropy: 0.1552\n",
            "Epoch 00028: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.3034 - accuracy: 0.9361 - binary_crossentropy: 0.1831 - val_loss: 1.0018 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.8657\n",
            "Epoch 29/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.2947 - accuracy: 0.9444 - binary_crossentropy: 0.1794\n",
            "Epoch 00029: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.3006 - accuracy: 0.9222 - binary_crossentropy: 0.2033 - val_loss: 0.9407 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.8816\n",
            "Epoch 30/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.2876 - accuracy: 0.9556 - binary_crossentropy: 0.1721\n",
            "Epoch 00030: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2607 - accuracy: 0.9444 - binary_crossentropy: 0.1704 - val_loss: 0.9483 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.8606\n",
            "Epoch 31/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.2725 - accuracy: 0.9375 - binary_crossentropy: 0.1559\n",
            "Epoch 00031: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.2183 - accuracy: 0.9528 - binary_crossentropy: 0.1368 - val_loss: 1.1014 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.9942\n",
            "Epoch 32/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.2509 - accuracy: 0.9667 - binary_crossentropy: 0.1339\n",
            "Epoch 00032: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3181 - accuracy: 0.9583 - binary_crossentropy: 0.1453 - val_loss: 1.0623 - val_accuracy: 0.7097 - val_binary_crossentropy: 1.0115\n",
            "Epoch 33/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.2628 - accuracy: 0.9444 - binary_crossentropy: 0.1459\n",
            "Epoch 00033: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2311 - accuracy: 0.9444 - binary_crossentropy: 0.1461 - val_loss: 1.2510 - val_accuracy: 0.6129 - val_binary_crossentropy: 1.0600\n",
            "Epoch 34/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.4131 - accuracy: 0.9000 - binary_crossentropy: 0.2961\n",
            "Epoch 00034: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2588 - accuracy: 0.9417 - binary_crossentropy: 0.1500 - val_loss: 1.0507 - val_accuracy: 0.6559 - val_binary_crossentropy: 0.9930\n",
            "Epoch 35/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.4135 - accuracy: 0.8000 - binary_crossentropy: 0.2957\n",
            "Epoch 00035: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2233 - accuracy: 0.9722 - binary_crossentropy: 0.0965 - val_loss: 1.0658 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.0180\n",
            "Epoch 36/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1671 - accuracy: 1.0000 - binary_crossentropy: 0.0491\n",
            "Epoch 00036: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.2043 - accuracy: 0.9667 - binary_crossentropy: 0.1161 - val_loss: 1.2160 - val_accuracy: 0.6667 - val_binary_crossentropy: 1.0675\n",
            "Epoch 37/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.2761 - accuracy: 0.9222 - binary_crossentropy: 0.1577\n",
            "Epoch 00037: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.2521 - accuracy: 0.9306 - binary_crossentropy: 0.1516 - val_loss: 1.1901 - val_accuracy: 0.6559 - val_binary_crossentropy: 1.1175\n",
            "Epoch 38/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3068 - accuracy: 0.9222 - binary_crossentropy: 0.1881\n",
            "Epoch 00038: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2387 - accuracy: 0.9417 - binary_crossentropy: 0.1551 - val_loss: 1.0811 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.0274\n",
            "Epoch 39/99999999999\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.2560 - accuracy: 0.9571 - binary_crossentropy: 0.1375\n",
            "Epoch 00039: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.1946 - accuracy: 0.9722 - binary_crossentropy: 0.0959 - val_loss: 1.5131 - val_accuracy: 0.6129 - val_binary_crossentropy: 1.2872\n",
            "Epoch 40/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1718 - accuracy: 1.0000 - binary_crossentropy: 0.0539\n",
            "Epoch 00040: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.2260 - accuracy: 0.9556 - binary_crossentropy: 0.1122 - val_loss: 1.3308 - val_accuracy: 0.6452 - val_binary_crossentropy: 1.1767\n",
            "Epoch 41/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.2464 - accuracy: 0.9000 - binary_crossentropy: 0.1285\n",
            "Epoch 00041: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1949 - accuracy: 0.9694 - binary_crossentropy: 0.0837 - val_loss: 1.1713 - val_accuracy: 0.6882 - val_binary_crossentropy: 1.1145\n",
            "Epoch 42/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1714 - accuracy: 1.0000 - binary_crossentropy: 0.0538\n",
            "Epoch 00042: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.1570 - accuracy: 0.9917 - binary_crossentropy: 0.0489 - val_loss: 1.2075 - val_accuracy: 0.7097 - val_binary_crossentropy: 1.1486\n",
            "Epoch 43/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1671 - accuracy: 1.0000 - binary_crossentropy: 0.0496\n",
            "Epoch 00043: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1779 - accuracy: 0.9750 - binary_crossentropy: 0.0789 - val_loss: 1.3063 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.1659\n",
            "Epoch 44/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1333 - accuracy: 1.0000 - binary_crossentropy: 0.0160\n",
            "Epoch 00044: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1702 - accuracy: 0.9889 - binary_crossentropy: 0.0530 - val_loss: 1.5217 - val_accuracy: 0.6344 - val_binary_crossentropy: 1.3167\n",
            "Epoch 45/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.3772 - accuracy: 0.9000 - binary_crossentropy: 0.2604\n",
            "Epoch 00045: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1609 - accuracy: 0.9806 - binary_crossentropy: 0.0691 - val_loss: 1.2211 - val_accuracy: 0.6237 - val_binary_crossentropy: 1.1596\n",
            "Epoch 46/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1414 - accuracy: 1.0000 - binary_crossentropy: 0.0256\n",
            "Epoch 00046: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.1501 - accuracy: 0.9917 - binary_crossentropy: 0.0496 - val_loss: 1.2979 - val_accuracy: 0.7097 - val_binary_crossentropy: 1.1860\n",
            "Epoch 47/99999999999\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.1644 - accuracy: 0.9857 - binary_crossentropy: 0.0496\n",
            "Epoch 00047: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.1526 - accuracy: 0.9889 - binary_crossentropy: 0.0498 - val_loss: 1.5309 - val_accuracy: 0.6882 - val_binary_crossentropy: 1.2639\n",
            "Epoch 48/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1718 - accuracy: 0.9778 - binary_crossentropy: 0.0579\n",
            "Epoch 00048: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.1488 - accuracy: 0.9833 - binary_crossentropy: 0.0572 - val_loss: 1.4846 - val_accuracy: 0.6452 - val_binary_crossentropy: 1.3167\n",
            "Epoch 49/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.2277 - accuracy: 0.9000 - binary_crossentropy: 0.1143\n",
            "Epoch 00049: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1512 - accuracy: 0.9833 - binary_crossentropy: 0.0567 - val_loss: 1.4670 - val_accuracy: 0.6129 - val_binary_crossentropy: 1.3449\n",
            "Epoch 50/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1211 - accuracy: 1.0000 - binary_crossentropy: 0.0082\n",
            "Epoch 00050: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1312 - accuracy: 0.9917 - binary_crossentropy: 0.0353 - val_loss: 1.3836 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.3612\n",
            "Epoch 51/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1740 - accuracy: 0.9667 - binary_crossentropy: 0.0618\n",
            "Epoch 00051: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1521 - accuracy: 0.9861 - binary_crossentropy: 0.0506 - val_loss: 1.3209 - val_accuracy: 0.6344 - val_binary_crossentropy: 1.2631\n",
            "Epoch 52/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1710 - accuracy: 1.0000 - binary_crossentropy: 0.0600\n",
            "Epoch 00052: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.1526 - accuracy: 0.9944 - binary_crossentropy: 0.0387 - val_loss: 1.4513 - val_accuracy: 0.6452 - val_binary_crossentropy: 1.3626\n",
            "Epoch 53/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1271 - accuracy: 1.0000 - binary_crossentropy: 0.0171\n",
            "Epoch 00053: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.1268 - accuracy: 0.9917 - binary_crossentropy: 0.0282 - val_loss: 1.3497 - val_accuracy: 0.6559 - val_binary_crossentropy: 1.3147\n",
            "Epoch 54/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1511 - accuracy: 1.0000 - binary_crossentropy: 0.0421\n",
            "Epoch 00054: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1414 - accuracy: 1.0000 - binary_crossentropy: 0.0284 - val_loss: 1.5038 - val_accuracy: 0.6559 - val_binary_crossentropy: 1.3313\n",
            "Epoch 55/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1320 - accuracy: 1.0000 - binary_crossentropy: 0.0236\n",
            "Epoch 00055: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.1856 - accuracy: 0.9972 - binary_crossentropy: 0.0228 - val_loss: 1.5255 - val_accuracy: 0.6559 - val_binary_crossentropy: 1.3548\n",
            "Epoch 56/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1200 - accuracy: 1.0000 - binary_crossentropy: 0.0125\n",
            "Epoch 00056: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1369 - accuracy: 1.0000 - binary_crossentropy: 0.0320 - val_loss: 1.5614 - val_accuracy: 0.6452 - val_binary_crossentropy: 1.4462\n",
            "Epoch 57/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1426 - accuracy: 1.0000 - binary_crossentropy: 0.0354\n",
            "Epoch 00057: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.1393 - accuracy: 0.9917 - binary_crossentropy: 0.0341 - val_loss: 1.6573 - val_accuracy: 0.6344 - val_binary_crossentropy: 1.4451\n",
            "Epoch 58/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1356 - accuracy: 1.0000 - binary_crossentropy: 0.0296\n",
            "Epoch 00058: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1444 - accuracy: 1.0000 - binary_crossentropy: 0.0231 - val_loss: 1.4052 - val_accuracy: 0.6344 - val_binary_crossentropy: 1.3577\n",
            "Epoch 59/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.1227 - accuracy: 1.0000 - binary_crossentropy: 0.0176\n",
            "Epoch 00059: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.1263 - accuracy: 1.0000 - binary_crossentropy: 0.0193 - val_loss: 1.5100 - val_accuracy: 0.6559 - val_binary_crossentropy: 1.3833\n",
            "Epoch 60/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1139 - accuracy: 1.0000 - binary_crossentropy: 0.0096\n",
            "Epoch 00060: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1279 - accuracy: 1.0000 - binary_crossentropy: 0.0205 - val_loss: 1.4954 - val_accuracy: 0.6022 - val_binary_crossentropy: 1.4953\n",
            "Epoch 61/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1116 - accuracy: 1.0000 - binary_crossentropy: 0.0082\n",
            "Epoch 00061: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1226 - accuracy: 0.9917 - binary_crossentropy: 0.0276 - val_loss: 1.4697 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.4326\n",
            "Epoch 62/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1189 - accuracy: 1.0000 - binary_crossentropy: 0.0162\n",
            "Epoch 00062: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1418 - accuracy: 0.9889 - binary_crossentropy: 0.0455 - val_loss: 1.4048 - val_accuracy: 0.7204 - val_binary_crossentropy: 1.3988\n",
            "Epoch 63/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1131 - accuracy: 1.0000 - binary_crossentropy: 0.0110\n",
            "Epoch 00063: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1333 - accuracy: 0.9917 - binary_crossentropy: 0.0492 - val_loss: 1.6605 - val_accuracy: 0.6667 - val_binary_crossentropy: 1.5967\n",
            "Epoch 64/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1496 - accuracy: 1.0000 - binary_crossentropy: 0.0468\n",
            "Epoch 00064: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1977 - accuracy: 0.9417 - binary_crossentropy: 0.1490 - val_loss: 1.5016 - val_accuracy: 0.6989 - val_binary_crossentropy: 1.3711\n",
            "Epoch 65/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.2359 - accuracy: 0.9875 - binary_crossentropy: 0.1326\n",
            "Epoch 00065: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.1761 - accuracy: 0.9694 - binary_crossentropy: 0.0967 - val_loss: 1.2428 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.2047\n",
            "Epoch 66/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.2058 - accuracy: 0.9667 - binary_crossentropy: 0.1031\n",
            "Epoch 00066: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.2062 - accuracy: 0.9778 - binary_crossentropy: 0.0779 - val_loss: 1.5042 - val_accuracy: 0.6559 - val_binary_crossentropy: 1.3846\n",
            "Epoch 67/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.1458 - accuracy: 0.9750 - binary_crossentropy: 0.0430\n",
            "Epoch 00067: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1391 - accuracy: 0.9917 - binary_crossentropy: 0.0386 - val_loss: 1.5412 - val_accuracy: 0.6022 - val_binary_crossentropy: 1.5062\n",
            "Epoch 68/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1600 - accuracy: 0.9778 - binary_crossentropy: 0.0576\n",
            "Epoch 00068: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1525 - accuracy: 0.9861 - binary_crossentropy: 0.0471 - val_loss: 1.4860 - val_accuracy: 0.6667 - val_binary_crossentropy: 1.4636\n",
            "Epoch 69/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1350 - accuracy: 0.9889 - binary_crossentropy: 0.0326\n",
            "Epoch 00069: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1256 - accuracy: 0.9944 - binary_crossentropy: 0.0318 - val_loss: 1.3938 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.3710\n",
            "Epoch 70/99999999999\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.1190 - accuracy: 1.0000 - binary_crossentropy: 0.0170\n",
            "Epoch 00070: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.1324 - accuracy: 0.9972 - binary_crossentropy: 0.0228 - val_loss: 1.4409 - val_accuracy: 0.6129 - val_binary_crossentropy: 1.4139\n",
            "Epoch 71/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1169 - accuracy: 1.0000 - binary_crossentropy: 0.0157\n",
            "Epoch 00071: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.1148 - accuracy: 1.0000 - binary_crossentropy: 0.0153 - val_loss: 1.4169 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.4120\n",
            "Epoch 72/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.1189 - accuracy: 1.0000 - binary_crossentropy: 0.0186\n",
            "Epoch 00072: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.1135 - accuracy: 1.0000 - binary_crossentropy: 0.0158 - val_loss: 1.5195 - val_accuracy: 0.6559 - val_binary_crossentropy: 1.4293\n",
            "Epoch 73/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1090 - accuracy: 1.0000 - binary_crossentropy: 0.0096\n",
            "Epoch 00073: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1056 - accuracy: 1.0000 - binary_crossentropy: 0.0112 - val_loss: 1.5975 - val_accuracy: 0.6559 - val_binary_crossentropy: 1.4572\n",
            "Epoch 74/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1068 - accuracy: 1.0000 - binary_crossentropy: 0.0086\n",
            "Epoch 00074: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1081 - accuracy: 1.0000 - binary_crossentropy: 0.0115 - val_loss: 1.4697 - val_accuracy: 0.6452 - val_binary_crossentropy: 1.4484\n",
            "Epoch 75/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.1084 - accuracy: 1.0000 - binary_crossentropy: 0.0116\n",
            "Epoch 00075: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.1057 - accuracy: 1.0000 - binary_crossentropy: 0.0136 - val_loss: 1.8845 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.4651\n",
            "Epoch 76/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.1077 - accuracy: 1.0000 - binary_crossentropy: 0.0118\n",
            "Epoch 00076: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.1102 - accuracy: 1.0000 - binary_crossentropy: 0.0115 - val_loss: 1.4802 - val_accuracy: 0.6452 - val_binary_crossentropy: 1.4456\n",
            "Epoch 77/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1004 - accuracy: 1.0000 - binary_crossentropy: 0.0055\n",
            "Epoch 00077: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1064 - accuracy: 1.0000 - binary_crossentropy: 0.0109 - val_loss: 1.5475 - val_accuracy: 0.6129 - val_binary_crossentropy: 1.5617\n",
            "Epoch 78/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1242 - accuracy: 1.0000 - binary_crossentropy: 0.0305\n",
            "Epoch 00078: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1049 - accuracy: 1.0000 - binary_crossentropy: 0.0186 - val_loss: 1.4283 - val_accuracy: 0.7097 - val_binary_crossentropy: 1.3903\n",
            "Epoch 79/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0989 - accuracy: 1.0000 - binary_crossentropy: 0.0055\n",
            "Epoch 00079: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.1159 - accuracy: 1.0000 - binary_crossentropy: 0.0142 - val_loss: 1.4697 - val_accuracy: 0.6989 - val_binary_crossentropy: 1.4443\n",
            "Epoch 80/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.1052 - accuracy: 1.0000 - binary_crossentropy: 0.0128\n",
            "Epoch 00080: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.1027 - accuracy: 1.0000 - binary_crossentropy: 0.0116 - val_loss: 1.6222 - val_accuracy: 0.6667 - val_binary_crossentropy: 1.4311\n",
            "Epoch 81/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0968 - accuracy: 1.0000 - binary_crossentropy: 0.0053\n",
            "Epoch 00081: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0994 - accuracy: 1.0000 - binary_crossentropy: 0.0090 - val_loss: 1.4568 - val_accuracy: 0.6667 - val_binary_crossentropy: 1.4191\n",
            "Epoch 82/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.0997 - accuracy: 1.0000 - binary_crossentropy: 0.0095\n",
            "Epoch 00082: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.0960 - accuracy: 1.0000 - binary_crossentropy: 0.0093 - val_loss: 1.4256 - val_accuracy: 0.6559 - val_binary_crossentropy: 1.4360\n",
            "Epoch 83/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0963 - accuracy: 1.0000 - binary_crossentropy: 0.0071\n",
            "Epoch 00083: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.0974 - accuracy: 1.0000 - binary_crossentropy: 0.0109 - val_loss: 1.4487 - val_accuracy: 0.6989 - val_binary_crossentropy: 1.4176\n",
            "Epoch 84/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0919 - accuracy: 1.0000 - binary_crossentropy: 0.0036\n",
            "Epoch 00084: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0962 - accuracy: 1.0000 - binary_crossentropy: 0.0093 - val_loss: 1.6441 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.4380\n",
            "Epoch 85/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0904 - accuracy: 1.0000 - binary_crossentropy: 0.0030\n",
            "Epoch 00085: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0940 - accuracy: 1.0000 - binary_crossentropy: 0.0102 - val_loss: 1.4328 - val_accuracy: 0.6452 - val_binary_crossentropy: 1.4477\n",
            "Epoch 86/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0997 - accuracy: 1.0000 - binary_crossentropy: 0.0134\n",
            "Epoch 00086: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.1020 - accuracy: 1.0000 - binary_crossentropy: 0.0132 - val_loss: 1.4595 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.4178\n",
            "Epoch 87/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0908 - accuracy: 1.0000 - binary_crossentropy: 0.0050\n",
            "Epoch 00087: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0960 - accuracy: 1.0000 - binary_crossentropy: 0.0094 - val_loss: 1.4588 - val_accuracy: 0.6559 - val_binary_crossentropy: 1.4742\n",
            "Epoch 88/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0968 - accuracy: 1.0000 - binary_crossentropy: 0.0118\n",
            "Epoch 00088: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0918 - accuracy: 1.0000 - binary_crossentropy: 0.0106 - val_loss: 1.5965 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.4482\n",
            "Epoch 89/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0981 - accuracy: 1.0000 - binary_crossentropy: 0.0138\n",
            "Epoch 00089: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0935 - accuracy: 1.0000 - binary_crossentropy: 0.0087 - val_loss: 1.5324 - val_accuracy: 0.6667 - val_binary_crossentropy: 1.4453\n",
            "Epoch 90/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0895 - accuracy: 1.0000 - binary_crossentropy: 0.0062\n",
            "Epoch 00090: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0902 - accuracy: 1.0000 - binary_crossentropy: 0.0096 - val_loss: 1.4310 - val_accuracy: 0.6667 - val_binary_crossentropy: 1.4421\n",
            "Epoch 91/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0924 - accuracy: 1.0000 - binary_crossentropy: 0.0100\n",
            "Epoch 00091: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0904 - accuracy: 1.0000 - binary_crossentropy: 0.0107 - val_loss: 1.5920 - val_accuracy: 0.6667 - val_binary_crossentropy: 1.4340\n",
            "Epoch 92/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1081 - accuracy: 1.0000 - binary_crossentropy: 0.0263\n",
            "Epoch 00092: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.0919 - accuracy: 1.0000 - binary_crossentropy: 0.0093 - val_loss: 1.5716 - val_accuracy: 0.6452 - val_binary_crossentropy: 1.4401\n",
            "Epoch 93/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.1053 - accuracy: 1.0000 - binary_crossentropy: 0.0244\n",
            "Epoch 00093: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0911 - accuracy: 1.0000 - binary_crossentropy: 0.0101 - val_loss: 1.6286 - val_accuracy: 0.6129 - val_binary_crossentropy: 1.4921\n",
            "Epoch 94/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0896 - accuracy: 1.0000 - binary_crossentropy: 0.0094\n",
            "Epoch 00094: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0930 - accuracy: 1.0000 - binary_crossentropy: 0.0110 - val_loss: 1.4027 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.4211\n",
            "Epoch 95/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0841 - accuracy: 1.0000 - binary_crossentropy: 0.0044\n",
            "Epoch 00095: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0908 - accuracy: 1.0000 - binary_crossentropy: 0.0102 - val_loss: 1.5929 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.4340\n",
            "Epoch 96/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0949 - accuracy: 1.0000 - binary_crossentropy: 0.0158\n",
            "Epoch 00096: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0876 - accuracy: 1.0000 - binary_crossentropy: 0.0112 - val_loss: 1.6475 - val_accuracy: 0.6559 - val_binary_crossentropy: 1.5256\n",
            "Epoch 97/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0959 - accuracy: 1.0000 - binary_crossentropy: 0.0175\n",
            "Epoch 00097: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0884 - accuracy: 1.0000 - binary_crossentropy: 0.0121 - val_loss: 1.4313 - val_accuracy: 0.6989 - val_binary_crossentropy: 1.4431\n",
            "Epoch 98/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0966 - accuracy: 1.0000 - binary_crossentropy: 0.0185\n",
            "Epoch 00098: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0894 - accuracy: 1.0000 - binary_crossentropy: 0.0103 - val_loss: 1.5810 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.4227\n",
            "Epoch 99/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0869 - accuracy: 1.0000 - binary_crossentropy: 0.0094\n",
            "Epoch 00099: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.0869 - accuracy: 1.0000 - binary_crossentropy: 0.0080 - val_loss: 1.6268 - val_accuracy: 0.6774 - val_binary_crossentropy: 1.4420\n",
            "Epoch 100/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.0855 - accuracy: 1.0000 - binary_crossentropy: 0.0089\n",
            "Epoch 00100: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0903 - accuracy: 1.0000 - binary_crossentropy: 0.0112 - val_loss: 1.4470 - val_accuracy: 0.6559 - val_binary_crossentropy: 1.4725\n",
            "Epoch 101/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.0862 - accuracy: 1.0000 - binary_crossentropy: 0.0102\n",
            "Epoch 00101: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 8ms/step - loss: 0.0882 - accuracy: 1.0000 - binary_crossentropy: 0.0125 - val_loss: 1.4503 - val_accuracy: 0.6667 - val_binary_crossentropy: 1.4508\n",
            "Epoch 00101: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEKCAYAAAAfGVI8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0\ndHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOydd3gU1d6A39nNpvdGGukJSWgplNBB\nQFCaCHKJolcs2HvBgtdyr1e9+nGvFcWCIih2QaVIC72FHtJIQgKk975Jdne+PyakJwTJEsp5n2ef\n3T1z5syZSXZ+c35VkmUZgUAgEFy7qHp6AgKBQCDoWYQgEAgEgmscIQgEAoHgGkcIAoFAILjGEYJA\nIBAIrnGEIBAIBIJrHKMJAkmSvpAkKV+SpPgOtkuSJL0nSVKqJEnHJEmKNNZcBAKBQNAxxlwRfAlM\n7mT7DUBQw2sBsMSIcxEIBAJBBxhNEMiyvB0o7qTLDGC5rLAXsJckyd1Y8xEIBAJB+5j04LE9gTPN\nvp9taMtp3VGSpAUoqwbMzc2jvL29L8kELycMBgMq1bVn0rlcz1uSDVjUZKPWawEJvdocvdoCtb6m\noU1Gr7agxsIdWVLmb1pXilltYSeDqqi2cEevtjDqeVfWyxTWKBkFTCQZR7UWe6kaU30lkqw3yjEF\nnaPFlJOyl1GPUZebWijLskt723pSEHQZWZaXAksB+vTpIycnJ/fwjC49sbGxjB07tqenccm5LM67\nPBty48FvFGgsoLoYls+A/BK44T1le+IaKEwB1wEQNh3M7WHDC+DlD7f9APuXwpZ/Qt/b4fp/AVLL\nY9RWwPd3QOlpuHU5sadh7NixZJXWkFumJcrHoVtO5fsDZ1j48zGe98xlvsV2nLM2Y2WooFo2o8Z3\nNk6DZ4PXYDJKanjkm8MUVNRirlEzPMAJnUFme0oBQb1suHeUP4k5ZWxNLiCjsIpAV2vG9nFhsK8j\nJ7LK2Zqcz/GsMnrZmjGmjyvjgl3wcLDodG6yDGt3xJErObEtpYCymvp2j/3MpGB62ZoDsDkxn/c2\nn2RUkDP/vKkfH21N4/u4M9wS5cW8YT7dcs0ulFqdgQOnitmSlM/h0yXYW5oyOtiFcSEu+DpZtbtP\n3KEjRI650ajz8rC3zOxoW08Kgiygd7PvXg1tAkFbKgugPAs8wrvW32CA1E3gGgr2vc/fHyA/EZDA\nNaSprTAVvpoGFdmgsYKgiVB4EopSIeZb5TvA+JdAWwbmdk372rjBT3fDh0OV/Qf8DWZ8BOoOfnZ3\n/qEImJVzcAl+iC+2e/D2xnS0Oj1vzOzPXL8a5Ri9h7TYTVuvZ2NCHrU6AwAmKonBfo542ltA5m5w\nCaHaxJaVe0/z+tpEFnoe5/6it5BMbaDfFEp9JxOzxZKMdJnPRw3CpdaMmJXJyLIj/5gbxoGMYjac\nyKOspp7HJg1nwWh/NGoVo4H7pkG5th5bc03jfAb2hVuvhwptPdZmJkhSK6HXCf4eZ7hr7Fie1RvY\nf6qYtfE57R77HLd6BaC38eClX+PZufQkOWVa7hk5iCenhF7Qcbsbb1+YNQ6qanWYa9SoVZ3PxSr1\nDO52nQtKY9KTgmAN8LAkSauAoUCZLMtt1EICAQB/PAkp6+HRw2DXbAmtq4WzB8BnBDT/4e/6H2x+\nVfnsEQlhMyDyDrB0bH/8tK3wbQzo62DEozDmOSjNVISAQQ8zl8LpPZD0O9RVwa3fQcC4lmM0FwIA\nfW8CtQZ+mA8R82Dae6BSd3yO1i4Y7viNmmXT6Zu4GM+ETwi2HU6x2pnQ358BVRZIalh4qvFY+9KL\neO7n45wqrGoz3HzXk7xc/jLlagdeqvs7q+sH8w+vo8wvfBvJdyTErAIza+yB5UG13PbZXuZ/eQBL\nUzUmahWrFkQT6GrDjHBPXp3ej3q9AXNN2/k3FwLNsemgvSuYqFUMD3RmeKBzp8cGuD3aB1O1xAu/\nxPPg2ACemdSnR4VAc6zMrgilC5Kxso9KkvQtMBZwBvKAlwENgCzLH0vKX+oDFM+iamC+LMtx5xtX\nqIauLWJjYxk7qC8sDgGDDqLmw7T/NXX442k48CkMvR8mv6kIg1PblSfrPjeCZ5Sitsk+DFauMOUd\nRSg0J+VP+G4eOAUqK44jK5XPNaXKjfuONU2rBIMe6irb3vSbIcsyO1MLCXK1wc3OXBEcplZo6/Uc\nzCwhuJcNLjZmLfY5kV3GD3FnWR+fS3F5BZM0R3nGJ5XeBbFQV0mS2QCOVDoQY7KV7aNWUuwYwf6M\nYr7Zd5rejha8NqMfgS7WAFTW6tiecJoZu26mWiehVVsRJqdR7hKFTcEhJP+xMPcbMLVsMYeiylpu\n/3w/JdV1rLxnKP4N411KLub/vLpOh6XplXHjbc2l+H1LknRQluVB7W0z2lWTZTnmPNtl4CFjHV9w\nFXFslSIE/MfB4a9h5OPg4AtZh+DAZ+DoD/s+Vp7mRz8DP96l3MhnfgxmNjDqScg5CqsfVvTwodMg\ntEEYVObBplegVxjc/quyYug/G357DNSm8PffwDmwaS4qdaMQqNXpOX62jEG+LVcZ6+NzeWDlIQAi\nve25LsSVxNwKtiblU12nx9bchEVTwrhlkBfaegOLNybz+c5TaNQqxgS7MLlfH8yL7PCe+DLo6kBX\nQ4CJDStXrIOMrazbsoVv9RKSBHeN8OPpScFtboChCb+AIY+KmF+wChoFez/ENvYNRZU152vQmLe5\nzE7WZqx5eAQ6g9zh03d3UF9fz9mzZ9FqtW222dnZkZiYaLRjX65053mbm5vj5eWFRtP1FZnRVgTG\nQqwIri1it25lbMJzyg19znJ4N1y5UU9/Hz4dBxV58PB+2LFYUQeZ2ysC4d4tin2gOXod7Hkftr4B\n+tqmds9BMO8nsLBvatPVKcKn1VNzc77em8lLv8bz8bwoJvdzUw5hkJn8v+3oZZmZ4Z6si88lIacc\nZ2tTJoa5MSrImS93ZbA/o5hh/k5kl9WQWVTNrUO9WTg5BDsL5cfb3t9bNuiR3+hNRejfKB79L6zN\nTNqsLAAoSIElw6HfLLj5k6Z2bRmY2kAPe2GdOnUKGxsbnJyc2qhwKioqsLGx6aGZ9Rzddd6yLFNU\nVERFRQV+fn4ttvXIikAg6A5sy1OgIEnRr9t6wOB7YN8SRTDkHIXZy5Qn9AmvgIkZbPsP3PxpWyEA\nipF25BMQ+XfF8+ccDr5tDbgmpoBpp3Pbm14EwKu/nWBUkDNWZib8djSbk/mVfHBrBFMHePDI+CCK\nKmuxtzRtNBhO7uvGyv2neWtdEk7Wpnx7bzTDApzOey0klRrJNRS7ilTsnNv3PkGWFXuKqWWDd1Iz\nOlFnXUq0Wi2+vr6XjR7/akKSJJycnCgoKLig/YQgEFzWuOVuBI0l9J2pNIx8Ag4uU1RBAdc1tUsS\njHsBhj10/huepWPHRuMuIssyB04VE+JmQ1JuBf/blMLCySG8u/kkIW423NivKTbSybrlU7tKJXF7\ntA8zwj0wN1FjanIBT+iuoYrRvD0MBlj7FGTsgKn/Bet2XcYvC4QQMB5/5dpefpE6gisbWYazcYoa\npqsUpkJVUdv2uipc83coN3tzW6XN2gWGP6qoOG58p6WnEFyyp94zxTXkV9RyW7QPMUO8+WJXBm+s\nS+JUYRVPTgxGdR53QVC8bS5ICIAiCKoKFHfa5hj08NsjEPcFjHhcMaoLBF1ECAJB95K8Fj4bD59P\ngLwT5+9v0MOyG+D72xUh0pwTv2Ki10LE7S3bxz4HTyWCU0D3zfsC2Z+hqJYG+zqwcHIf7C00fL7z\nFAO87JgY1st4Bz6n8ipoZlg06OHXB+HwChizUFGTiSfuTlGr1YSHhzNw4EAiIyPZvXu3UY7z+uuv\nEx4eTnh4eOMxw8PDee+997o8xr59+3jiiSeMMr9zCNWQoHtJWa8EXpWegU9Gw6inlJtTR/7zOUeg\nKl95pW9V1D2gGGt3v0e1hSeW3tEt95EkxUZwiSirqaewspaAZu6UcRnF2FloCHa1QaWSeGlqGE//\ncJSnrzeyD7trmPKenwR+o5XPib8pnlVjX4CxC4137KsICwsLjhw5AsCGDRt4/vnn2bZtW7cf58UX\nX+TFF18EwNrauvGYrdHpOl5BDx06lKFDh3b73JojVgSC7kOWIXUzBI6Hh/YrKp1tb8GJXzreJ3Uz\nIIG1G2x5vWlVsOcDKEgiLeDOHn+6ff7nY0x7fyel1XWNbfszihnk49CoAropwpND/5jI6GAj6+Wt\ne4GFA+QnNLUl/Q4WjorQFVww5eXlODgoKTwqKysZP348kZGR9O/fn9WrVwNQVVXFlClTGDhwIP36\n9eO7774D4ODBg4wZM4aoqCgmTZpETk7XY2LnzZvHAw88wJAhQ3j11VfZu3cvw4YNIyIighEjRnDy\n5EkANm3axE033QTAokWLuPvuuxkzZgz+/v58+OGH3XINxIpA0H0UJClpIMYsBCsnmPkJpGxQjJf9\nZ7e/T+pmJYgr6k7Fd//kn+ASonj/hEylyHlI+/tdIs4UV7M+PheDDKsOnOH+MQEUVdaSXlDFLVEt\nU1d0FGHbrUiSsirIb1AN6euVa9ZnSsepKy5jXv3tBAnZ5Y3f9Xo9avXFxTCEedjy8rS+nfapqakh\nPDwcrVZLTk4OW7ZsARQf/F9++QVbW1sKCwuJjo5m+vTprF+/Hg8PD/744w8AysrKqK+v55FHHmH1\n6tW4uLjw3Xff8eKLL/LFF190ea45OTns3buXqqoqDAYDO3bswMTEhPXr17No0aJGgdOclJQUNm/e\nTGlpKaGhodx///0Xfc2uvP8cQc9RXQzaUiWAqz1SNyvvgeOVd5Uaeg+F03vb719TAmf3K0+y4bfB\nzv/Cln8pbqKSSokUPpLW/edxAXy5OwOVJBHiZsNXuzO4e6QfBzJKABji1z2J4C4YlxA4/qOyesrc\nrcQHhBg3YdnVRnPV0J49e7jjjjuIj49HlmVeeOEFtm/fjkqlIisri7y8PPr3789TTz3FwoULmTp1\nKqNGjSI+Pp74+HgmTlTyTen1etzdLyyT/i233NKYZba0tJQ77riDtLTO/+enTp2Kqakprq6uODo6\nUlBQgJub21+4Ck0IQSA4P7Ks3HjWPQs6LTy4FxzayeyYukm5STXPBeQzDDZvVIRIa5fN9G0gGyBg\nvJKTZ8xz8Ov9kHtM8YG37w30nCCo0Nbz3YEz3NjfnekDPbhneRzr4nM5eqYUMxMV/Tx7yC/fNRRq\ny6AiRzHOm5g32VauMFo/ufdEQNmwYcMoLCykoKCAtWvXUlBQwMGDB9FoNPj6+qLVagkODubQoUOs\nXbuWRYsWMX78eGbOnEnfvn3Zs2fPXz62lVVTPMiLL77IpEmTePDBB0lNTWXy5PbrepmZNbkjq9Xq\nTu0LXUXYCASdU54N386Fn+9RAq9AEQitPXzqqpWn04DxLdu9hynvp9v5saRtBjM78BqsfB8wB1z7\ngtsAJXdQD/ND3Fkqa3XcNdKP60Jc8XWy5Iudp4jLKGZgb3vMTIyXhqFTzhmM8xIgaS34jwXTDgLM\nBOclKSkJvV6Pk5MTZWVluLq6otFo2Lp1K5mZSubm7OxsLC0tmTdvHs888wyHDh2iT58+FBQUNAqC\n+vp6TpzogqdcB5SVleHp6QnAl19+edHndSGIFYGgY4rSlOyb1cUw6d/KzXnPh7DxJUj6A0KnNvXN\n3KWkbQhsJQg8IpWcPaf3QMiUpvZzhmX/MU26bZUa7t4AKhNlhdCD6A0yy3afIsrHgfDeSuqJ+SP8\neHmN8kN/eFxgZ7sbl3MupMd/gLLTMPrpnpvLFco5GwEowYFfffUVarWa2267jWnTptG/f38GDRpE\nSIiSbPD48eM888wzqFQqNBoNS5YswdTUlB9//JFHH32UsrIydDodjz/+OH37dm6f6IiFCxdy1113\n8eqrr3LDDTd027l2BSEIrjVKzyg6+M7SIQMUJMNX08FQD/dsBLf+Snv0A3B0FaxbqDyJmjW4VKZu\nAhMLJR10czTmijDIbLUiKEhuMiw35xK6hXbGxoQ8zhTX8PwNTakqZkd58X9/JlOu1THY7+Iiky8K\nS0fFy+r4D4AEfS7tTeNqQK9vvxKbs7Nzu6oeX19fJk2a1KY9PDyc7du3d+mYlZWVLb6vWLGixfeR\nI0eSkpLS+P31118HYMKECUyYMAGAf/2rZdqQpKSkLh37fAjV0LVEcTq8F6EEH3WWbDAvAb6coujv\n7/yjSQiA8qQ+9b9QflYx7BqUYiikbgLfEe1mtcRnmBIvUNcsZ37qJuW99QqiGaXVdRRrDV0+PYNB\n5mBmMbtTC9u8DmQUozd0LcFiZlEVr/12Ai8HC65vFhxmZWbCvGgfzDUqIr3tOxnhEuAaArJeUatZ\nu/bsXARXPGJFcC1xeIXyhH9sFXgPhUF3te0jy0oaZ5VJQwrmoLZ9vIcqidv2LYGEX5WbeVGqkhCu\nPbyHKx5BWQebgqDaMyw343RRNTGf7iWvrIYcs9Q2lalak1ZQycIfjxGXWdJhn1mRXrxzy4BOA77S\nCiq59dO91OkMrLhnKCatjvnkxGBui/a5qKIr3YJrGKTHCm8hQbcgBMG1gl4HR76BwInKk/66heAe\nDp6RLfudPaCkL5j2XvtC4BxT/g98R0LCasWjSFJB0PXt9+09BJAU9ZDfaKWOQMZOiG7fIJxeUMmt\nn+5Dq9PT30XN2xuS+eNYDv+ZPaCNp45Ob+CT7em8u/kkFho1/57ZnwCXtobTjQl5fLbzFIN8HYgZ\n4t3YnlVaw9niakAp6LLwp+OAzKoFw+jj1lZNZaJWKSUgexqPSOWah0w9f1+B4DwIQXCtkLZFcTe8\n8W3lCf2T0fD93+G+bS3dOg9/rWT77Hdz5+OpNYqXz4A5UFsJFbkd5/6xsIdefeH0bsXw/P3flXq+\nI59s0zU1v4KYT/dhMMisWhBNbtIhtM4hvLQ6nllLdvPJ7VGM7aOoQup0Bh799jDrT+Qypb87r0zv\n235+fmCQryPJeRW8vOYE/T3tCO5lw0exqXy4NZV6fZPKyNXGjG/uHUag66WvznVB9JsFXoPA0e/8\nfQWC8yAEwbXC4eVg6QxBk5Rc+3OWwxeTYO0zMPtzpU9tJcT/TG2f6dTK5th2dWwzazA7jxeN9zBl\nRfLzAkUg3bWhTVyBtl7PXV8q1UpXLYgmqJcNuUkwuZ8bQ/wcmffZPhYsP8iSeZGMDHLmoZWH2JSY\nzz+mhnHXyM5viGqVxLtzI5j63g7uX3EQK1MTkvMqmBHuwZxBvTmnLAp1t8XBqvM6BJcFKpUQAoJu\nQxiLrwWqCiF5HQyc21BwBfCKUiJ6439UCreDouapq+SFjHAeaii12G14R0N9FaRuhMlvKMdvxQdb\nUjldXM17cyMI6tVSLeNopRRwCXW34f4VB5nz8R42Jebzr5v6nVcINB/jw9siySvXUlZTz+d/H8S7\ncyMY0VAkfXig85UhBASCbkYIgmuBow01f1uncx75hJIu4o+noF4Lh1dQbePHT4W92ZNWRGXtxUcs\nnsyr4PDpEo5r+iFLagz9ZrdrVE7Nr+CT7WncHOHZYbUuO0sNX98zlP6edhzLKuM/swYwL7qdCOdO\niPB2YNOTY9j01BjGhxoxXbTgsuZSpaHetm0bw4YNa9Gm0+no1asX2dnZHe73yiuv8M477xhlTu0h\nVENXO7Ks6P29Bisuh83RmCvFXVbcrCR8O72b3+zvRqNWUa+X2ZNW9Jdz6xdU1PLKmhP8cbwpG2Og\n9AbTbUfxaCuvHVmWWfRrPBYaNS9MaafEZDNszTV8c280WaU1LdJCXwg+TiIK91rnUqWhHjVqFGfP\nniUzMxMfH+WhZdOmTfTt2xcPD49uP95fRawIrnayDytZQcNva3974HjF8HhsFbKk5p3cSB4YG4il\nqZptKfl/6ZA/HTzLhMXb2JiQxxMTglk2fzDL5g/GMyiCpbvOUFJV16L/L4ez2JtezHM3hOJs3b6x\ntznmGvVfFgICQWuMmYZapVIxZ84cVq1a1di2atUqYmJiAPj0008ZPHgww4cPZ9asWVRXV1+KU26D\nWBFc7cT/BCoN9L2p4z6T/g0nN5JgNpDyeifuHO5LQnY521IKkGX5ggqtbE3O56kfjhLl48Bbswa0\n8L7xsLNg8rvbWbojnYWTldVJVmkN//w9gQhve+YO7t3RsIKrmL990hTJey4N9dQB7tw+zJeaOj13\nLtvfZp/ZUV7cMqg3xVV1PLDiYItt3903rE3/1lzKNNQxMTHce++9LFy4kNraWtauXcvixYsBuPnm\nm7n33nupqKjgrbfe4vPPP+eRRx65sAvYDQhBcDVjMChFYQInKMVMOsLGjdI7NjN/yVFujvTE0cqU\nMcHObErMI6OoGj/nrqtSfj2chb2lhlULotsEgPVxs2HaAA++3KWkc7YxN+HBlYfQ6WUWzwnvUp1f\ngaA7uJRpqAcNGkRlZSXJyckkJiYydOhQHB0Vj7n4+HgWLVpEcXEx1dXV7aaxuBQIQXA1c3a/ks9n\nwivn7boiWSJfZ8ldIxQPnDHBrsAJtiXn4+fcNa+cmjo9GxPymBHu2WEU8OMTgvj9WDZLYtOo1xs4\neqaUj+dFXpCwEVxdNH+Cb52G2sJU3ekTvqOVaZdWAJ1xKdJQx8TEsGrVKhITExvVQgB33nknv/76\nK/7+/vz000/ExsZe1Ln8VYSN4Gom/iclV/15kpLJssy3+88wKsi50W3T28kSXydLtqUUdPlwW5Pz\nqa7TM21Ax8U5/F2suTnSi692Z7B8Tyb3jvJjcr8LK+YhEHQnlyINdUxMDCtWrGDLli3MmDGjsb2i\nogJ3d3fq6+tZuXKl8U+2A8SK4GrFoIcTv0LwpPNm9DyZX0lWaQ2PXNcyKGxMsAvfxZ1BW6/HXHP+\n3Pu/Hc3G2dqMof7tu3+e47HxQaw+ksVgXweenRzSaV+BwBhc6jTUoaGhWFlZERUV1aIYzT//+c9G\nVdHw4cOpqKi4NBegFUYVBJIkTQbeBdTAZ7Isv9lquw/wBeACFAPzZFk+a8w5XTNk7ISqfOh7nlQR\nwLZk5am/deH1MX1c+GpPJnEZJYwMcm6xTZZlqur0WJsp/0KVtTq2JOUzd3Bv1OfR9fd2tGT946Nx\ntzPvNJGcQGAseiIN9TmbRHMeeOABHnjggTYqsVdeeaVLY3YXRvsVSpKkBj4EbgDCgBhJksJadXsH\nWC7L8gDgNeANY83nqkeWlQjic8T/BKbWHSeCa8b2kwUEuVrj0SqZWrS/E6ZqVbtupB/FphH5z41s\nScoDYFNCHrU6A9MGds03OsDFGktTsSAVCC4HjPk4NgRIlWU5XZblOmAVMKNVnzBgS8Pnre1sF3SV\n+J/g7QD4cChseR0S10CfG8HUstPdqut07EsvZkyr1QCApakJQ/wcWX8iF52+qS6Atl7P5ztPUa83\ncN/XB9lwIpffjmbjYWdOpHcPFXQXCAR/GWMKAk/gTLPvZxvamnMUOKe7mAnYSJLUuYL5Wsegb1ng\n5RzxP4GVi/La8Q7UlED/2ecdbl96MXV6A2P6tBUEAHcM8+FMcQ0/H8pqbPv1cBbFVXV8PC+Kfp52\nPLjyENtSCpgywF24gAoEVyA9vTZ/GvhAkqQ7ge1AFtBGeSdJ0gJgAYCLi0uPuVj1JJWVlcTGxuKX\nvoJeeVvZN/RjZJVSHEWlr2XEyU3kuE8k1XcBGo97sKrKpDTLFLJjOx33m8RaTFVQczqe2Ky2N3GN\nLONnq+KtP47jWJGKWoL3d9XQ20aFaX4iC4LhvxUSKSUGPHU5xMb+tWjk8533tcbVfN52dnYdGkX1\nen2PGUx7ku4+b61We0H/P8YUBFlA81BRr4a2RmRZzqZhRSBJkjUwS5bl0tYDybK8FFgK0KdPH3ns\n2LFGmvLlS2xsLGPHjoXUf0FtIWPcaiBMCWQh6Q8w1OF13b14BYy9oHFfi4tleJAD148f0mEfySOf\nO5cdIMfSH18nS7Iq9/P27P6MG6T8eceN0ZOcW8HA3t1fvrHxvK8xrubzTkxMbGEYbU5ro+m1Qnef\nt7m5OREREV3ub0zV0AEgSJIkP0mSTIG5wJrmHSRJcpYk6dwcnkfxIBJ0hL4eco8rnw9/3dSetBbM\n7JSKYRfAmeJq0gur2rUPNGdMsAuDfBz4cEsqH29Lw9najOnhTUZhc43aKEJAIBBcGowmCGRZ1gEP\nAxuAROB7WZZPSJL0miRJ0xu6jQWSJUlKAXoBrxtrPlcF+Ymg04JTkFLztzxbsRmkrIegiUrVsAvg\nXLBYa7fR1kiSxJPXB5NbrmVXahG3R/tgZnL+uAKB4HLF2rpt0sLFixcTFhbGgAEDGD9+fGMw2TmK\niooIDw8nPDwcNzc3PD09G7/X1dW1Ga8j5s+fT3Jy8kWfQ3diVBuBLMtrgbWt2v7R7POPwI/GnMNV\nRfZh5f2GN2HFLKXil88IqC6EkBup1ekv6Aa9LaUALwcL/LuQ3mF4gDPDA5yIyyzhtmjv8/YXCK40\nIiIiiIuLw9LSkiVLlvDss882ZhkFcHJyaowFeOWVV7C2tubpp59uM44sy8iyjErV/nP2smXLjHMC\nF4GI5rmSyD4E5nYQMB58RsLhFZD0O6g0bNINJPzVjeSVa7s0VEFFLbtSCxkT7NLl7KL/mxvO9/cN\n61KqaIHgSmPcuHFYWiru1tHR0Zw92/XY1tTUVMLCwrjtttvo27cvOTk5LFiwgEGDBtG3b19ee+21\nxr4jR47kyJEj6HQ67O3tee655xg+fDjDhg0jP797nS26Sk97DQkuhOzD4BEBkgSRt8Mv90HcF+A3\nijWJFdTU69l5spBZUV7nHerfaxOp1xuYP6LrdW9dbcxxtTG/mDMQCFqy7rkmuxdgodeB+iJvS279\nlVXzRfD5559zww2d5+hqTVJSEsuXL2fQoEEAvPnmmzg6OqLT6Rg3bhyzZ88mLKxlTG1ZWRljxozh\nxRdf5OWXX+aLL77gueeeu6i5/xXEiuAKQaWvg7wT4BGpNIROBzNbqK/GEHwDO04q+v7daUXnHWt3\naiG/HM7igTEBLeoFCAQCWLFiBXFxcTzzzDMXtF9AQECjEAD49ttviYyMJDIyksTERBISEtrsY2Fh\n0ShwoqKiyMjIuKi5/1XEik1gpHMAACAASURBVOAKwaoqQ6k77NHgEmZqqVQWO7iMJNuRlFSfwtrM\nhD1phZ0Wk6nV6Vn0azzejpY8OC6w3T4CwSWj1ZN7TQ+7j27atInXX3+dbdu2YWZ2YSrQ5snkTp48\nybvvvsv+/fuxt7dn3rx5aLVt1bampqaNn9VqNTrdxdcJ/yuIFcEVgCzLWJefVL54RjZtmPAy3LGG\nTdkaJAnuHeVPdpmWzKKOy90t3ZZOemEVr83o26WMogLBtcLhw4e57777WLNmDa6urhc1Vnl5OTY2\nNtja2pKTk8OGDRu6aZbGQawIrgBeXnOCoalJBFo6o7ZtlqXDwgH8x7B9w276e9oxdaA7/92Uwp70\nInybeQLll2vZcCKXdfG57E0vYsoAd8b2ubh/dIHgSqa6uhovryZb2pNPPsnatWuprKzklltuAcDb\n25s1a9Z0NESnREZGEhYWRkhICD4+PowYMaJb5m0shCC4AjieVcZthnT2an3wLqmht2NTIrmy6noO\nnS7hoXGB+Dtb4Wpjxu60ImKGKC6eCdnlzPxoF7U6A/4uVjwwNoAFowN66lQEgssCg8HQpu3JJ5/s\n8v6t00QHBga2SDMtSRJff/017bFz587Gz6WlTYkU5s6dy9y5c7s8h+5ECIIrgJKSYgJVWWw2DOeZ\nT/bwzb3RjU/8u9IKMcg0uoEOD3BiZ2pRo51g8cZkzExUrH54BH162VxQIXqBQHBtIGwElxMGvVJX\noBn1egOuVSmokZk6+Ua0OgNzPtlDan4lANtTCrAxNyG8IcXD8ABnCitrSc2v5MiZUjYl5nPvKH9C\n3GyFEBAIBO0iBMHlQkkGvB8F/+2n+FZn7obaSvKLiomUUgDw7jeCVQuiMcgwd+keknMr2JZSwMhA\nZ0waKn0NC1CyeO9OK2LxxhQcLDXMH9n1WAGBQHDtIVRDlwNFafDVdKirBO9oJUhs3xJAKeDwnAbK\nNc7YWrsSbA3f3RfNrZ/uZdaS3VTW6nhsfFOuoN6Olng5WLBs1ykyiqp5/oaQxnKSAoFA0B7iDtET\n6HVKTABAcTp8PRMM9XDn70pUZG0FnPwTys5yIruM1UeyGdSnH+eKTga4WPPdgmHc+uleKmt1bZLG\nDQ9w4vu4szhbm3HHMN9LemoCgeDKQwiCS01FLnwUrVQQO4eVK9z5B7iGKt/NbJRgMWB7bBpL9UlE\nuLQsOenrbMXPD44gJa+iTa3h4QHOfB93lofGBWBhKmIFBAJB5whBcKnZsRi05TDuRVCZgKSCvjeB\ng2+73XPKarAxN8HCpK2h183OHDe7trl/buzvjt4gt6gZIBAImrC2tqaysrJF2+LFi/nss88wMTHB\nxcWFL774Ah8fnxZ9xo0bx3PPPcekSZMa2/73v/+RnJzMkiVLLuh4lxPCWNydxP8M7wRDVWH720vP\nwMFlEDEPxjwLo56EkY93KAQAsku1eNhZdLi9PUxNVMyK8kKjFn9egaCrnEtDfezYMWbPns2zzz7b\npk9MTAyrVq1q0bZq1SpiYmIu1TSNgrhTdBfVxdT99hRU5lGZuLn9PjveUd5Ht01mZTDIzPl4D+9v\nPtmiPaesBnd7kfFTIDA2XUlDPXv2bP7444/GQjQZGRlkZ2czatQoKisrGT9+PJGRkfTv35/Vq1df\n0vlfDEI11F1sfhV1bSnVshmF8RuxHvS3ltuLT8HhFRT0uZWZn5xk4WQ10wY2qW62nyxgf0YxOoOB\nR8YHNbbnlGkbykB2nD9IILiiWTal8WNjGuq+N8GQe6GuGlbe0naf8Fsh4jaoKoLv72i5bf4fFz2l\njtJQOzo6MmTIENatW8eMGTNYtWoVc+bMQZIkzM3N+eWXX7C1taWwsJDo6GimT59+RcTviBVBd3Bm\nPxz8khXcyC5DP2yyd7fts+0/GCQ1cxKGc7akhjfWJlKr0zdu/nznKQCScyswGJSgspo6PcVVdXi0\nYwcQCATG4XxpqJurh5qrhWRZ5oUXXmDAgAFMmDCBrKws8vLyLtm8LwaxIrhY9Dr4/QlqLd34T/FM\n/m6+g4l1BxV7gH1vpU/xKeRjq1huuAHJ1p13xgby9A9H+e7AGe4Y5ktKXgU7Thbi72JFekEVZ0qq\n8XGyIqesBgB3Owuo6MFzFAiMSbMn+DZpqE0tO3/Ct3LqlhXAObqShnrGjBk88cQTHDp0iOrqaqKi\nogBYuXIlBQUFHDx4EI1Gg6+vb7uppy9HxIrgr7BvKbzmBK86wr9cIC+eX3s9il5jhXfUZABKEprs\nBGV7lmEwyGywmcWqBdHMivRkiK8jH2xJRVuvZ9muU5iZqHhpqlK9KDFHuevnlCn/RMJGIBAYn66m\noba2tmbcuHHcddddLYzEZWVluLq6otFo2Lp1K5mZmZdi2t2CWBH8FTK2KymgI/8OgOwUwHvrejEy\n0I6BUYEUxdlQmbAZh+F3gkGP6ui3bDcM5O27b2gs9fjU9cH8bele3tt8kp8PZXFzpBfRfk5IEiTl\nljO5nxvZpcqKwNPeglNneupkBYKrj4tNQx0TE8PMmTNbeBDddtttTJs2jf79+zNo0CBCQkKMexLd\niBAEnfH7k2BmDRNfa9leegbcBsD4lwBIyC4jq2wnj04Ioo+bHZtU/RicuxdkGf3JzdjU5XOi1/2M\nc2gKChvq78TIQGc+ik0D4K4RvliYqvFzsiIxpxxoWhG42Zlz6hKcrkBwrXCxaahvuukm5FYJIp2d\nndmzZ0+7/S/nGAIQqiFkWWbu0j2sPpLVcoPBAMd/hJQ/2+5UehrsvRu/bkzIQ5LgupBeqFQSRc5D\ncNDlIxenU7TzM4pkGwJHzW4zzJPXBwMwOtiFoF6KXjTU3ZakXEU1lF1ag7O1KWYmIjpYIBAYj2te\nEJTX6NibXszWpPyWG0pOQW2ZkhW0ueSvrYSa4iZDMIogiPR2wMVGMS5Z9rkOgNID3+N4ZjPrVGO4\nrm9vWhPp7cD/3TKQV6aFNbaFuNmQWVRNVa2O7DKtYigWCAQCI3LNC4KsBj18WkFVqw2HlHddDVQ2\nExJlDcp6e5/G/U9klzMxrFdjl34DosiVHbDe/19M0FEZNhdTk/Yv9awoL/xdrBu/h7rbApCUW0FO\naQ0ewlAsuApprVYRdB9/5dpem4KgvgaWjoP02EZBkF5Q2fICZh9u/FhwJrmpvbRBENgpT/ibExU/\n4QmhTYLA38Waw+r+aAy1HDEEMG7U2C5PLcRdUREl5ZaTI1YEgqsQc3NzioqKhDAwArIsU1RUhLn5\nhT1AXpvG4vwEyD4EyevJtvMFoKpOT155bWMSt/ozcZTKtrhI5eyJi2N62Ghl39IGl7AGG0FscgHe\njpYEujY91UuSRInrMMjdzi7bG3nIrZlf9HnwtLfAxtyEA6eKqazViRWB4KrDy8uLs2fPUlBQ0Gab\nVqu94JvY1UB3nre5uXkLj6iucI0KgiTlPS+ebLmmsTm9oFIRBHodqtxjbNAP51aTLZxJT6CqVoeV\nmYmiGlKbgnUvanV69qQVMTuq7UU3GziLf585jd/wO9ps6wxJkgh1syU2RfmRiBWB4GpDo9Hg59d+\n1bzY2FgiIiIu8Yx6np4+b6OqhiRJmixJUrIkSamSJD3XznZvSZK2SpJ0WJKkY5Ik3WjM+TSSn6C8\n58VztqS6sYJXWkGDi1dhCmp9DXGGPtRauOGmz+XHgw0JqEpPg50XqFTEZZRQU69nTKvCMAA3RAXg\neP0zzBwccMHTC3G3obS6HkCsCAQCgdExmiCQJEkNfAjcAIQBMZIkhbXqtgj4XpblCGAu8JGx5tOC\n/ETlvaYEbfFZBnjZYWmqbjIYZyuG4lOmwZi7+hNqVsyyXaeUHEDNXEe3pRSgUUuNdYKbY2lqwv1j\nAjDXXLjr5zmDMdCm6IxAIBB0N8ZcEQwBUmVZTpdluQ5YBcxo1UcGzt317IBsI86nifzExpu5TVky\nXg4WSp6fwnOC4DDVkgXmvYKRHPzwN8kno6iazUn5irG4wVC8PaWAwb6OisqoGwlpsCmoVVJjJLJA\nIBAYC2PaCDyB5okRzgJDW/V5BfhTkqRHACtgQnsDSZK0AFgA4OLiQmxs7F+elEl9JSMrssn0no1P\n6Wnca9LIKc3D2mDgxOkKYmNjiUzaRqLeDytDJellMv7aAjzM6/jf6r1MrM3nVImBI+u3kJRbw5xg\nzUXNpz1qdTISYGcKO7ZvA5TIxO4+zpWAOO9rC3HePUNPG4tjgC9lWf4/SZKGAV9LktRPluUW8d+y\nLC8FlgL06dNHHjt27F8/4um9sAt8Rv4N3W97CCk9jV94KDmlWvZtTmHo0KGY78jksOF6xkb2wd/6\nOji1kudH2vHfzWlgBn4RozlQFwQcY/4N0S1UOd2F75FYHK1MGTt2OKAYky7qvK9QxHlfW4jz7hmM\nKQiygObhtF4Nbc25G5gMIMvyHkmSzAFnoFWYbzdyzlDsGkq5bR9CylIosrfAQqNGliEn5SD++jqO\nG/y5vZcNmPoCMMWrloOuNVAGleYebDtRgKuNWaMap7t5aWqoSC0hEAguCca0ERwAgiRJ8pMkyRTF\nGNw6ld9pYDyAJEmhgDnQ1rm4O8lPBFMbsPMizzKQACkbT2uJgIbo3spT+wE4KvsT3MumsZ6wqjSD\ne/srcvODw7XsPFnI6GAXo1Ufui6kFyMCnY0ytkAgEDTHaIJAlmUd8DCwAUhE8Q46IUnSa5IkTW/o\n9hRwryRJR4FvgTtlY4cb5ieCayhIEhlqP0wkA271p/FztgJAlXOEKrUdtVZeOFqZgqWTIjhKMvCk\nAD1qPj1SQ1lNfbtuowKBQHClYVQbgSzLa4G1rdr+0exzAjDCmHNoQ34ChCg1UhP0vbkBMCtKhN4R\neNqZ41xyhGRVAH16Nej9JUlZFZRkgJkNkp0nzqaWFFTUMlI8sQsEgquAnjYWX1oqC6C6CFyVcIaj\nNU7UYopZbjwAM20ScCvM5CPD9QT1akoZgYMPFJ4EC3tUDj58ODOShJxyHKxMe+IsBAKBoFu5+gRB\n1kH49UHQ1ynfLRxh1qfg6N/CUAxwtqyOXDM/fPLiQZa5teprTssufFM3in/1amYEdvSD1E2gLYPA\n8QzydWSQr+MlPjGBQCAwDldf9tHjP0LxKfCMotJ5INXZCRSsegjZYGiKKHYNQ5ZlsktrKLEJhrx4\nSPodj5pk3q2fhQ4Tgpt7Azn4gk4LlbmNwWQCgUBwtXD1CYJTO8A7GmZ9xj9Nn+TNultwyd/NZx+/\nQ03WccX4a+VCcVUd2noDWqdQRV204QVqbPz41aCYLIJcm6uGfJs+N6tMJhAIBFcDV64gSFgNax5p\n2VZVBHnHwW8UhZW1/HIkC13kfPJtQrkp7wPOHt9GtV0QSBLZpUo9YJVbP2Xf0tPUjlqIHnVDKmhN\n07gOzTIl2osVgUAguLq4cgVB4m9waDnkJxKbnM/9Xx+k5mSsss1vDN/sO02dzsDdo4NwjVmCs6qC\nIM4QV+MGNFUms/EOV/ZxDcNu0BysTNUENzcUg6IOkhoulVgRCASCq4wrThBI57JPlClBytojP/D0\nD8dYfyKXA1t/RTa1ptZ1AMv3ZDKuj4sSKOYRgTT4XgD+LHQku7SmURC4ubnDdYtg+vtIKjXXhbq2\nzSZqYgq2XoowsPXs1vP5ZFsa8Vll3TqmQCAQXAhXnNeQdVWGogIqVwRB5cHvKa6KZM6g3ngci+Os\nSzj74gsprKzlrpHNVDrXLaKiVsef+6Ow3pNJvd6AhUaNvaUGRj8DQHZpDb8dzeG3ozksGN2qjoCD\nD8gGUGvoLqrrdLyxTimSk/HmlG4bVyAQCC6EK04QIBvg6LdQkUO9hQvONWd4dmAd913vghSfzRt5\n4/h9YwrBvaxbBnyZ22IzczGDqg/y7f7ThPe2x9PBokWKiO/jmpKlNlYkO8fwR6Gqe1MgFVbUNX42\nGGRUKuOkqxAIBILOuOJUQ3q1OcR9Afo6vmMiOtTMtzuElLETgDTrSLJKa7hrhF+7eYDuGuFHWU09\n21IK2hR9mT/cj9ujfQDYf6q45Y7B10PEvG49F28nSxbPGQhAYm55t44tEAgEXeW8gkCSpEckSXK4\nFJPpCvUaWyhOA2BHWS+Ke43ELGk1nNoG5vYs/Pts7hvtz00RnuSXa3n4m0MUVdY27h/l48BALzsA\nPFuVgbSz1PDilFC+umsI0f5tq44ZgxGBzowMdKZeb9wUSwKBQNARXVkR9AIOSJL0fUMN4h7VX+g0\nNqBRnuQlO09chs2FstNKIJnvSILc7Xn+xlDMNWpW7M3k92M5fLg1rXF/SZIabQeezVYEb61P4rej\n2Zhr1IwJdsHC1PgpoD/dns7bG5JZcc9QwnvbG/14AoFA0B7nFQSyLC8CgoDPgTuBk5Ik/VuSpAuv\nyt4NyEgw8FYAHNz9kEKmgNpMifz1G92i750jlBv+hhO56A1NT9w39ndn/ghfJvdTXElzy7Qs3Z5O\nQo6injlbUs3iP5MpbLaSMAZ70os4ka0cs6y6nnq94Tx7CAQCQffTJRtBQ2ro3IaXDnAAfpQk6T9G\nnFuH1JpYUy+r8fLyBnM7CJqobGglCBytTPng1giySmvYcbKpzIFGreLlaX0JdFXSSPwQdwa9QWbu\nYCVYrLiqjve2pLIrtdCo53G6uBpvRwv2pBUR8c8/icsoMerxBAKBoD26YiN4TJKkg8B/gF1Af1mW\nHwCigFlGnl+7VOZnUooVM8+8CfU1MOopiH4QXEIa+yTllvPZjnSi/Z1wsjLlYGb7N9nKWh3f7j/N\niEAnfJyUmgR9Peyws9AYVRAYDDJniqvxdrSkr6ctkiR12/EyCquY99k+koQBWiAQdIGurAgcgZtl\nWZ4ky/IPsizXAzTUFZ5q1Nl1QH3JWUpkGzxO/QS/PwEeETD5DaV2QAPrjufy77WJaFQqtjw1lqeu\n79PuWAt/PEZuuZZHrwtqbFOrJIYHOLHzZCHGqpNTUFlLrc6At6MltuYaBnrZsbObBMHnO0+xM7WQ\n+74+SK1O3y1jCgSCq5euCIJ1QKMvpSRJtpIkDQWQZTnRWBPrDJOqXNJVPshjnlNiCvZ/2qbPrtRC\n+nvZY2epwc5SCQKr07XVwc8d0ptXZ/RjaCsvoRGBzmSXackoqjbKOVRodfTztG0skTky0JljZ0sp\nq6m/qHFr6vT8ejiLgb3teXZSiKh7LBAIzktXBMESoLLZ98qGth7Dpi6fOit3pDELIfgG2PA8ZO5u\n3F6hrefwmVJGBjbd3N/bfJLJ727H0GA0PnfDHRXk0hg70JyRgc5YmqpJL6hss607CHS15vdHRjG8\nIehtRKAzBhn2phdd1Li/H8umolbHizeGMmWAO6AYwwUCgaAjuiIIpOZ1hBtUQj0WkSzJesyoIw8n\nZn+yF92MJWDvA7FvQsM0958qRm+QGRHQFFkcalnGl2X3EPOPdwletI6Br/7ZIpIYgLoq+Goa7Pwf\nPk6WHPnH9YwP7dXhXB5bdZjgReu47p1Yauo6VsFo6/XnVTFFeDvwyrQwBjTEOPxVonwceHJiMIN9\nldCPPWlFjP7PVtbH517UuAKB4OqlK4IgXZKkRyVJ0jS8HgPSjT2xjjDodQAcLLEkwMUaEysHWBAL\nd6xutBFkFFVjbWZCpE9THNx11RvwVhXwjsPP3DXCj0evC2R0ULPi87IMqx+CU9th52IknRZTk/Yv\nT36F8oQ9ro8rsyI9SS+sYu3xnA7n/P6Wk0xYvK2Fvv7V306wYHlc43dTExV3jvDD3c6ivSG6jL+L\nNY+OD2qMqo7wtifUw5anvj9Can7FRY0tEAiuTroiCO4HhgNZwFlgKLDAmJPqjLp6RRBYOvfmXzOV\nWgKZVWpFCNQrN+i7R/oRt2gC5pom/bh67ELwHkbvqhM8N8qRJ6/vg5tds8ji3e/DiV+UNBLTPwCV\nhhPZZdzw7g6OnS1t7FZaXcfQf2/m852nuCnCk3/P7I+fsxXf7j/d7nzr9Qa+jzuLtZkJ21OajMHx\nWWVt7AH55VpWH8n6y/EEPx0820a1ZK5R8/G8SCxM1Sz4+iDl2ouzQQgEgquPrgSU5cuyPFeWZVdZ\nlnvJsnyrLMvdm33tAqjTKTeyp2ePQ6NWsTkxj3HvxLJ300/IbwdSlnmcWp2+hRAAQG0C094Dgw6O\nfNNym74ejv8AYTMUIRA2HdQmuNqYk5hT3uTNY9CzJ60IWYbw3ooKR5IkYob0Ji6zhMyiqpbjGvRs\nTsynoKIWlUri3uVxFFcpieZON7iONmdPehGPrTpCan5Lu4Qsy+dVLWnr9bz62wm+2ddWILlbGPjk\nZj/Ki/J48dtdGAwyOr2B0uo6o3lFCQSCK4euxBGYS5L0kCRJH0mS9MW516WYXHto0KNDhYeXL6AY\nWft62PHgpjrqa6v58dPXmbt0b4v8Qvz6IOz5CFyCIeJ2sPVoOahaA3ethxkfKSuL6mKIfRMXbSYh\nbjbsOZkHK+fA8hnsPFmAlamaAV5NKSHmDOrNusdGNcYhAErKi7cD2LVzC2625rx4YygAu9MK0dbr\nySuvpXcrQdDPUxEux1vVJ7h3eRzP76zp9Lr8mZBHuVbH3CGtKqiVnoa3fIn6Poo40wW8nzkDTvzM\nqcIqwl/byIdbUzsdV9DD/P4kvOrY07MQXOV0RTX0NeAGTAK2AV5AjymbTdFRbuIMKuWJ31yj5qu7\nhvDETcPJcpvAPPNd3B3tgaOVqbJDSaayAtA2qHdmfAAD5iif66ph06tQWwmmVmDWUJlMNsD2d+Dg\nMkYEOnMmMw1OboCMHRSl7CHa3wmNuunS2VuaEupu2zTJ3OPw091QU4J0Zh9zBvcmvLc9NmYm7Eot\n4myJ4pLaekXg52SFtZlJi0I1BoPMpsR8cqvkTmMCtqcUYG+pIdqvVbK803tBXwdjFsLkt8BrMCor\nJ1xszBjY256v92aiE6ktLl/iPgdZDzUi6lxgPLoiCAJlWX4JqJJl+StgCoqdoEdQo6PW0q1Fm6OV\nKbdH++A36SHMdOVMNTnQlIL68NfKe8TtTTvUVUH6Nvj9cdj5X8iKazEeVs4QOhWOfMNoPxsydE7s\nu3kPBhMLxlauZUTzOgcNVGjreXzVYTbEJcCq28DGg/qHDzM85jlihvTGRK0iOsCpMXp4YlgvgnvZ\ntBhDpZII87BtsSIorm6qWZCc2778lWWZXamFjAhwblvTIGQKzF8Po5+F6Pvhnk3gPxZ7S1MeGhtA\nXnktW5ML2h1XcBkQ853yXniyZ+chuKrpiiA4Z10slSSpH2AHuBpvSp2jQYeqo3KRvqPA0R8Ofql8\nr8iFwyuUXETNi85v/Tcsnw7HvoNxL4L/2LZjRd0J2lJGrb2Oaf1dMLV3Rxd2M7PN9jEp0LJNdytT\nE46cKaVs6/sYynPImPAx1Va9mdzPHfeG7iMDnTldXI25Rs2ndwwizMMWakqhwRMKoL+nHYk55Y1P\n6c7WZmx/ZhwScKqwqs1xAQor69AZ5HYFFKZW4DNMsZGA4h1Vehr09VwX4oqrjZli6K4uhrwTTa+6\ndo6lrwetcdNWVGjrScotb3xpdde4DcMlWHkvSO7ZeVws1cVgEFHulytdiQdY2lCPYBGwBrAGXjLq\nrDpBgx5Ll97tb1Sp4MZ3wLJBPbJ3CVTkwJT/a9kvYh7s+VB5Wh71VPtj+Y4GMztUVfm8P8MXrB1A\nfTdIMp6WbVUpKpVEzBBvnlt3IyulEI6tquThcek8pv0Yk5xDcN82ZoR7MDGsF262Dd5KBj285aNk\nU52pxOjdM8qPu0f6oW54sq/XG+jtaMHHEyyZFN6+AHSxMWP/C+PRGVrdNA0GiH1DWd24KwVwSPwN\nvr8dFsRi4hHBnEG9+XZfJoZPx6MqaeYVHDQJbvu+5Xgrb4H0rfCK8WosL/zpGGuPN8U8OJpLRA2t\nxcXG7MIHqymByoKmm+mVRtIfELdMqZXdnmC+hKTkVVCnMzTasS4IWYYPBoHvSLjlqxapYASXB50K\nAkmSVEC5LMslwHbA/0IGlyRpMvAuoAY+k2X5zVbb/wuMa/hqCbjKstxpYn4VBqxdvDvuEDi+6fOA\nOeA3CgLGt+zjGgoP7gVHP0V4tHsgFTy0F1QasHbhbEk169IcuHHcYjxt2/f1v3OwC/4uQ9DpBykn\nZGaCuiQUDn0B2Yex94jA3lIx/lbV6vjmnqFg4wG5xxrHaB5HUKvTM+T1zTw+IQg/k85/PJIkoVG3\n6lOcBtv/A/beTYLArb/ynn0EPCK4b4w/D4/zR5WyCHKOgmeUYug++SfoasGk2Q04favybjB0fN0u\nkg9iIlkTlo2ZiYqKWh2Lfj7GG6sPsHhwBRSlQfBkcA7s2mDLbgQLR5j/h1HmanQydkHGDlhU0LSi\n6yGWxKaxN72IPc+PP3/n1mjLoLoIElYrqthRT3b/BAUXRaf/XbIsGyRJehb4vrN+7SFJkhr4EJiI\nEn9wQJKkNbIsJzQb/4lm/R8BIro0tp1X1ybRq6/yag/XkPbbm9PgXXT0TCkzPtwFgIOVKbPdC8Hc\nVlFDnSP7MGZfTmVizCpF+JyjZg5s/IeirvKIYHdaIRsT8hgf4qo8GQWOh6TflaemhielFXszsdCo\n8bC3oKymHi8HS46d0LHsi/0svSOqRf4gvUFmyns7uHukH7cMarVSyj6ivHuEN7U5+IK5PeQo22zM\nlTxMhrCbIexmxcbgGaUk8WsuBEoborAnvWE0IXCubvNNEU0rn9xTydzpngDfPqM0yHpwfuz8g+Wd\nUFZcmTsV/bpz0Pn3udzIOQK9+vW4EABIK6ikVmdg58lCRga1o4LsjKoGG5SNO6RtgRGPNTp7CC4P\nuvKL3iRJ0tOSJPWWJMnx3KsL+w0BUmVZTpdluQ5YBczopH8M8G0XxoWObARGIsyjySNopLcZfDEZ\ndr3bstPBL5Ubj/uAlu0W9tDvZuUpu7aiMe9PZa0OUjbAyY2KCqO0yf9/zZFs/thzlMNJJ1GrJIb6\nO6LVwbaUAlJP50LxCJRUeQAAIABJREFUqca+x7PKSMqtaBs3AcqNxMS8RXpuJElZHZwTEkDe/h+Z\n//ZyYlMawkPsvJRXc05tU979x3Z2qbrM6aJqtPVNOuPKWh2j397K78eyW/Qb4GKC7YkVyL36orUP\ngvTYrh0gZT0UNujVD33VLXO+pMgGyDmmCPGENbD0/9s77/CoqrwBv2cmvZJGEhIgCYTQAqF3CIhS\nVMSGKLq6FtRVF3VFcd31s++6uhZcV8W1N+wKqIAgQZDeQyeEFhICIb238/1x7mRmUocyRJjzPs88\nM/fec+89d+7M/Z3zq6PrAiYB9Vs7vvvcdEVK9h8vJrekkqcX7Gx5B4N92UUqONIvHK77GG5eADd9\n26QQyC+tJK+8EQ+2qnI1G2ykXzszW7ZZHT5Z2mwKmLNN0ZEdLN+VScqe4/y69wQlFdUt73QGbDyU\nR8qe46TsOc5Bw45YXlVzSud2ZKhxnfF+j806SctqoijANpmPJSq5AUKIjkAs8EsT26djRDP3izSx\neschKvY7JytoU7TzE2QWS3bv2IEMHUr4pk/YRC+K/Tthri5lyJa5nAgbxp41mxvsG0hP+lR+wo7v\nX0H6DwMgyq2IrF/mEFms9OHbl3xCTthQ1V5W8HbODRTnePNNwHtsWvMbYW7lgKDi23uh6Bc29HuZ\nYv845u9XXkUyew8pKXvtzpu0MwWTdwc2rfjNbn1cdQjRx35jxS8/I4WJYSvv44rqQTz+VRhVg73x\ndBOE5KwlsGAX6Z1uAaBt9n7iPEOo+OSPpMfdTEGb7qf9Xe7Nq+H5deXEB5mY2d8Ls0mQcqSKjLxK\nstN3kZJrvQ5zdipkbeXLwNsozT3KjQW/sGrpYmrNHs2eo/O+jUSYfckL6kXg+g9Y7TYKaXI/7T6f\na+TJ/VBZxO5Cb2pTt9A9cxPrF82lxC8GgPaHv6ZT+ods7PsCRQHOtYGcLKulpLKGUG/Bnuwivlv0\nC208mx9DZhXX8ujKMi7u6Ma0bp6AP2RnABn4FaXjVZ5NTtgQu33uXlJCWTUEeaXYre+8bw7RR39g\n9eB3qPCyzkY+2FHBsiPVPDbIi/igxoVLVa3kjsWlJIaa+Ut/r0bb1GdfXg1uJogNPPVZi0dFHkNX\n30J29Sgerr4TgPExbkzt2ryNq7i4mJSUFMqqJWuzqhkc6YZXC+pggD25NfxjnXWAcGVnd67o7MHJ\nslr+srzMoXODA4JAShnb4lHOnKnAV1LKRsW2lHIOMAegfzs3OeTiySoI7Bzy85BqqmpqaePjAf17\nwJxk+qe9DNOXw+75UFNO5KWPEtl+QMOda4ZBx0B6dBpNj4B2jBhWToifJ+Z3X4Co/hA7gp6JV9Sp\nsUo8t8IiWFeTwMS+cSQnJyCXLcPfq5LoSmXQ7X/xNeAVwFt719AtsopJl4ywP6eUsLkAuo4jOTnZ\nflvXEMi5jFFdR8Kx7bC8lK7DruDoMsmCE22YPTUJsXwNbP+ODje8DN5BQDKcvBGv1/rSJzYYetc7\npoMcKyjnoddWEujjwe7cSlaXhvO3y7rz0n9W0jXCk1uvGGF1/QUy3/ovuHlz0U2z+Meb7+FWvZCk\ndm4EdGvh/NnvQEUUYeMfgo+vZlRHM3Q6vT63Bhvm74cOQ+g65galDtv1bwbE+EPPZNVg5RZIh35i\nJyQ7N+PLin0nYPk67hrTlWd+2AVtE0ju0/ys/NkfdgIHGNqrC8kJ1ZB/CGKTlZrr27lwYDFc/Yid\nmrFq8Y+AZNiIkXZxOuyYBcCQOH/okgyo2cC76euBE4jQWJJHND4uTc0ogMUrGdytA8nJjg1e3nhr\nNdW1kq+vGOpQewulldX4yHJYDVPcltP59nd57qe9HCirJjl5ZLP7Llu2jG59B5ORV8b7S1bRrWsC\n4wc0Yws1+HbuZgK8jvPuLQMwmQSRgV5EBnpTUV3DK6nLOVDm1uK5wbHI4j809mrxyCo3ka3SOtpY\n1xhTcVAtJIX5nAsBAF9PNyUEAPzC4LqPoPg4fHULrH8H2naH6P6N72x2hz7T6mwObQO8MAsgZ69S\nJY19ws6W0bd2OwBfB9zIOKOushCCnu0C8ajMVzERXgGUlRSz5VCOXbrtOoSAGdvg4qcabotIhJ5X\nKxuAYQDuPvQyZo5LYP7WTN5ZecBQAUk4sEJ5rFRXgq+RpK/k9OMOVqfnUFFVw+fTBzN9ZBxdIvzZ\nfrSAbRkFXD+wg50QoLaGoLwt0PMqQkLbcssNN1Au3fl60dKWg+CKjoF/BMSNgXs3QKcxp93n1qDY\nv5OKdg/vDiGdAWEfSzD8fuVtlvqVCoh0Ir3bt+GT2wcxZUB72vi4t1hAqaK6hq83HWVCzwj+OCxW\npW/5+Bqrt1BcsjIeZ2+32+9f1yi16qH6NUDK86H7ZOgyrm6VEIIP/jiAUD/PBpH4tli23dhIqvmm\n2H+imKN5Zfztu1SH9yksr+Ky11by+qpjyjMK6Fu5iYu6hZNTXKFUwc2QcqSaMS+m4OtpJiHcv9FU\nMfWprqkl9WgBV/aJon9MMH07BNU5m3i6mblhYEf2ZBfVJclsDkdsBANsXiOAJ4BJDuy3HogXQsQK\nITxQD/t59RsJIbqiaiCvduCY1JhPw43QGUT1hctfgW6TVLTyhOebd4vLP6IinGuNB1jJCfUDD01Q\nEc5H1tel0Q7PWUM1Ji7rKOnha/2TJ3dwo43MR4Z2gcoS3D+cwJx287m4e0RjZ1SjLQ/fxrdlboGD\nK5XOPTwR/MK4e1QnJvSMYE16LrJdX/DwU9s3fgDPx5BTWEKNyYPdafv5Yv0RVu0/9YpqV/aJZvnD\no4kP9+evE7sxpX97Pl9/BH9PNzsjseq/mXUDX68TZj3j2vPjxFU8eWwoLy7e28jRbSg+Bn4R6jtw\nkqG4rLLGrhb2WUXaCDp3b2jTgarsXWw8lKvKs9bWqliXyiKVLNGJBHi5M6xzKAFe7gztFML6g7nN\ntl+8I5vckkqmDuxAQVkVGRmHlEu3xTYQO0q929h7DuaU1D3E7HJtFWUrF/D2g0BKigpymf7hBvaf\nKEYIQZ8Obewi8euTerQAP083DueWNtvOQn5pJTnFlZhNgo/XHGZHZsv71NZKHvx8K4dPljLWvEnF\nLPmGwcb3+eOwGNY/NhY/z4bKl9X7T/LF+iO8s/IAH++qZEBsMPFt/Zk6sD1bMwpa7K+b2cTPD4xi\n5vjGHV+GG3FFq/e3XOPEEdXQfbbLQog2KMNvS/tVCyHuBRah3EfflVLuEEI8BWyQUlqEwlRgrnQw\n+1mZd6Qjzc4NSTc43nb/Upg/Q/2gQzpBwREwe6qH1JZP4MeH4IEdEBiN6dg2COvChJ0zId5XzSaA\nOwcEwcFERHgP8PDFrcMgRqx/G4ovBq6xP9+aN+BkWsMYCguL/6YEUe4B9UBBjbJevi4JD7MJYRLK\n7zs9BQoyICCSTScEPWoC2LEvjYd3KpfX2df3YVLvdo2fw4b80kp2ZhaS1KGNNf2HwdBOIfh4mgn0\nbjjTkyZ3FeltcNWgLhwuguSEhjGNUko2HMrDbBL0vXVRnWCltha++iO0HwhD7mmw3+ny7eaj/PXb\nVH6aMcI+xciZUlvL0FW3gNsMa5xL/MUcyqvl6jdWszk5laBtb8OMrTBqFkQ3oo48i3y7OYOoNj4M\njA3m8ct62N0nKSVCCHKKKwj1U4O08AAvruobxYjOobyweA9J+/YTHhZK3V4BkcqBIT0Fhv0ZgAe/\n2EJZVS1h3sI++67ZHS55VnnXfXgFBaVmFh+6nT8MiaFTmB/TBnXgZLE1+r4+GXml9IwK4L7PNnNx\nt3BeuLZ3s9e63yhE9dC4Lsz6OpW5647w9OTmYyeW7zvBkl3Z/O3SbiSsmwg5IyFpGmRswMskoX60\nv8Fn6w4zb6tyjojwFbx6XR/MJsGVfaL450+7mbv+MM9EJTa6r5SSqhqJh5upUSEDysmljY87u48V\nNeulA47NCOpTgjLstoiU8kcpZRcpZScp5bPGusdthABSyieklLNOox/nF5GGC6fhtklUP3gsS42O\nLNssnjx3LMN0yw9g9rB6voASIHetRHYaw4uL9rCx60PQfjB8f6/Kb2TL7h/g6Kam+9MuCU7shftT\nYXidFy9e7mZMJkFWQRnfFyVQ6+ap8izFJXNJjwiCu43iksF9WfHwaAbEBPHS4j0Opc1ek36SG/63\nttE0GWO7h/PIuHqjGinh/cuIyFpqv74wk/uPPEBSqZpAFhlptVfvP0lZVQ33z93CS4v3KjVcoDHD\nMJkgczMcWddiP0+F0V2VqmzlvrNTa7qOvAN4VBWAj42b5qX/xn/SPzCbBAU7f1ZqL08/GP2oY67Q\nZ8CzP+ziq43K7yMi0AtvDzWyn7vuMPd8uol1B3IZ+S+rx9fA2GBempKEySS4rn97QijgWLV9OhXi\nkiFzE9RUU1hexdaMAi7q2pYXRvlwue3AwicYht4LYQnQLol22csJI49BccpxMTmhLVf3a9qd/MNb\nB/LOzQMYEqfSu7Q03rTMRvp1CObSxEi+23yU0srm1TqfrT1MqJ8Hf0j0VrOXyCS46HEVv2J247N1\nh5ny1uq6c1ven5jUg99mjeG3WWN4Zph3XUndNj4eXJoYyaGTpU32d8OhPIb8Y6ldivz6mE2CXx8e\nzSNNzBhsccRGMF8IMc94LQD2AM6di16ItO2uHuw2bpuYzMp4FtEThNkqJEwmNQoO7qQe1jZMeXM1\nF/17Of9ZlsbPe/NhyofKRXXuNBXGD+ohanE9bIrIJKipUKN934Z+4buziphxYCCv+9wNwCqpRibe\nU9/F/9KnaB/sw+vT+vLFnUPsDXtNkHq0ALNJNDpydjebGuZIKsiAgysw1VbYr/cJVQ/1tCW8tnQf\nl85eScqe49z87jpeWLSHqQPaszdtH3kLn4O8g9b92iVZv98zZNnu4/ywLYvIQG86hfm2qDM/ZTIN\nzzOb+yelpLK6lkviA4ks3EpNzChr+8NrYYtjntenikVVYqmtDfD+bwe499NNPP79DorKq+kVHUj3\nyABmfrmNj1YfJDPfmik3JtSXaPcidhV51ZWJBVQSxAd3gdmNtelGRcHGUqRkbIBCo+hT35sxUcPN\n3ivrfnMWF9K92Y3n4RJC4OvpVleDvKk0LRYmJEby5V1DiAry5vpBHSiqqGbBtqaLThVXVLNq/0mu\n6dcej+PGYKxdklUNVnKSmpoa1h3IrTv3jLlbeHL+DoJ9PYhq401UG2/c6v3+/3F1Ih/dNsjeZmbD\nZ2sPU1ldS+e2fo1utxDg5Zg91ZEZwYvAv43XP4CRLjGCP9u4eSiDsOVhtOgxWPGS+uzurabKmVtg\n4aPwy7NqfVgXZVC28M107i54ifScEkbEhzJzXAL4h8OUj5QwqCgyMqr+H1QUWGcajdHOiN1b+Gij\nm0d3bcsDYxOoSVPG5AWFnRqMTtr6e9E2wIuaWsnn6w9TUyuVUXnbl/Y+70Dq0ULi2/pZ4x12/6ge\n9k1hfE9F/p3s17t5QMwwSE9hWHwoWQVl3PLeesIDPZlxUTzX9m9PgvkoQWuehwIb34TIJCUYmsvi\nmbFRRVfX40BOCa8t3cfspft4Zcle/jx3M28sT6O6ppbhnUNZdyDXLjNsTa1k/tbMutmKI2w9km/V\nCWdtoVa4QVi3uu3H07fg+Wo3rsp7B0+q2ORmVXHUrPsf8qeHobKE7MJyZht9nb10H2+k7OdEUUX9\n06n4lUbyF+3fvpbtq36yLhuqEtsHzq6sIhZsy6JtgCezp/bBy93Mf6f1xd/Ljb9/v4Mn5u2wO+be\nka/xr7LLefc3a/xLuXug+t0Dv6Xl4OVuom/HNvxyuIpxL/9q/a19fpMKyAQI6cQurz5cI5bW2dqE\nENzy3jreXLYPNn9il4pj4fYsZszdTHFFdZ2+/Dcbod3YaDvAy50BMcGYTYL+HYMY3yPCqnopy4N9\nS6yN17yJn7mW32aN4c6RccZvVkCEEUt0ZB281JVJmS9zn/kbChc9x8n9m/ghNavJ6ocWLEGjheVV\nDfqZX1rJD6lZTO4ThY9H89r90spqpn+4gS/rl+WthyOC4DCwVkq5XEr5G3BSCBHjwH6a+kQmqQeN\nlMrAd8ImIKhdkpoqb/0MCo2gqtAEyDugUj0AHFlLB3/oEu7H7Kl96vIR0X4A3JECQR2VIfG3V8Hd\nR+n4myIoVqW3sPHEqM99YzrTLqojGzwH8fdrhqrRybq3YXZfq/4dNUJ+5OtUXvp5D1SVwurXYN59\ndW2klGw/WkCiJU9NbjrMvR6+vavp/mVuAWGmxDem4baYEXAyjb7BVTx7ZSKRgV68dWN/2vh4EBHo\nxeh26qFc5WtTb9oyum7kQV/H/8bAWw1d7Q6dLOHlJXt56ee9vLJkHwFe7rwxrR9uZhPDOodSVlXD\n5sPWKfrC7ce477PNHMltvoaEhcrqWm77YD1T3lqtVGfHd1Pq014JPYMdhd60FfmMLfqeKtx466C6\nNiklL+cOQVQUInd8S3ZhOS/9vLfu9fzC3dz2wXq74D32/azyRqXYZXxBSkn7LyfQc/FUykrUCNui\nKrEVBJf2iiTM35O3bupHkGHvaRvgxRs39iOqjTd3jLR35Rw87CKqg7tQaFTkm781k9EvppC/4m2Y\ndx+/peUwMDak7uG3J7uIrIJy5ZVXlGk3M9oUPJGI2uPqv2KQGBWI56EU+P5PsMFaKmXFvhz27t6G\n77d/oCOZRLXxZt1BNRDYeiSfKW+trgvwtPDOygNsPKTaCCF486Z+TEw07JLbv4ZlzyhhU1EMCx+B\n1C8J9HZX30PmFmXzs6Szj+wNgdEEpH7AX9y/IintdSq/n0FNrWSqA66hq9Jy6P/MEj5cfcjuHj36\nTSpVNbVMG9zyMbzdzezILGTJruxm2zkSUPYlqlSlhRpjnXMtVBciI2fCmL9BZTEUHoVQm0CgwXcr\nt86FsyDOmPb3u0XlSzK5Y6qpgLxDdEq+nkWjRjacMlr8sX2C4fFcQDSfCsJkgr/sara7JpNgyt1P\n1BkEAZWBNHe/Gh35KD3t2O7hXD+wPa8v20/PdoFM6DIelj+vjLMD7yCzoJzckkoSow1BsOlD9V7R\nTFRo1lZo243axrzELLOZrK1M6X8x1/aLtvs+RrWrgROQXu5HgmVlZJKypzSF7ajLJt0HKD30nmcm\nYDLWmQR15xvWOZRv/zTUKuSAuesP0y7Qi4QIf/vvrgmW7Momp7gSL3cTd360gZ+GXUIWHbH1ddp8\nQtBLBhAcGkFa9BTu7qNGnf9N2c9/0ttye3AMbTZ+QOJt09j/3MS6/ZbuyuajNYeoqKpVs7HcdFUr\nA6kGGTaUVdXgI5TASF38PgOvvI/9J0rwcDMRHWTNuDuySxjr/nqRuq7Ur+CnhyHpBvpd8gwrHxlt\nf71leXjsms+yO5KRAcqbvFtkAEXl1SxatYEp5V/w6h8eptJN2RAifdVvNu14Me0wZs82M9tpN94O\nBxPs/js9owLxStuknmb9/li3fvvRAu70W4nYsxAmvsjXk70J7dSTnOIK7vp4I2aTwNNmZF5eVcMz\nP+xkxkXx9LOpd15cUU1NjSQw9wAc36UGWUCpfyyHfpiNb4cr6RDiA1e9pdyWLbh5wn2bQNYy6+tt\n5G9fjCj3ZWinEGJDm/Dms2FwXAgjOofy9IKddIsMYGBsMOsP5vHT9mM8NrEbXSNadlAQQjC8cyg/\nbW9avQWOzQjcjBQRABifmw/r1DROYJTSx1v8wcMSrNsiEqHaGJ1Y3OsCo9QIw2TCuywTkBAa3/yD\nRQilnzyL+YDszudneOuU2OvFn5jUg8mRuaz48lX2dbldJYdbOAsOraatvyfz7h3GeCMmos6ltbpp\nbw+CYtQxGiOyN8RfUqdaqP99xHoWIT39SWhv41brEwy3LWo6RUap4WI3/p91QuCZBTtVTAXKjmE2\nCcwmYXc+X083+nQIws3QWR8+WcqKfTlcN6ADZVU13PHhRhZuP0ZzZOSVEhfqy4e3DmJQbAhiwG0c\njb7crk3q0QIy3Tpg8g6i2+SZ9OsYTMqe47y4eA+X944icPjtkLEOcXxnXT/NJsElPSL48NaBBPq4\nKxWDVxvofLF6Fdo/HHw83JDjngMgYOcnAMwcl8DSB0dZZ58GQgglMBc9pr67PQut6205mQ7z7kNk\n76yzA3Vu68e/p/Tm6/x4hKylW/lWktqrXJORfqrN/hPFVlWLbdoWn2BVUtbL+hBMjApkmGk7ReED\n1Gi8poqqmlrSjuUxtvxnNestzSXi84mI5f/knk82kVtSyb+u7sXTC3ayZKcaLaefKEFK+9lPSUU1\nvZ5YxIerDyrVYlCM+n0IwY8e4+lWvZuICiP9had/Q1dl4/94SWI7tnr156fCWK4f2PJIHtRA7OWp\nSXQI9uFPn2wkq6CMgbHBfHfPMG4f4Xic77D4UArLmzd4OzIjOCGEmGTx9BFCXAGcZeuYC7HqNav/\ndGi91ABLnlDv/oZKQ0pY/z8IisW3xNDxhSbQqlgMyyXH7dI7e7qZeS5yJTLvO675dBTf3PkG3u+P\nhS/+gPudy+kVbeMJMnKmChAyNfPzu/RF9Z6S0nCbVwBM+7LJXU3F2eAXQX5pJa8s2Wfn1WSS1Tx6\nWWJD3Wqemn5/tBt2Z6VSXFHN91syuXVYy3+4tONFfLzmMA9c3IW56w9jEjBlQDRuJsGJ4gr+8sUW\nft0XhUB5ckwb1JGECKsXzfSRnbh1WCxuZhMDOwRAWa7dDMWiWvP1dIMja6G2hp3HSrjlvfUkhPvz\n/NWJiKoOqhxr7oEGiRYt7p33fbqZBy/pwoBr3lG2JDdryoXC8ioOnyyl55B7WHjMnw82HOff+WW0\na+PdoKRqHSf2qHiN0ATl3VZw1OqpZaHEyF/lF2a3elyPCHaOGk/p6n9RuOBpIqrKoNe1BHoIArzc\nlEqqfIsKpvNU31VOcQW3vLeOWUP8GF7xKwy4Azx86BVSS6g4yBbf8fT9QsW67h3+GiNqN+BXnadm\n1uE9kEnTMK98kSk1a/lH53bE5B7lzl3tcTebGJvxH8oq2wNRdoLA19ONjiG+KjCt5JASBMDxonKe\nz0pisqc7Hls/Bnmd8tQbck/dTNmWMV3D+fIufxb9uooJGS9DtyfBw/hei5oeKAR4ufPWTf2YOHsF\ns75O5YNbB9YJTUcZ2qmRgNN6ODJsvAv4qxDisBDiMPAIcOcp9URjJfVLSFuiPIKC7XWpJE2DCf+y\nLgsBv82GrZ9R5R6gRsghDqZgdha+lhlBvUCqsnx89n5PRdereenGYXgHBMPUTyF6AF9vO8GyPcYD\nIXOLMvSFxqs04I1R42CSrqYiaq9+h8qbFzJj7hYWbMtk0Y5jLNpxDM/UT3hs2yVUlTQSqBPend2T\n5tP30P/otu15fkvL4dJekfx1YsuudyeKKnl/1UHWpp9k4Y5jjOnalshAb7zczbx1Yz/iwvxYbPRh\nz7Eiaz0KILdEzYosMwpOpsGLnVmzeimFhrFZSnhyUk9qh82AjsNA1lJWVUO/jkG8/Yf+Sqj5hsAD\n21XtiUZwr63gruz/470P31N6cQ8fu1njt5uOcsNri0jft5Oh46bwyiP3Euzrwd+/286WI024KFoG\nNGOfUO+WxIS2WH4nvg3jPv58SQ82Bl+Kf+VxOKZsN56Vudzf6ZhSnVzytArWNDhWUM72o4V45e9T\nBuTDyoW4bflBpLs38UMug8D2sPsHKvKPcYfPcqr9IqHzWBACMfFFUn2HMt5rB3EnfsGUsZ6hnUJY\nmZaD3Pk9vTb9jUBRSkyIvdqmZ1Qg2zPyrTMCYOmu45yo9ae000Rlc0lbAitebHZwEx3kw229vXBb\nP0el5Ab1f3g1ifBjjaZZAyA+3J83pvWjtLK6RVfWxgj18+Tru5tPl+FIQNl+YLAQws9Ydm48+4VO\nZG81+rxvY8NI5Mn/bdg+rAvk7CGv602QfP+56WNz+EeoojXeQfbrU7+E6jKCR95BsMVFtG1X5NRP\n+MezS0iOr2F021KYkwyXPKNsH6lfQsKEhgJx+fMqyG5GM4bdje/D/PthZlpD91ezGx4BoXxwa731\naQI+fgOv/B2szOnOu78d4I0b+yIleLl707XvSNgaTo/qLG6842KHv5K+Hdvg5W5i1f6TLLhvOHml\nVm+hiEAv5t/X0GhfUV1DTa1k3Cu/MjmpHY9dauTBKVSeVBuKgvh+81FuGhKDySS4tFckcBUMuwqA\nfh2DGv65TWYlZEtPNhiBB1ZkMapmDQtqB3D3JxuZO60znsufgV5TkR2H8tm6w9wasoO4T+6AP28m\nADg5/798sW4YA2ODGx+FHliunA66jFeRtOkpDYMsi40BgG9Yg93NJsGIGe/Zreuy9w2GFu2G8b9A\nSBcVO2Ng8X5yix0Gq9zV+TpfBB2HYJ51CH+TGdq0hdX/oW/ujzBiolKFWVw53b1InPmT3fmGrz7I\noh3ZZP3hLdp9MZ5b/Nfh5X6tXZvEqAB+2nqY0jF34xOn7Ey/peUQHuCJ/+QXwSsQvrpVDdK8WtDb\ndxym2m18H5Kuh+JsCOpIbnC/Zncb2z2csd3Dm23THLY2j8ZwJI7gOSFEGyllsZSyWAgRJIR45rR7\n5OpEJqmI3vxDLbcFY9qdpozFvwd8glXlsrhk6zopVSWtyN7Qrg/HCsq5f+5mth7J51hhOZXFeczM\nelC5AgoBPSarEp2L/qpSa9Qna4v6czWXUyo4DpD2cRmWvvzwEOxf1nCfSMPInLmFwvIqftl9nL99\nu52r/ruK+Z/Pge3fqPuTvd3xWQlKLTYwVo0sfTzciGrTeOEiCxXVNUyds4Zr31zNiaIKBsXaTN0N\nl1eTXxifrD2MlJItR/LZfNjB4vWfXKMq0NXHiKm4cswwNh/O558/pyuj/dENbDmSz+5jRYyNKFXV\n0ALbU5R9kJBtbzPRtLZxX3UpVcLCuGQ1sxh4pwqSrE9JDngGgLuDmT/j71RG1tcHULvyVeUSbZBd\nqGxoocFBKkL7m6+UAAAaeklEQVTfJkXFgfwqXl9+gNLAOOg4DLnpQxjxEAxqPiGfJXZhWVE7ZEQv\n7gtcae84gJoRVOPG+pjpdYWvxnRty92jOiH82qr+Zm5u3l3bghDQ92Y4skalEe8yDu5eRZXHaVR+\nO4s4ohqaIKWsmxsa1comNtNe0xwWH+Of/8+x9qHxUF3GyBVT4NcXnNevM6EsTz0MjFQVvp5mFu/M\n5tO1h0nNKKAYb7x8/VUltvhLVK2DNobBrL5AlMbDvaU/laXiWla9tN/l+bD+bVWYpj6+IUp1kLmZ\niYmR3J3ciS83ZrDrWCHDT34Na99UrorV5fauvbbU2kRRL30aPrsePruevxc9xd15L7By8/bG97PB\n083M4LgQBmfPZZLfbpITbEbLhUcBQY/oMHYfK2JrRgGvLtnLrK8dTIAWN0qpTOrHCBiCYGj//tw1\nqhNL08up9QqiKiedh77cio+HmQTPXHVvzO74JSRzoDacme6f0+WX6eo6q20GI0LAjC1w8ZNqedRM\nGNSIxnjUw3Dbz471HajwCmPH8NcAMC153O6hfNyYEYT5eyoBdGybegC/OZycHSm8sGgPt72/gTkl\nIxC56SxY0vJ5Y0N9GRIXgptJIPrdgtuJnQ0i8hOjAvnHhGgS/Mrq+nNV32husdiP0pao++bfRM6v\n+lhmTd//Sb3/Dor0OCIIzEKIOh8+IYQ38DvJ/HYe0i5JZf60SevQLLaeRX4O/tCczYeT4Yubrcs+\nwXDnCjXSQVU9m9S7HfO2ZrI6/SQIEx5T3oMeV0GyEYvo7qXiGGyjf0GF6Jccbz4qGtSMITiu4Yyg\nyPCXbupPGdm7LljtoUsSmDaoA89M7klQRabS/9ZPBWJL/mF4Y4iK5AWl/y44AgVHiHHL43K3tfTf\n82Lz/TZ4aKA3f3f/mNnVT1ntA6CC7PwjGBjlhbe7mU/XHiL1aKHjtYK7T1bvB1far887CO6+4KsC\nEeffNxxTcAwi/xCebmbuHxuPe6HVGCpMJvIHP4LwCcVclKGuU9ZLJWIyq/tgoaKozuheh0/wKafA\n8EsYxUNVd5LW4To7VUuInwcj4kNVvEFcsioju+o/cCyVbp06MjgumIKyKn6oHsgqj6HEh7Ts3CiE\n4LPpgxkRH8YTB7uT0++BBgZvfy93rjctIWJOIlSVsTe7iKwCmxiRdn0hYSIMuM2xC/QNhbFPQrfL\nW257jnDEa+gTYKkQ4j1AALcA52HJp98JZne45t2W21mIHgBXv6N8v8Na2WOoDmmMXC2Lht+9sI5s\npg7swNz1R3jvt4N0CffDOzAUrrXXBxMU01AQWB7sjkyzI5Mgo55qySj006Qg6HWdMshKidkkePbK\nROXGujBD9SekM/S4sqHQrSqDz29UwX4+hipn0uy6ze4A6cutNaFbwFxkBA3WNy72uBKiB+BdLLh3\njHIMyCnOIDHKwaR2bTqoB75tympQKp92SSAEZoFKHBcUg1vWVn6cYdSyWHsIEqwuu30m3gYT6z3c\nMreoWIS0JSoa3kgaB8DbFykHgBs+t64zvN7saom3QHSQD/PEaIIjYvirzfppgzoybZCRTjqqLzxy\nEOb/Gfwi8Ivqwdzptja3U6utvP1oAe9vzOXyu/9MqH9Dr5/S7P2YvcLw9PDhmR/WkZVfxs8PGm7e\nPsFw/Smm+Bj+O7D32eCIsfh5IcRWYCyqMtkiwPHk3pozw+xufej+Xuru+obZlcvkv0OUb/doa7qK\n3tGBdIsMQABz72wikCsopqGnSZv2MOhulX+pJZKmQceh9gFgFle8pmZP3RvJoG4Z7QbFKBXXte/b\nb5cSFjyggtyu/xxCm/DcsgQCVlcqlUWHRgvyKToOUZlDlz+vhIwRE0G8YaROSeGe0Z352fBxrwvG\nawkh1O8kp55qaNyzDduGxCsVmkX9MuGfENBCPfCUf6q6w7KmYSbXmOGw7XMVdGix7/zyrLIJnYIg\nMJsEcaG+9umo62Myq8Cu9OV1XkGnS3FFNdM/2ghA51A/5QZq9rDeCyAvYy9ZpUG0Lyxn3YGTDkUG\nn084GnWUjRIC1wJjgOZDUjVnlzVvqPf6njqthW9ba0BZyUk4satB3QMhBHeMiGVEfChebk3oQMc9\nq7ynbIlIVA+kpuoo2BI/FgbeYf8QqChSMxP/ZjwsSnLsVRiWWYmhFlFtTqq6wADr5qjUH8l/tRsx\nN8nSJ+GDy5vO/lpwVOViatcHYkcowzlY7SPlVvfWI7mqSMsppbke9QgMubfldmMeg3vX1wVI0fPq\n5oUXKM82/3CorW4YnBeXrKLmMzao5ZpqFRPRiOtoS3Rq69dAEFw6ewUvLbYRcLvnQ2lOwzrhp4ht\nGudAH3dY9hz8Yu8PE1KVxWHZlg9WHaS8qrYud9GFQpOCQAjRRQjxf0KI3cBrqJxDQko5Wkr5n6b2\n0ziBS19iT5c/tXYvrPiFQVWJyrliMdY2otO/qm80j07s1nSCLZ9g60gY1IM3Y6P1AewIuen2htGB\nd8Dfc+qCkBrlf2Php0esy53GwENpVq+XHd/BC3HKYCwlHF4DXSaoQDhHGP6gKtj++U1Q3EjhmgUP\nwNujlcfIzfNVfn5QRvc5o1TyNIOECH9mjktoMbmYHV0n2o/Ai0/AnNH2CdPqU5ABh1bZG4QbwycY\nrp8L/W9VrpC2xAwHhHWWV2oMFhrJbtsSlyVGct2A9nUJ12prJXuOFVFtm8G043CVUqLPjad8/Pq8\ndVM/nr2ypxKIidcqG5FldllThWdpJkdkW95cvh+zSdSlwb5QaG5GsBs1+r9MSjlcSvkaKs+Q5lzT\ndSJZ7ZpODnfOaddX/QFrqmx0+s0X/GiUomxY+Fdr2uXMLSrxmyXYxhE+uqrB6K3F9BpxycqYanER\nFUIJNzfDB6JtN2t/hFA2nWvfczxth2+IKmVamqMK4ti6ohZkQNrPyrhYX51hycZqY6wc1jmUe0af\nYhBhZQkc+NXqw593QCVpq2/sLc1V39/O72HnPHhvgl32ziYJ7wGXvWz9viz4BKsBgcWt03J+v1Of\nEUxIjOSe0Z3rUlbkllZSXStp629zTt8QVSXQ68xdL8f1iLDaH+KS1Xu6IdBqaxCTXiPVbxi1EpLa\nt8HfwfTO5wvN/bKvArKAZUKIt4UQF6GMxRpXJ26U+gN6t1F68+C40/wzSljzulWVYNRPJrblYtt1\n1K8z8PPjKo1Hc8QlqxKPlgyW695WdacthHRWRtzv/6TURkLYz1wc7dflr8LBFfCLTd3ozR+rWUZf\nw9f/42vgG8Pt0mILaklP3xL5R5RqyhJLUaf6qmfa8wxQD+2sraqNh/+Zqx/HPQcTDc+pZqKKHSGv\npJKjRm0DSwxBeIBj8QhnREQv9T1YBJq7F/S5Ec8OfXE3C566okezu5+PNCkIpJTfSSmnAl2BZcD9\nQFshxBtCiEvOVQc1v1Nqa5RRNGZ4ndvoKeMXrvLdWB5U6SnKRnAqqoTIJOXWedJI/LVznnWG0RSx\nIwFh/aNv/gj2LrRuN5lVvWZQQVOnS++pcNH/Qa+pannx32DFv6HTaKs9QpisRdwbmRGcFsFxyk5i\nMRhbvt829QycZjdlnM87aJ9Q7UzoONRq6I9Lhpn7lYfPaTBx9gr+tVDFc1hiCNoGnAPPdZNJJX7M\nTVfLuQcgczN/GduZX/6STI92rRv85QxanOtKKUuklJ9KKS8HooHNqHxDGlelMBOeDlVpIAbdefqu\ncEJYXUgrS1VCtbjkUztGz6vUbOSLm9UxirPBv4W61j7BSpVlEQQ2OWTquO4juPKtJnP3OMyIByHc\nSB8R3lN5Oo190ro9NF65etbWKEFgcj/tEXQdbh5KGJywEQT+kY3Paizff97BhjOG02XXAlVvw2RW\nQr2+CslBerQLVMneUO6uExMjiGrTRAK8s83kN+BWY3Cw8T145xLiQv2aTsB3nnMKFqi6qOI5xkvj\nqviEKH3zyTTl4XImOlrLg+jwaqipPHVB0KYDXP2uirPIWKcK4/g5kJNl4otKIJTlqWuoLwhORT3l\nKL2nqpctYQmqZGj+IWWkjEg8OynEwxKssQQBUdCpCffNoBhlI6gqs3OXPCPWzVGeWcKshNEoB43s\n9UiMCmTp7myKK6rp2yGI/05rPh/PWcXD5oGfdxDadDyrqd1/b1y4V6ZxHm6e4BkIq/8D/+xo5+54\nygTFKJfDjkPhpu+gQ/NZEhslfizcv01FKkPLMwJQVd1COjXuOnousaQVP7FXqVQSrzlLx41XBYRq\nqpSb6OTXG28X2VvV0572VV2KkDMmLhmO71CJ1Ta+f9qHSYwOUMX8jha0WHTeKSz+m6q019iM8QJD\nCwLN6WHJbhnU8cxmBOOeU1lG3b2V7tzjNKfeXoFK1RQQ7XjOl9SvVIyG2bP1/uhhXaD39WqWlbbE\nPlDvTOh7M9y2WNkgmqP/rfDHH1U8w9kKWIxLVu/7lzbIgnoqWNJqpB4t4O6PN3Htm6vOvG+nQnmh\nciU+uV8LAo2mUSx6bEdSQTSHyayCt5Y+3TDdxKkSGK3UEB2GONZ+0wcqsvaxY3aF4s8p3kFw5Zsq\nhuHTqWc0grYjOFYdM/cAvNhF5cxvimPbYduXLccQOEpkb5X+GRpNP+0obf29ePm63ozrEcGxwvK6\nmsbnjLhkVU61slgLAo2mUSwRti0lh2uJkhwVvLXixcaDr04Fd2+l3jA7aPqKS1YeO6U5rav/lVJ5\n+NRWKWF2to65da7yiCrObjrArrIU3hwG39x+ds4LSrhbbCxnaPi+sk807YN9OFFUcW48hmyxlIzt\nOPzMnQZ+52hBoDk9LOm0z3RG4G6jCrIUpT9XxCWr9w8nn9vz1mfhLPivkY8p4AxdRy0IAUuehN9e\nUctNjWhtVXGn6d3TKJPfUC64pxFVbMvxonK+2pjB0fyycxNDYItviPqdW7zbLmBOyWtIo6kjLAEu\n/feZP7wtDyJhcnwkf7awCLEyB4u+OIsgm5KdZ2tGAMr+UJSpYjUc8aQ6m3j6waMZylh9BqRmFPDQ\nl6pSnV1U8bmi9/XqO7zA0YJAc3oEtIMBZ0mdcNdKa2rnc4nJ3HrntsXWSHs2BUFoFxUr0aZj84Fi\n9250TnEUIVRMwxmQaFOHofcpFm0/Kwz5HeX4ciJOVQ0JIcYLIfYIIdKEELOaaDNFCLFTCLFDCPGp\nM/uj+Z0SkagEi6ud24KlzkTXy85uhtnQLuq9YwvG89DOyrj8O6RtgBdt/T25qk8UfTv8TrLvXoA4\nbUYghDADrwMXAxnAeiHEPCnlTps28cCjwDApZZ4Q4gxDKjWa85CAKFVMJjD6zFM82GIRMN1b2QZy\nhnQK82PDoVZW313gOFM1NBBIk1KmAwgh5gJXADtt2twBvG5ELCOlPO7E/mg0v0+EgLFPKJ3+2SR6\nIPxlz7m3D5xlAr3dWZ1+kvKqGrzcW7++74WIcFbEnhDiGmC8lPJ2Y/kmYJCU8l6bNt8Be4FhgBl4\nQkq5sJFjTQemA4SFhfX74osvnNLn3zPFxcX4+fm1djfOOfq6XYvGrruyRpJbLonwvXCdHM/F/R49\nevRGKWX/xra1trHYDYgHklEJ7X4VQiRKKfNtG0kp6/IbJSQkyOTk5HPczdYnJSUFfd2ug75u16K1\nr9uZIvYo0N5mOdpYZ0sGME9KWSWlPICaHfxOCvNqNBqNa+BMQbAeiBdCxAohPICpwLx6bb5DzQYQ\nQoQCXYB0J/ZJo9FoNPVwmiCQUlYD9wKLUMXuv5BS7hBCPCWEmGQ0WwScFELsRBW/mSmlPOmsPmk0\nGo2mIU61EUgpfwR+rLfucZvPEnjQeGk0Go2mFbhwzfAajUajcQgtCDQajcbF0YJAo9FoXBwtCDQa\njcbF0YJAo9FoXBwtCDQajcbF0YJAo9FoXBwtCDQajcbF0YJAo9FoXBwtCDQajcbF0YJAo9FoXBwt\nCDQajcbF0YJAo9FoXBwtCDQajcbF0YJAo9FoXBwtCDQajcbF0YJAo9FoXBwtCDQajcbF0YJAo9Fo\nXBwtCDQajcbF0YJAo9FoXBwtCDQajcbF0YJAo9FoXBwtCDQajcbF0YJAo9FoXBwtCDQajcbF0YJA\no9FoXBynCgIhxHghxB4hRJoQYlYj228RQpwQQmwxXrc7sz8ajUajaYibsw4shDADrwMXAxnAeiHE\nPCnlznpNP5dS3uusfmg0Go2meZw5IxgIpEkp06WUlcBc4Aonnk+j0Wg0p4EzBUEUcMRmOcNYV5+r\nhRDbhBBfCSHaO7E/Go1Go2kEp6mGHGQ+8JmUskIIcSfwATCmfiMhxHRgOkBYWBgpKSnntJO/B4qL\ni/V1uxD6ul2L1r5uZwqCo4DtCD/aWFeHlPKkzeL/gH81diAp5RxgDkBCQoJMTk4+qx09H0hJSUFf\nt+ugr9u1aO3rdqZqaD0QL4SIFUJ4AFOBebYNhBCRNouTgF1O7I9Go9FoGsFpMwIpZbUQ4l5gEWAG\n3pVS7hBCPAVskFLOA/4shJgEVAO5wC3O6o9Go9FoGsepNgIp5Y/Aj/XWPW7z+VHgUWf2QaPRaDTN\noyOLNRqNxsXRgkCj0WhcHC0INBqNxsXRgkCj0WhcHC0INBqNxsXRgkCj0WhcHC0INBqNxsXRgkCj\n0WhcHC0INBqNxsXRgkCj0WhcHC0INBqNxsXRgkCj0WhcHC0INBqNxsXRgkCj0WhcHC0INBqNxsXR\ngkCj0WhcHC0INBqNxsXRgkCj0WhcHC0INBqNxsXRgkCj0WhcHC0INBqNxsXRgkCj0WhcHC0INBqN\nxsXRgkCj0WhcHC0INBqNxsXRgkCj0WhcHC0INBqNxsXRgkCj0WhcHKcKAiHEeCHEHiFEmhBiVjPt\nrhZCSCFEf2f2R6PRaDQNcZogEEKYgdeBCUB34HohRPdG2vkDM4C1zuqLRqPRaJrGmTOCgUCalDJd\nSlkJzAWuaKTd08DzQLkT+6LRaDSaJnBz4rGjgCM2yxnAINsGQoi+QHsp5Q9CiJlNHUgIMR2YbixW\nCCG2n+3OngeEAjmt3YlWQF+3a6Gv23l0bGqDMwVBswghTMBLwC0ttZVSzgHmGPttkFK6nC1BX7dr\noa/btWjt63amaugo0N5mOdpYZ8Ef6AmkCCEOAoOBedpgrNFoNOcWZwqC9UC8ECJWCOEBTAXmWTZK\nKQuklKFSyhgpZQywBpgkpdzgxD5pNBqNph5OEwRSymrgXmARsAv4Qkq5QwjxlBBi0hkces5Z6eD5\nh75u10Jft2vRqtctpJSteX6NRqPRtDI6slij0WhcHC0INBqNxsU5rwSBoykrzneEEO2FEMuEEDuF\nEDuEEDOM9cFCiJ+FEPuM96DW7uvZRghhFkJsFkIsMJZjhRBrjXv+ueF4cMEhhGgjhPhKCLFbCLFL\nCDHkQr/fQogHjN/3diHEZ0IIrwv1fgsh3hVCHLeNgWrq/grFbOM72GbEWzmV80YQOJqy4gKhGviL\nlLI7yq32HuNaZwFLpZTxwFJj+UJjBsq5wMLzwMtSys5AHnBbq/TK+bwKLJRSdgV6o76DC/Z+CyGi\ngD8D/aWUPQEzyrPwQr3f7wPj661r6v5OAOKN13TgDWd37rwRBDiesuK8R0qZJaXcZHwuQj0UolDX\n+4HR7ANgcuv00DkIIaKBS4H/GcsCGAN8ZTS54K4ZQAgRCIwE3gGQUlZKKfO5wO83KqDVWwjhBvgA\nWVyg91tK+SuQW291U/f3CuBDqVgDtBFCRDqzf+eTIGgsZUVUK/XlnCGEiAH6oJLyhUsps4xNx4Dw\nVuqWs3gFeBioNZZDgHzDFRku3HseC5wA3jPUYv8TQvhyAd9vKeVR4EXgMEoAFAAbcY37baGp+3vO\nn3XnkyBwOYQQfsDXwP1SykLbbVL5/V4wvr9CiMuA41LKja3dl1bADegLvCGl7AOUUE8NdAHe7yDU\nyDcWaAf40lB14jK09v09nwRBSykrLiiEEO4oIfCJlPIbY3W2ZYpovB9vrf45gWHAJCPdyFyUiuBV\n1LTYkhPrQr3nGUCGlNKSiv0rlGC4kO/3WOCAlPKElLIK+Ab1G3CF+22hqft7zp9155MgaDZlxYWE\noRt/B9glpXzJZtM84Gbj883A9+e6b85CSvmolDLaSDcyFfhFSjkNWAZcYzS7oK7ZgpTyGHBECJFg\nrLoI2MkFfL9RKqHBQggf4/duueYL/n7b0NT9nQf8wfAeGgwU2KiQnIOU8rx5AROBvcB+4LHW7o8T\nr3M4apq4DdhivCaidOZLgX3AEiC4tfvqpOtPBhYYn+OAdUAa8CXg2dr9c9I1JwEbjHv+HRB0od9v\n4ElgN7Ad+AjwvFDvN/AZyhZShZoB3tbU/QUEykNyP5CK8qxyav90igmNRqNxcc4n1ZBGo9FonIAW\nBBqNRuPiaEGg0Wg0Lo4WBBqNRuPiaEGg0Wg0Lo4WBBqNgRCiRgixxeZ11pK8CSFibDNPajS/J9xa\nbqLRuAxlUsqk1u6ERnOu0TMCjaYFhBAHhRD/EkKkCiHWCSE6G+tjhBC/GDnjlwohOhjrw4UQ3woh\nthqvocahzEKIt40c/IuFEN5G+z8btSe2CSHmttJlalwYLQg0Give9VRD19lsK5BSJgL/QWVJBXgN\n+EBK2Qv4BJhtrJ8NLJdS9kblDNphrI8HXpdS9gDygauN9bOAPsZx7nLWxWk0TaEjizUaAyFEsZTS\nr5H1B4ExUsp0IxngMSlliBAiB4iUUlYZ67OklKFCiBNAtJSywuYYMcDPUhUhQQjxCOAupXxGCLEQ\nKEallvhOSlns5EvVaOzQMwKNxjFkE59PhQqbzzVYbXSXonLL9AXW22Tf1GjOCVoQaDSOcZ3N+2rj\n8ypUplSAacAK4/NS4G6oq8Ec2NRBhRAmoL2UchnwCBAINJiVaDTORI88NBor3kKILTbLC6WUFhfS\nICHENtSo/npj3X2oqmIzURXG/misnwHMEULchhr5343KPNkYZuBjQ1gIYLZUZSo1mnOGthFoNC1g\n2Aj6SylzWrsvGo0z0KohjUajcXH0jECj0WhcHD0j0Gg0GhdHCwKNRqNxcbQg0Gg0GhdHCwKNRqNx\ncbQg0Gg0Ghfn/wGZa06vkq0L9QAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Av3RkqsePBQ",
        "colab_type": "text"
      },
      "source": [
        "# Model with l2 regularizer and dropout layers"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHap6Uu1eOgp",
        "colab_type": "code",
        "outputId": "b58c92ea-81bc-4f91-f38e-e3cab4eff8fb",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "from tensorflow.keras import regularizers\n",
        "\n",
        "def create_l2_dropout_model():\n",
        "    model = tf.keras.Sequential([\n",
        "      preprocessing_layer,\n",
        "      tf.keras.layers.Dense(256, activation=\"relu\",\n",
        "                            kernel_regularizer=regularizers.l2(0.001)),\n",
        "      tf.keras.layers.Dropout(0.50),\n",
        "\n",
        "      tf.keras.layers.Dense(256, activation=\"relu\",\n",
        "                            kernel_regularizer=regularizers.l2(0.001)), \n",
        "      tf.keras.layers.Dropout(0.50),\n",
        "\n",
        "      tf.keras.layers.Dense(256, activation=\"relu\",\n",
        "                            kernel_regularizer=regularizers.l2(0.001)), \n",
        "      tf.keras.layers.Dropout(0.50),\n",
        "\n",
        "      tf.keras.layers.Dense(256, activation=\"relu\",\n",
        "                            kernel_regularizer=regularizers.l2(0.001)), \n",
        "      tf.keras.layers.Dropout(0.50),\n",
        "\n",
        "      tf.keras.layers.Dense(1, activation=\"sigmoid\"),\n",
        "    ])\n",
        "\n",
        "    lr_schedule = tf.keras.optimizers.schedules.InverseTimeDecay(\n",
        "                  0.001,\n",
        "                  decay_steps=STEPS_PER_EPOCH*1000,\n",
        "                  decay_rate=1,\n",
        "                  staircase=False)\n",
        "\n",
        "    model.compile(\n",
        "        loss=\"binary_crossentropy\",\n",
        "        optimizer=tf.keras.optimizers.Adam(lr_schedule),\n",
        "        metrics=[\"accuracy\", \"binary_crossentropy\"]\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "\n",
        "train_model = create_l2_dropout_model()\n",
        "l2_dropout_model_path = \"/content/drive/My Drive/l2_dropout_model_heart_v3/l2_dropout_heart_model_v3.ckpt\"\n",
        "\n",
        "\n",
        "# train model\n",
        "print(\"--Fit model--\")\n",
        "val_loss_callback = tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", mode=\"max\", verbose=1, patience=100, min_delta=0.001)\n",
        "checkpoint_val = tf.keras.callbacks.ModelCheckpoint(l2_dropout_model_path, monitor=\"val_accuracy\", mode=\"max\", save_best_only=True, save_weights_only=True, verbose=1)\n",
        "log_name = \"sizes/l2_dropout\"\n",
        "tb_log = tf.keras.callbacks.TensorBoard(logdir/log_name)\n",
        "#checkpoint_train = tf.keras.callbacks.ModelCheckpoint(\"base_heart_model.h5\", monitor=\"loss\", mode=\"min\", save_best_only=True, save_weights_only=True, verbose=1)\n",
        "cb = [val_loss_callback, checkpoint_val, tb_log]\n",
        "\n",
        "train_history = train_model.fit(\n",
        "    train_data,\n",
        "    epochs=99999999999, \n",
        "    verbose=1, \n",
        "    validation_data=test_data, \n",
        "    callbacks=cb,\n",
        "    steps_per_epoch=STEPS_PER_EPOCH)\n",
        "\n",
        "#model_histories = {}\n",
        "model_histories[\"l2_dropout\"] = train_history\n",
        "\n",
        "plotter = tfdocs.plots.HistoryPlotter(metric='accuracy')\n",
        "plotter.plot(model_histories)\n",
        "plt.ylim([0.4, 1.0])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--Fit model--\n",
            "Train for 36 steps\n",
            "WARNING:tensorflow:Model failed to serialize as JSON. Ignoring... ('Cannot serialize', functools.partial(<function normalize_numeric_data at 0x7f9f81de2488>, mean=array([138.81842818,   3.79650407,   4.78547425,  25.49937669,\n",
            "        52.90514905,  26.04127371,  17.70642276,  43.55555556]), std=array([21.26571252,  4.75853044,  2.09918096,  7.56312   , 10.22035483,\n",
            "        4.09612605, 25.53965407, 14.5910849 ])))\n",
            "Epoch 1/99999999999\n",
            "34/36 [===========================>..] - ETA: 0s - loss: 1.3628 - accuracy: 0.6471 - binary_crossentropy: 0.6396\n",
            "Epoch 00001: val_accuracy improved from -inf to 0.69892, saving model to /content/drive/My Drive/l2_dropout_model_heart_v3/l2_dropout_heart_model_v3.ckpt\n",
            "36/36 [==============================] - 2s 67ms/step - loss: 1.3556 - accuracy: 0.6556 - binary_crossentropy: 0.6345 - val_loss: 1.2236 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.5465\n",
            "Epoch 2/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 1.3188 - accuracy: 0.6222 - binary_crossentropy: 0.6412\n",
            "Epoch 00002: val_accuracy improved from 0.69892 to 0.73118, saving model to /content/drive/My Drive/l2_dropout_model_heart_v3/l2_dropout_heart_model_v3.ckpt\n",
            "36/10 [============================================================================================================] - 0s 12ms/step - loss: 1.1938 - accuracy: 0.6694 - binary_crossentropy: 0.6086 - val_loss: 1.1484 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.5325\n",
            "Epoch 3/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 1.1978 - accuracy: 0.6875 - binary_crossentropy: 0.5662\n",
            "Epoch 00003: val_accuracy did not improve from 0.73118\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 1.2220 - accuracy: 0.7139 - binary_crossentropy: 0.5845 - val_loss: 1.1753 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.5585\n",
            "Epoch 4/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 1.1705 - accuracy: 0.7111 - binary_crossentropy: 0.5760\n",
            "Epoch 00004: val_accuracy did not improve from 0.73118\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 1.3548 - accuracy: 0.7111 - binary_crossentropy: 0.5697 - val_loss: 1.0799 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5329\n",
            "Epoch 5/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 1.1104 - accuracy: 0.7250 - binary_crossentropy: 0.5472\n",
            "Epoch 00005: val_accuracy did not improve from 0.73118\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 1.1610 - accuracy: 0.7167 - binary_crossentropy: 0.5208 - val_loss: 1.0513 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.5311\n",
            "Epoch 6/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 1.0340 - accuracy: 0.8000 - binary_crossentropy: 0.5005\n",
            "Epoch 00006: val_accuracy did not improve from 0.73118\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 1.0538 - accuracy: 0.7250 - binary_crossentropy: 0.5506 - val_loss: 1.0928 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5542\n",
            "Epoch 7/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.9677 - accuracy: 0.7667 - binary_crossentropy: 0.4621\n",
            "Epoch 00007: val_accuracy did not improve from 0.73118\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.9531 - accuracy: 0.7528 - binary_crossentropy: 0.4983 - val_loss: 1.0587 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5410\n",
            "Epoch 8/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.9217 - accuracy: 0.7750 - binary_crossentropy: 0.4412\n",
            "Epoch 00008: val_accuracy did not improve from 0.73118\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 1.0569 - accuracy: 0.7194 - binary_crossentropy: 0.5054 - val_loss: 1.0017 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5490\n",
            "Epoch 9/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.9440 - accuracy: 0.7222 - binary_crossentropy: 0.4884\n",
            "Epoch 00009: val_accuracy did not improve from 0.73118\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.8882 - accuracy: 0.7278 - binary_crossentropy: 0.5111 - val_loss: 0.9956 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.5653\n",
            "Epoch 10/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 1.0490 - accuracy: 0.6111 - binary_crossentropy: 0.6159\n",
            "Epoch 00010: val_accuracy did not improve from 0.73118\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.9148 - accuracy: 0.6944 - binary_crossentropy: 0.5577 - val_loss: 0.9717 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.5529\n",
            "Epoch 11/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.9100 - accuracy: 0.7444 - binary_crossentropy: 0.4986\n",
            "Epoch 00011: val_accuracy did not improve from 0.73118\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.8031 - accuracy: 0.7583 - binary_crossentropy: 0.4799 - val_loss: 0.9986 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.5663\n",
            "Epoch 12/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.8635 - accuracy: 0.7667 - binary_crossentropy: 0.4717\n",
            "Epoch 00012: val_accuracy did not improve from 0.73118\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.7819 - accuracy: 0.7583 - binary_crossentropy: 0.4844 - val_loss: 0.9254 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.5494\n",
            "Epoch 13/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.8984 - accuracy: 0.7556 - binary_crossentropy: 0.5257\n",
            "Epoch 00013: val_accuracy did not improve from 0.73118\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.8799 - accuracy: 0.7500 - binary_crossentropy: 0.5348 - val_loss: 0.8810 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.5435\n",
            "Epoch 14/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.8390 - accuracy: 0.7444 - binary_crossentropy: 0.4845\n",
            "Epoch 00014: val_accuracy did not improve from 0.73118\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.6879 - accuracy: 0.7444 - binary_crossentropy: 0.4939 - val_loss: 0.8848 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5401\n",
            "Epoch 15/99999999999\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.7533 - accuracy: 0.8143 - binary_crossentropy: 0.4151\n",
            "Epoch 00015: val_accuracy did not improve from 0.73118\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.8030 - accuracy: 0.7944 - binary_crossentropy: 0.4785 - val_loss: 0.8898 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5595\n",
            "Epoch 16/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.7953 - accuracy: 0.8000 - binary_crossentropy: 0.4731\n",
            "Epoch 00016: val_accuracy did not improve from 0.73118\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.7675 - accuracy: 0.7722 - binary_crossentropy: 0.4815 - val_loss: 0.8741 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5615\n",
            "Epoch 17/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.7835 - accuracy: 0.8444 - binary_crossentropy: 0.4761\n",
            "Epoch 00017: val_accuracy did not improve from 0.73118\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.8064 - accuracy: 0.7889 - binary_crossentropy: 0.4808 - val_loss: 0.8144 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.5416\n",
            "Epoch 18/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6981 - accuracy: 0.8375 - binary_crossentropy: 0.4047\n",
            "Epoch 00018: val_accuracy improved from 0.73118 to 0.75269, saving model to /content/drive/My Drive/l2_dropout_model_heart_v3/l2_dropout_heart_model_v3.ckpt\n",
            "36/10 [============================================================================================================] - 0s 12ms/step - loss: 0.7159 - accuracy: 0.7944 - binary_crossentropy: 0.4756 - val_loss: 0.8359 - val_accuracy: 0.7527 - val_binary_crossentropy: 0.5505\n",
            "Epoch 19/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.7294 - accuracy: 0.8375 - binary_crossentropy: 0.4494\n",
            "Epoch 00019: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.7393 - accuracy: 0.7667 - binary_crossentropy: 0.4918 - val_loss: 0.8030 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.5485\n",
            "Epoch 20/99999999999\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.6594 - accuracy: 0.8714 - binary_crossentropy: 0.3916\n",
            "Epoch 00020: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.8051 - accuracy: 0.8056 - binary_crossentropy: 0.4539 - val_loss: 0.7858 - val_accuracy: 0.7419 - val_binary_crossentropy: 0.5505\n",
            "Epoch 21/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.7185 - accuracy: 0.7778 - binary_crossentropy: 0.4616\n",
            "Epoch 00021: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.8763 - accuracy: 0.7667 - binary_crossentropy: 0.4921 - val_loss: 0.7977 - val_accuracy: 0.7419 - val_binary_crossentropy: 0.5549\n",
            "Epoch 22/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6765 - accuracy: 0.7889 - binary_crossentropy: 0.4307\n",
            "Epoch 00022: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.7793 - accuracy: 0.7972 - binary_crossentropy: 0.4351 - val_loss: 0.8348 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.6009\n",
            "Epoch 23/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.8107 - accuracy: 0.7875 - binary_crossentropy: 0.5741\n",
            "Epoch 00023: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.7150 - accuracy: 0.7750 - binary_crossentropy: 0.4953 - val_loss: 0.8452 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5705\n",
            "Epoch 24/99999999999\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.8023 - accuracy: 0.7286 - binary_crossentropy: 0.5763\n",
            "Epoch 00024: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.5968 - accuracy: 0.7556 - binary_crossentropy: 0.4993 - val_loss: 0.7501 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.5566\n",
            "Epoch 25/99999999999\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.6667 - accuracy: 0.7857 - binary_crossentropy: 0.4498\n",
            "Epoch 00025: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.7946 - accuracy: 0.7528 - binary_crossentropy: 0.5070 - val_loss: 0.7742 - val_accuracy: 0.7419 - val_binary_crossentropy: 0.5502\n",
            "Epoch 26/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6424 - accuracy: 0.8250 - binary_crossentropy: 0.4351\n",
            "Epoch 00026: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.8292 - accuracy: 0.7417 - binary_crossentropy: 0.5135 - val_loss: 0.7503 - val_accuracy: 0.7419 - val_binary_crossentropy: 0.5394\n",
            "Epoch 27/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.7361 - accuracy: 0.7875 - binary_crossentropy: 0.5373\n",
            "Epoch 00027: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.6556 - accuracy: 0.7694 - binary_crossentropy: 0.4970 - val_loss: 0.7802 - val_accuracy: 0.7419 - val_binary_crossentropy: 0.5353\n",
            "Epoch 28/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.7827 - accuracy: 0.7500 - binary_crossentropy: 0.5902\n",
            "Epoch 00028: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.6724 - accuracy: 0.7694 - binary_crossentropy: 0.4990 - val_loss: 0.7847 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.5510\n",
            "Epoch 29/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5751 - accuracy: 0.8375 - binary_crossentropy: 0.3893\n",
            "Epoch 00029: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.6181 - accuracy: 0.8056 - binary_crossentropy: 0.4510 - val_loss: 0.7052 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5488\n",
            "Epoch 30/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6997 - accuracy: 0.7000 - binary_crossentropy: 0.5212\n",
            "Epoch 00030: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.5314 - accuracy: 0.7889 - binary_crossentropy: 0.4507 - val_loss: 0.7408 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5399\n",
            "Epoch 31/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.7201 - accuracy: 0.7125 - binary_crossentropy: 0.5470\n",
            "Epoch 00031: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.5676 - accuracy: 0.7722 - binary_crossentropy: 0.4605 - val_loss: 0.7640 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5742\n",
            "Epoch 32/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5731 - accuracy: 0.8000 - binary_crossentropy: 0.4052\n",
            "Epoch 00032: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.6409 - accuracy: 0.8167 - binary_crossentropy: 0.4349 - val_loss: 0.7150 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.5843\n",
            "Epoch 33/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5577 - accuracy: 0.8333 - binary_crossentropy: 0.3946\n",
            "Epoch 00033: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.6440 - accuracy: 0.7667 - binary_crossentropy: 0.4696 - val_loss: 0.7049 - val_accuracy: 0.7419 - val_binary_crossentropy: 0.5567\n",
            "Epoch 34/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6939 - accuracy: 0.6778 - binary_crossentropy: 0.5359\n",
            "Epoch 00034: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.4978 - accuracy: 0.7722 - binary_crossentropy: 0.4614 - val_loss: 0.6997 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.5754\n",
            "Epoch 35/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6177 - accuracy: 0.7500 - binary_crossentropy: 0.4644\n",
            "Epoch 00035: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 11ms/step - loss: 0.6172 - accuracy: 0.7861 - binary_crossentropy: 0.4518 - val_loss: 0.6944 - val_accuracy: 0.7419 - val_binary_crossentropy: 0.5676\n",
            "Epoch 36/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6876 - accuracy: 0.7000 - binary_crossentropy: 0.5383\n",
            "Epoch 00036: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.5439 - accuracy: 0.7833 - binary_crossentropy: 0.4389 - val_loss: 0.6761 - val_accuracy: 0.7527 - val_binary_crossentropy: 0.5548\n",
            "Epoch 37/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5242 - accuracy: 0.8778 - binary_crossentropy: 0.3785\n",
            "Epoch 00037: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.5950 - accuracy: 0.8056 - binary_crossentropy: 0.4203 - val_loss: 0.6948 - val_accuracy: 0.7419 - val_binary_crossentropy: 0.5701\n",
            "Epoch 38/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5253 - accuracy: 0.8250 - binary_crossentropy: 0.3824\n",
            "Epoch 00038: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.4909 - accuracy: 0.7972 - binary_crossentropy: 0.4240 - val_loss: 0.6730 - val_accuracy: 0.7527 - val_binary_crossentropy: 0.5582\n",
            "Epoch 39/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6554 - accuracy: 0.7333 - binary_crossentropy: 0.5164\n",
            "Epoch 00039: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.7334 - accuracy: 0.7639 - binary_crossentropy: 0.4740 - val_loss: 0.7145 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.5729\n",
            "Epoch 40/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5851 - accuracy: 0.7500 - binary_crossentropy: 0.4493\n",
            "Epoch 00040: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 11ms/step - loss: 0.5851 - accuracy: 0.7667 - binary_crossentropy: 0.4644 - val_loss: 0.7534 - val_accuracy: 0.6667 - val_binary_crossentropy: 0.6292\n",
            "Epoch 41/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5785 - accuracy: 0.7750 - binary_crossentropy: 0.4450\n",
            "Epoch 00041: val_accuracy did not improve from 0.75269\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.4751 - accuracy: 0.8111 - binary_crossentropy: 0.4124 - val_loss: 0.8025 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.6116\n",
            "Epoch 42/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5112 - accuracy: 0.9000 - binary_crossentropy: 0.3797\n",
            "Epoch 00042: val_accuracy improved from 0.75269 to 0.76344, saving model to /content/drive/My Drive/l2_dropout_model_heart_v3/l2_dropout_heart_model_v3.ckpt\n",
            "36/10 [============================================================================================================] - 0s 12ms/step - loss: 0.4885 - accuracy: 0.8056 - binary_crossentropy: 0.3894 - val_loss: 0.6832 - val_accuracy: 0.7634 - val_binary_crossentropy: 0.5630\n",
            "Epoch 43/99999999999\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.5218 - accuracy: 0.8143 - binary_crossentropy: 0.3919\n",
            "Epoch 00043: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 11ms/step - loss: 0.5462 - accuracy: 0.8111 - binary_crossentropy: 0.4213 - val_loss: 0.6729 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.5630\n",
            "Epoch 44/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5209 - accuracy: 0.8125 - binary_crossentropy: 0.3931\n",
            "Epoch 00044: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.5320 - accuracy: 0.7944 - binary_crossentropy: 0.4393 - val_loss: 0.7665 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5872\n",
            "Epoch 45/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4937 - accuracy: 0.8375 - binary_crossentropy: 0.3678\n",
            "Epoch 00045: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.5221 - accuracy: 0.8250 - binary_crossentropy: 0.3869 - val_loss: 0.6801 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.5897\n",
            "Epoch 46/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4530 - accuracy: 0.8125 - binary_crossentropy: 0.3292\n",
            "Epoch 00046: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.4737 - accuracy: 0.8028 - binary_crossentropy: 0.3898 - val_loss: 0.7144 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.6042\n",
            "Epoch 47/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6006 - accuracy: 0.7375 - binary_crossentropy: 0.4794\n",
            "Epoch 00047: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.4684 - accuracy: 0.7833 - binary_crossentropy: 0.4374 - val_loss: 0.7249 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5610\n",
            "Epoch 48/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5473 - accuracy: 0.7500 - binary_crossentropy: 0.4288\n",
            "Epoch 00048: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.6065 - accuracy: 0.8222 - binary_crossentropy: 0.4029 - val_loss: 0.7134 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5893\n",
            "Epoch 49/99999999999\n",
            " 6/10 [=================>............] - ETA: 0s - loss: 0.4483 - accuracy: 0.8833 - binary_crossentropy: 0.3308\n",
            "Epoch 00049: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.7351 - accuracy: 0.8028 - binary_crossentropy: 0.4368 - val_loss: 0.6648 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.5675\n",
            "Epoch 50/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5007 - accuracy: 0.8333 - binary_crossentropy: 0.3863\n",
            "Epoch 00050: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.5808 - accuracy: 0.8139 - binary_crossentropy: 0.3882 - val_loss: 0.6686 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5707\n",
            "Epoch 51/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4935 - accuracy: 0.7625 - binary_crossentropy: 0.3800\n",
            "Epoch 00051: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 11ms/step - loss: 0.5376 - accuracy: 0.7972 - binary_crossentropy: 0.3845 - val_loss: 0.6900 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.6020\n",
            "Epoch 52/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5782 - accuracy: 0.7375 - binary_crossentropy: 0.4661\n",
            "Epoch 00052: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.5291 - accuracy: 0.8111 - binary_crossentropy: 0.3956 - val_loss: 0.6987 - val_accuracy: 0.7419 - val_binary_crossentropy: 0.6164\n",
            "Epoch 53/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.6473 - accuracy: 0.7625 - binary_crossentropy: 0.5357\n",
            "Epoch 00053: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.4517 - accuracy: 0.7972 - binary_crossentropy: 0.4535 - val_loss: 0.6708 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5544\n",
            "Epoch 54/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4975 - accuracy: 0.8125 - binary_crossentropy: 0.3886\n",
            "Epoch 00054: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 11ms/step - loss: 0.4845 - accuracy: 0.8306 - binary_crossentropy: 0.3984 - val_loss: 0.6871 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.5959\n",
            "Epoch 55/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5103 - accuracy: 0.8000 - binary_crossentropy: 0.4027\n",
            "Epoch 00055: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.4712 - accuracy: 0.8250 - binary_crossentropy: 0.3890 - val_loss: 0.7327 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.6418\n",
            "Epoch 56/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4601 - accuracy: 0.8625 - binary_crossentropy: 0.3527\n",
            "Epoch 00056: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.5010 - accuracy: 0.8111 - binary_crossentropy: 0.4348 - val_loss: 0.6822 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5752\n",
            "Epoch 57/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4673 - accuracy: 0.8250 - binary_crossentropy: 0.3628\n",
            "Epoch 00057: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.3777 - accuracy: 0.8250 - binary_crossentropy: 0.3869 - val_loss: 0.6732 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5914\n",
            "Epoch 58/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5106 - accuracy: 0.7875 - binary_crossentropy: 0.4065\n",
            "Epoch 00058: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.6221 - accuracy: 0.8139 - binary_crossentropy: 0.3923 - val_loss: 0.7744 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.6100\n",
            "Epoch 59/99999999999\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4362 - accuracy: 0.8571 - binary_crossentropy: 0.3327\n",
            "Epoch 00059: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.4631 - accuracy: 0.8194 - binary_crossentropy: 0.4058 - val_loss: 0.6425 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5645\n",
            "Epoch 60/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4850 - accuracy: 0.8222 - binary_crossentropy: 0.3829\n",
            "Epoch 00060: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.5633 - accuracy: 0.8139 - binary_crossentropy: 0.4020 - val_loss: 0.6414 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5650\n",
            "Epoch 61/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5197 - accuracy: 0.7667 - binary_crossentropy: 0.4183\n",
            "Epoch 00061: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.6478 - accuracy: 0.8028 - binary_crossentropy: 0.4029 - val_loss: 0.6609 - val_accuracy: 0.7419 - val_binary_crossentropy: 0.5808\n",
            "Epoch 62/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4774 - accuracy: 0.8667 - binary_crossentropy: 0.3765\n",
            "Epoch 00062: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.5257 - accuracy: 0.8583 - binary_crossentropy: 0.3454 - val_loss: 0.7215 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.6295\n",
            "Epoch 63/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4833 - accuracy: 0.7778 - binary_crossentropy: 0.3819\n",
            "Epoch 00063: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4678 - accuracy: 0.7917 - binary_crossentropy: 0.3854 - val_loss: 0.6745 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.6049\n",
            "Epoch 64/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4991 - accuracy: 0.8333 - binary_crossentropy: 0.3987\n",
            "Epoch 00064: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4742 - accuracy: 0.8389 - binary_crossentropy: 0.3612 - val_loss: 0.7239 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.6247\n",
            "Epoch 65/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4565 - accuracy: 0.8250 - binary_crossentropy: 0.3562\n",
            "Epoch 00065: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3539 - accuracy: 0.8639 - binary_crossentropy: 0.3055 - val_loss: 0.8690 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.6837\n",
            "Epoch 66/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.5089 - accuracy: 0.8125 - binary_crossentropy: 0.4081\n",
            "Epoch 00066: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4107 - accuracy: 0.8472 - binary_crossentropy: 0.3381 - val_loss: 0.7671 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.6417\n",
            "Epoch 67/99999999999\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4226 - accuracy: 0.8429 - binary_crossentropy: 0.3224\n",
            "Epoch 00067: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3686 - accuracy: 0.8667 - binary_crossentropy: 0.3330 - val_loss: 0.7054 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.6387\n",
            "Epoch 68/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.3934 - accuracy: 0.9000 - binary_crossentropy: 0.2934\n",
            "Epoch 00068: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4306 - accuracy: 0.8833 - binary_crossentropy: 0.3070 - val_loss: 0.7347 - val_accuracy: 0.7419 - val_binary_crossentropy: 0.6685\n",
            "Epoch 69/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4134 - accuracy: 0.8778 - binary_crossentropy: 0.3127\n",
            "Epoch 00069: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.4305 - accuracy: 0.8583 - binary_crossentropy: 0.3259 - val_loss: 0.6942 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.5991\n",
            "Epoch 70/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4971 - accuracy: 0.8125 - binary_crossentropy: 0.3978\n",
            "Epoch 00070: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.6140 - accuracy: 0.8278 - binary_crossentropy: 0.3736 - val_loss: 0.8258 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.6512\n",
            "Epoch 71/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4821 - accuracy: 0.8500 - binary_crossentropy: 0.3834\n",
            "Epoch 00071: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3891 - accuracy: 0.8222 - binary_crossentropy: 0.3911 - val_loss: 0.6930 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.6157\n",
            "Epoch 72/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4648 - accuracy: 0.8000 - binary_crossentropy: 0.3663\n",
            "Epoch 00072: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4395 - accuracy: 0.8444 - binary_crossentropy: 0.3449 - val_loss: 0.7781 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.6215\n",
            "Epoch 73/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4654 - accuracy: 0.8667 - binary_crossentropy: 0.3666\n",
            "Epoch 00073: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3676 - accuracy: 0.8472 - binary_crossentropy: 0.3454 - val_loss: 0.7328 - val_accuracy: 0.7419 - val_binary_crossentropy: 0.6807\n",
            "Epoch 74/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.6537 - accuracy: 0.7222 - binary_crossentropy: 0.5554\n",
            "Epoch 00074: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.4272 - accuracy: 0.8250 - binary_crossentropy: 0.3699 - val_loss: 0.6773 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.6221\n",
            "Epoch 75/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4524 - accuracy: 0.8125 - binary_crossentropy: 0.3539\n",
            "Epoch 00075: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.3978 - accuracy: 0.8444 - binary_crossentropy: 0.3436 - val_loss: 0.7800 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.6650\n",
            "Epoch 76/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4289 - accuracy: 0.8556 - binary_crossentropy: 0.3293\n",
            "Epoch 00076: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.5759 - accuracy: 0.8306 - binary_crossentropy: 0.3478 - val_loss: 0.7582 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.6580\n",
            "Epoch 77/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4354 - accuracy: 0.8333 - binary_crossentropy: 0.3361\n",
            "Epoch 00077: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.4402 - accuracy: 0.8250 - binary_crossentropy: 0.3713 - val_loss: 0.7003 - val_accuracy: 0.7527 - val_binary_crossentropy: 0.6295\n",
            "Epoch 78/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4595 - accuracy: 0.8500 - binary_crossentropy: 0.3596\n",
            "Epoch 00078: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.3796 - accuracy: 0.8167 - binary_crossentropy: 0.3558 - val_loss: 0.7595 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.6122\n",
            "Epoch 79/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4966 - accuracy: 0.7750 - binary_crossentropy: 0.3961\n",
            "Epoch 00079: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.4709 - accuracy: 0.8000 - binary_crossentropy: 0.3813 - val_loss: 0.7490 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.6030\n",
            "Epoch 80/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4494 - accuracy: 0.8000 - binary_crossentropy: 0.3492\n",
            "Epoch 00080: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4446 - accuracy: 0.8139 - binary_crossentropy: 0.3663 - val_loss: 0.6943 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.6317\n",
            "Epoch 81/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4750 - accuracy: 0.8500 - binary_crossentropy: 0.3743\n",
            "Epoch 00081: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 11ms/step - loss: 0.6768 - accuracy: 0.8333 - binary_crossentropy: 0.3883 - val_loss: 0.7303 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.6431\n",
            "Epoch 82/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3902 - accuracy: 0.8444 - binary_crossentropy: 0.2887\n",
            "Epoch 00082: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4336 - accuracy: 0.8528 - binary_crossentropy: 0.3421 - val_loss: 0.8161 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.7342\n",
            "Epoch 83/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3991 - accuracy: 0.8778 - binary_crossentropy: 0.2972\n",
            "Epoch 00083: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.4572 - accuracy: 0.8528 - binary_crossentropy: 0.3352 - val_loss: 0.7606 - val_accuracy: 0.7312 - val_binary_crossentropy: 0.6624\n",
            "Epoch 84/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4175 - accuracy: 0.8889 - binary_crossentropy: 0.3159\n",
            "Epoch 00084: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.4417 - accuracy: 0.8583 - binary_crossentropy: 0.3255 - val_loss: 0.7305 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.6598\n",
            "Epoch 85/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4558 - accuracy: 0.8111 - binary_crossentropy: 0.3540\n",
            "Epoch 00085: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3818 - accuracy: 0.8306 - binary_crossentropy: 0.3413 - val_loss: 0.7560 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.6421\n",
            "Epoch 86/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.4785 - accuracy: 0.8000 - binary_crossentropy: 0.3771\n",
            "Epoch 00086: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4062 - accuracy: 0.8361 - binary_crossentropy: 0.3553 - val_loss: 0.7414 - val_accuracy: 0.7097 - val_binary_crossentropy: 0.6356\n",
            "Epoch 87/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3944 - accuracy: 0.8778 - binary_crossentropy: 0.2922\n",
            "Epoch 00087: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4678 - accuracy: 0.8667 - binary_crossentropy: 0.3122 - val_loss: 0.8656 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.7286\n",
            "Epoch 88/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4278 - accuracy: 0.8667 - binary_crossentropy: 0.3257\n",
            "Epoch 00088: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4573 - accuracy: 0.8778 - binary_crossentropy: 0.2961 - val_loss: 0.8319 - val_accuracy: 0.6667 - val_binary_crossentropy: 0.7457\n",
            "Epoch 89/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4346 - accuracy: 0.8333 - binary_crossentropy: 0.3311\n",
            "Epoch 00089: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3287 - accuracy: 0.8222 - binary_crossentropy: 0.3488 - val_loss: 0.7627 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.6759\n",
            "Epoch 90/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4460 - accuracy: 0.8333 - binary_crossentropy: 0.3424\n",
            "Epoch 00090: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.4773 - accuracy: 0.8833 - binary_crossentropy: 0.2945 - val_loss: 0.7996 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.7395\n",
            "Epoch 91/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4379 - accuracy: 0.8222 - binary_crossentropy: 0.3331\n",
            "Epoch 00091: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4124 - accuracy: 0.8444 - binary_crossentropy: 0.3676 - val_loss: 0.8572 - val_accuracy: 0.6667 - val_binary_crossentropy: 0.7440\n",
            "Epoch 92/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4428 - accuracy: 0.8889 - binary_crossentropy: 0.3387\n",
            "Epoch 00092: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3646 - accuracy: 0.8611 - binary_crossentropy: 0.3229 - val_loss: 0.8177 - val_accuracy: 0.6559 - val_binary_crossentropy: 0.7199\n",
            "Epoch 93/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5750 - accuracy: 0.7889 - binary_crossentropy: 0.4703\n",
            "Epoch 00093: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4250 - accuracy: 0.8306 - binary_crossentropy: 0.3697 - val_loss: 0.7699 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.6890\n",
            "Epoch 94/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4225 - accuracy: 0.8778 - binary_crossentropy: 0.3186\n",
            "Epoch 00094: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4100 - accuracy: 0.8667 - binary_crossentropy: 0.3038 - val_loss: 0.7617 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.6940\n",
            "Epoch 95/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4062 - accuracy: 0.8889 - binary_crossentropy: 0.3022\n",
            "Epoch 00095: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4127 - accuracy: 0.8639 - binary_crossentropy: 0.3237 - val_loss: 0.7557 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.6932\n",
            "Epoch 96/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4731 - accuracy: 0.8111 - binary_crossentropy: 0.3691\n",
            "Epoch 00096: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.5468 - accuracy: 0.8333 - binary_crossentropy: 0.3425 - val_loss: 0.8760 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.6997\n",
            "Epoch 97/99999999999\n",
            " 1/10 [==>...........................] - ETA: 0s - loss: 0.6387 - accuracy: 0.8000 - binary_crossentropy: 0.5338\n",
            "Epoch 00097: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3368 - accuracy: 0.8972 - binary_crossentropy: 0.2503 - val_loss: 0.9050 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.7854\n",
            "Epoch 98/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3166 - accuracy: 0.9111 - binary_crossentropy: 0.2098\n",
            "Epoch 00098: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.2924 - accuracy: 0.8944 - binary_crossentropy: 0.2458 - val_loss: 0.9287 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.8149\n",
            "Epoch 99/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.5085 - accuracy: 0.8000 - binary_crossentropy: 0.4004\n",
            "Epoch 00099: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.4336 - accuracy: 0.8306 - binary_crossentropy: 0.3648 - val_loss: 0.7867 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.7278\n",
            "Epoch 100/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3875 - accuracy: 0.8778 - binary_crossentropy: 0.2795\n",
            "Epoch 00100: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3227 - accuracy: 0.8694 - binary_crossentropy: 0.3059 - val_loss: 0.9507 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.7584\n",
            "Epoch 101/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4814 - accuracy: 0.8667 - binary_crossentropy: 0.3728\n",
            "Epoch 00101: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3697 - accuracy: 0.8750 - binary_crossentropy: 0.3310 - val_loss: 0.8646 - val_accuracy: 0.6344 - val_binary_crossentropy: 0.7261\n",
            "Epoch 102/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.3836 - accuracy: 0.9125 - binary_crossentropy: 0.2761\n",
            "Epoch 00102: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.5284 - accuracy: 0.8694 - binary_crossentropy: 0.3317 - val_loss: 0.7650 - val_accuracy: 0.6882 - val_binary_crossentropy: 0.6848\n",
            "Epoch 103/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4853 - accuracy: 0.8333 - binary_crossentropy: 0.3789\n",
            "Epoch 00103: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3995 - accuracy: 0.8417 - binary_crossentropy: 0.3324 - val_loss: 0.9020 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.6567\n",
            "Epoch 104/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4899 - accuracy: 0.8222 - binary_crossentropy: 0.3825\n",
            "Epoch 00104: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3438 - accuracy: 0.8361 - binary_crossentropy: 0.3360 - val_loss: 0.7610 - val_accuracy: 0.6559 - val_binary_crossentropy: 0.6708\n",
            "Epoch 105/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3553 - accuracy: 0.9000 - binary_crossentropy: 0.2479\n",
            "Epoch 00105: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3282 - accuracy: 0.8861 - binary_crossentropy: 0.2856 - val_loss: 0.8341 - val_accuracy: 0.6559 - val_binary_crossentropy: 0.7537\n",
            "Epoch 106/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.3512 - accuracy: 0.9000 - binary_crossentropy: 0.2425\n",
            "Epoch 00106: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3875 - accuracy: 0.8611 - binary_crossentropy: 0.3557 - val_loss: 0.8092 - val_accuracy: 0.6237 - val_binary_crossentropy: 0.7223\n",
            "Epoch 107/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.3339 - accuracy: 0.9625 - binary_crossentropy: 0.2263\n",
            "Epoch 00107: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4052 - accuracy: 0.9083 - binary_crossentropy: 0.2519 - val_loss: 0.8833 - val_accuracy: 0.6452 - val_binary_crossentropy: 0.8127\n",
            "Epoch 108/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4089 - accuracy: 0.8125 - binary_crossentropy: 0.2990\n",
            "Epoch 00108: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3576 - accuracy: 0.8861 - binary_crossentropy: 0.2392 - val_loss: 1.0533 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.8530\n",
            "Epoch 109/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4292 - accuracy: 0.8500 - binary_crossentropy: 0.3187\n",
            "Epoch 00109: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4060 - accuracy: 0.8639 - binary_crossentropy: 0.3092 - val_loss: 0.8413 - val_accuracy: 0.6667 - val_binary_crossentropy: 0.7627\n",
            "Epoch 110/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.3690 - accuracy: 0.8875 - binary_crossentropy: 0.2591\n",
            "Epoch 00110: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3521 - accuracy: 0.8722 - binary_crossentropy: 0.2772 - val_loss: 0.8541 - val_accuracy: 0.6667 - val_binary_crossentropy: 0.7899\n",
            "Epoch 111/99999999999\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.4860 - accuracy: 0.8286 - binary_crossentropy: 0.3756\n",
            "Epoch 00111: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4104 - accuracy: 0.8861 - binary_crossentropy: 0.2841 - val_loss: 0.9024 - val_accuracy: 0.6559 - val_binary_crossentropy: 0.7674\n",
            "Epoch 112/99999999999\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.3569 - accuracy: 0.8714 - binary_crossentropy: 0.2463\n",
            "Epoch 00112: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.3484 - accuracy: 0.8639 - binary_crossentropy: 0.2806 - val_loss: 0.9969 - val_accuracy: 0.6237 - val_binary_crossentropy: 0.7783\n",
            "Epoch 113/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4069 - accuracy: 0.9000 - binary_crossentropy: 0.2946\n",
            "Epoch 00113: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3673 - accuracy: 0.8944 - binary_crossentropy: 0.2783 - val_loss: 0.9524 - val_accuracy: 0.6452 - val_binary_crossentropy: 0.8327\n",
            "Epoch 114/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3553 - accuracy: 0.8889 - binary_crossentropy: 0.2419\n",
            "Epoch 00114: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3106 - accuracy: 0.8861 - binary_crossentropy: 0.2632 - val_loss: 0.9843 - val_accuracy: 0.6237 - val_binary_crossentropy: 0.9037\n",
            "Epoch 115/99999999999\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.3866 - accuracy: 0.8857 - binary_crossentropy: 0.2722\n",
            "Epoch 00115: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3430 - accuracy: 0.8972 - binary_crossentropy: 0.2439 - val_loss: 0.9777 - val_accuracy: 0.6559 - val_binary_crossentropy: 0.9080\n",
            "Epoch 116/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3477 - accuracy: 0.8889 - binary_crossentropy: 0.2329\n",
            "Epoch 00116: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.4673 - accuracy: 0.8556 - binary_crossentropy: 0.3116 - val_loss: 0.8579 - val_accuracy: 0.6237 - val_binary_crossentropy: 0.7547\n",
            "Epoch 117/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4129 - accuracy: 0.9000 - binary_crossentropy: 0.2983\n",
            "Epoch 00117: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3429 - accuracy: 0.8944 - binary_crossentropy: 0.2643 - val_loss: 0.9750 - val_accuracy: 0.6559 - val_binary_crossentropy: 0.8184\n",
            "Epoch 118/99999999999\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.3774 - accuracy: 0.8857 - binary_crossentropy: 0.2612\n",
            "Epoch 00118: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3127 - accuracy: 0.9000 - binary_crossentropy: 0.2366 - val_loss: 1.0277 - val_accuracy: 0.6774 - val_binary_crossentropy: 0.8642\n",
            "Epoch 119/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3750 - accuracy: 0.9111 - binary_crossentropy: 0.2580\n",
            "Epoch 00119: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3256 - accuracy: 0.9028 - binary_crossentropy: 0.2563 - val_loss: 0.9801 - val_accuracy: 0.6559 - val_binary_crossentropy: 0.9212\n",
            "Epoch 120/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3319 - accuracy: 0.9222 - binary_crossentropy: 0.2149\n",
            "Epoch 00120: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4236 - accuracy: 0.9222 - binary_crossentropy: 0.2152 - val_loss: 1.0900 - val_accuracy: 0.6667 - val_binary_crossentropy: 1.0329\n",
            "Epoch 121/99999999999\n",
            " 7/10 [====================>.........] - ETA: 0s - loss: 0.3935 - accuracy: 0.8857 - binary_crossentropy: 0.2745\n",
            "Epoch 00121: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4024 - accuracy: 0.8889 - binary_crossentropy: 0.2983 - val_loss: 0.9786 - val_accuracy: 0.6452 - val_binary_crossentropy: 0.8809\n",
            "Epoch 122/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4621 - accuracy: 0.8222 - binary_crossentropy: 0.3436\n",
            "Epoch 00122: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4617 - accuracy: 0.8528 - binary_crossentropy: 0.3091 - val_loss: 0.8939 - val_accuracy: 0.6237 - val_binary_crossentropy: 0.8008\n",
            "Epoch 123/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4530 - accuracy: 0.8556 - binary_crossentropy: 0.3349\n",
            "Epoch 00123: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3110 - accuracy: 0.8833 - binary_crossentropy: 0.2818 - val_loss: 0.9698 - val_accuracy: 0.6559 - val_binary_crossentropy: 0.8859\n",
            "Epoch 124/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.2775 - accuracy: 0.9250 - binary_crossentropy: 0.1578\n",
            "Epoch 00124: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.3755 - accuracy: 0.9056 - binary_crossentropy: 0.2461 - val_loss: 0.9698 - val_accuracy: 0.6452 - val_binary_crossentropy: 0.9119\n",
            "Epoch 125/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4381 - accuracy: 0.8333 - binary_crossentropy: 0.3179\n",
            "Epoch 00125: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3757 - accuracy: 0.8944 - binary_crossentropy: 0.2604 - val_loss: 0.9604 - val_accuracy: 0.6129 - val_binary_crossentropy: 0.8602\n",
            "Epoch 126/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.4218 - accuracy: 0.9125 - binary_crossentropy: 0.3001\n",
            "Epoch 00126: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.2729 - accuracy: 0.9111 - binary_crossentropy: 0.2368 - val_loss: 1.1029 - val_accuracy: 0.5914 - val_binary_crossentropy: 0.9861\n",
            "Epoch 127/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4449 - accuracy: 0.8778 - binary_crossentropy: 0.3213\n",
            "Epoch 00127: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.5172 - accuracy: 0.9056 - binary_crossentropy: 0.2526 - val_loss: 1.0343 - val_accuracy: 0.6237 - val_binary_crossentropy: 0.9414\n",
            "Epoch 128/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3861 - accuracy: 0.9111 - binary_crossentropy: 0.2633\n",
            "Epoch 00128: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3403 - accuracy: 0.9139 - binary_crossentropy: 0.2564 - val_loss: 1.0025 - val_accuracy: 0.6237 - val_binary_crossentropy: 0.8414\n",
            "Epoch 129/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3772 - accuracy: 0.8889 - binary_crossentropy: 0.2553\n",
            "Epoch 00129: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.3855 - accuracy: 0.9083 - binary_crossentropy: 0.2125 - val_loss: 1.0826 - val_accuracy: 0.6667 - val_binary_crossentropy: 0.9745\n",
            "Epoch 130/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4303 - accuracy: 0.8667 - binary_crossentropy: 0.3069\n",
            "Epoch 00130: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.3469 - accuracy: 0.9083 - binary_crossentropy: 0.2364 - val_loss: 0.9462 - val_accuracy: 0.6667 - val_binary_crossentropy: 0.8715\n",
            "Epoch 131/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.3386 - accuracy: 0.8875 - binary_crossentropy: 0.2147\n",
            "Epoch 00131: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.4411 - accuracy: 0.9056 - binary_crossentropy: 0.2222 - val_loss: 1.0353 - val_accuracy: 0.6667 - val_binary_crossentropy: 0.9127\n",
            "Epoch 132/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4580 - accuracy: 0.8667 - binary_crossentropy: 0.3339\n",
            "Epoch 00132: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3085 - accuracy: 0.8917 - binary_crossentropy: 0.2760 - val_loss: 0.9205 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.8461\n",
            "Epoch 133/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.2958 - accuracy: 0.9444 - binary_crossentropy: 0.1712\n",
            "Epoch 00133: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.4200 - accuracy: 0.9000 - binary_crossentropy: 0.2637 - val_loss: 0.9867 - val_accuracy: 0.6452 - val_binary_crossentropy: 0.8905\n",
            "Epoch 134/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4241 - accuracy: 0.8889 - binary_crossentropy: 0.2993\n",
            "Epoch 00134: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.3783 - accuracy: 0.9056 - binary_crossentropy: 0.2578 - val_loss: 1.0184 - val_accuracy: 0.6452 - val_binary_crossentropy: 0.9174\n",
            "Epoch 135/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.2839 - accuracy: 0.9125 - binary_crossentropy: 0.1587\n",
            "Epoch 00135: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.2910 - accuracy: 0.9056 - binary_crossentropy: 0.2245 - val_loss: 1.0776 - val_accuracy: 0.6129 - val_binary_crossentropy: 0.9735\n",
            "Epoch 136/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3703 - accuracy: 0.8889 - binary_crossentropy: 0.2443\n",
            "Epoch 00136: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4805 - accuracy: 0.8889 - binary_crossentropy: 0.2452 - val_loss: 1.0860 - val_accuracy: 0.6344 - val_binary_crossentropy: 0.9298\n",
            "Epoch 137/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3388 - accuracy: 0.8889 - binary_crossentropy: 0.2126\n",
            "Epoch 00137: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4716 - accuracy: 0.8944 - binary_crossentropy: 0.2410 - val_loss: 1.0515 - val_accuracy: 0.7204 - val_binary_crossentropy: 0.8908\n",
            "Epoch 138/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.3445 - accuracy: 0.8778 - binary_crossentropy: 0.2186\n",
            "Epoch 00138: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.4881 - accuracy: 0.8889 - binary_crossentropy: 0.2312 - val_loss: 0.9754 - val_accuracy: 0.6667 - val_binary_crossentropy: 0.8664\n",
            "Epoch 139/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4898 - accuracy: 0.7667 - binary_crossentropy: 0.3636\n",
            "Epoch 00139: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.3973 - accuracy: 0.8722 - binary_crossentropy: 0.2475 - val_loss: 0.9996 - val_accuracy: 0.6989 - val_binary_crossentropy: 0.8951\n",
            "Epoch 140/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.3899 - accuracy: 0.9250 - binary_crossentropy: 0.2639\n",
            "Epoch 00140: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.3443 - accuracy: 0.9278 - binary_crossentropy: 0.2064 - val_loss: 1.0579 - val_accuracy: 0.6344 - val_binary_crossentropy: 0.9084\n",
            "Epoch 141/99999999999\n",
            " 9/10 [==========================>...] - ETA: 0s - loss: 0.4200 - accuracy: 0.8556 - binary_crossentropy: 0.2942\n",
            "Epoch 00141: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 9ms/step - loss: 0.2948 - accuracy: 0.9111 - binary_crossentropy: 0.2265 - val_loss: 1.0895 - val_accuracy: 0.6559 - val_binary_crossentropy: 0.9154\n",
            "Epoch 142/99999999999\n",
            " 8/10 [=======================>......] - ETA: 0s - loss: 0.2742 - accuracy: 0.9375 - binary_crossentropy: 0.1472\n",
            "Epoch 00142: val_accuracy did not improve from 0.76344\n",
            "36/10 [============================================================================================================] - 0s 10ms/step - loss: 0.3432 - accuracy: 0.9167 - binary_crossentropy: 0.2090 - val_loss: 1.0906 - val_accuracy: 0.6452 - val_binary_crossentropy: 0.9392\n",
            "Epoch 00142: early stopping\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(0.4, 1.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAEKCAYAAADn+anLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\ngg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gmmvyKGj_Yaj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# *** DOES NOT WORK; INPUT ERROR?? ***\n",
        "# load base model and evaluate\n",
        "#load_model = create_base_model()\n",
        "\n",
        "#load_model.load_weights(base_model_path)\n",
        "#test_loss, test_accuracy = load_model.evaluate(test_data)\n",
        "#load_model.summary()\n",
        "#print('\\n\\nTest Loss {}, Test Accuracy {}'.format(test_loss, test_accuracy))"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}